Writing training job pid to /opt/ml/training_worker.pid: 58
Training Worker Args: Namespace(aws_region='us-east-1', checkpoint_dir='./checkpoint_sagemaker', environment_s3_key=None, framework='tensorflow', model_metadata_s3_key='s3://aws-deepracer-data-us-east-1-1/data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/model_metadata.json', preset_s3_key=None, pretrained_checkpoint_dir='./pretrained_checkpoint_sagemaker', pretrained_s3_bucket=None, pretrained_s3_prefix='sagemaker', s3_bucket='aws-deepracer-data-us-east-1-1', s3_prefix='data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts')
[s3] Successfully downloaded model metadata                  from s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/model_metadata.json to local ./custom_files/agent/model_metadata.json.
Sensor list ['FRONT_FACING_CAMERA'], network DEEP_CONVOLUTIONAL_NETWORK_SHALLOW, simapp_version 5.0, training_algorithm clipped_ppo, action_space_type discrete lidar_config {'num_sectors': 8, 'num_values_per_sector': 8, 'clipping_dist': 2.0}
Action space from file: [{'steering_angle': -10.0, 'speed': 1.3333333333333333, 'index': 0}, {'steering_angle': -10.0, 'speed': 2.6666666666666665, 'index': 1}, {'steering_angle': -10.0, 'speed': 4.0, 'index': 2}, {'steering_angle': -6.666666666666668, 'speed': 1.3333333333333333, 'index': 3}, {'steering_angle': -6.666666666666668, 'speed': 2.6666666666666665, 'index': 4}, {'steering_angle': -6.666666666666668, 'speed': 4.0, 'index': 5}, {'steering_angle': -3.333333333333335, 'speed': 1.3333333333333333, 'index': 6}, {'steering_angle': -3.333333333333335, 'speed': 2.6666666666666665, 'index': 7}, {'steering_angle': -3.333333333333335, 'speed': 4.0, 'index': 8}, {'steering_angle': 0.0, 'speed': 1.3333333333333333, 'index': 9}, {'steering_angle': 0.0, 'speed': 2.6666666666666665, 'index': 10}, {'steering_angle': 0.0, 'speed': 4.0, 'index': 11}, {'steering_angle': 3.333333333333332, 'speed': 1.3333333333333333, 'index': 12}, {'steering_angle': 3.333333333333332, 'speed': 2.6666666666666665, 'index': 13}, {'steering_angle': 3.333333333333332, 'speed': 4.0, 'index': 14}, {'steering_angle': 6.666666666666668, 'speed': 1.3333333333333333, 'index': 15}, {'steering_angle': 6.666666666666668, 'speed': 2.6666666666666665, 'index': 16}, {'steering_angle': 6.666666666666668, 'speed': 4.0, 'index': 17}, {'steering_angle': 10.0, 'speed': 1.3333333333333333, 'index': 18}, {'steering_angle': 10.0, 'speed': 2.6666666666666665, 'index': 19}, {'steering_angle': 10.0, 'speed': 4.0, 'index': 20}]
Using the following hyper-parameters
{
  "batch_size": 64,
  "beta_entropy": 0.01,
  "discount_factor": 0.999,
  "e_greedy_value": 1.0,
  "epsilon_steps": 10000,
  "exploration_type": "categorical",
  "loss_type": "huber",
  "lr": 0.0003,
  "num_episodes_between_training": 20,
  "num_epochs": 10,
  "stack_size": 1,
  "term_cond_avg_score": 100000.0,
  "term_cond_max_episodes": 100000
}
[s3] Successfully uploaded hyperparameters to                  s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/ip/hyperparameters.json.
Hostname: ip-10-0-86-100.ec2.internal
[s3] Successfully uploaded ip address to                  s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/ip/ip.json.
[s3] Successfully uploaded ip done to                  s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/ip/done.
## Creating graph - name: MultiAgentGraphManager
## Start physics before creating graph
## Create graph
## Creating agent - name: agent
[RL] Created agent loggers
[RL] Dynamic import of memory:  "DeepRacerMemoryParameters" {
    "load_memory_from_file_path": null,
    "max_size": [
        "<MemoryGranularity.Transitions: 0>",
        1000000
    ],
    "n_step": -1,
    "shared_memory": false,
    "train_to_eval_ratio": 1
}
[RL] Dynamically imported of memory <markov.memories.deepracer_memory.DeepRacerMemory object at 0x7fcb6ae7f4a8>
[RL] Setting devices
[RL] Setting filters
[RL] Setting filter devices: numpy
[RL] Setting Phase
[RL] After setting Phase
[RL] Setting signals
[RL] Agent init successful
[RL] ActorCriticAgent init
[RL] ActorCriticAgent  init successful
## Created agent: agent
## Stop physics after creating graph
## Creating session
2022-04-03 14:25:17.362195: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
INFO:tensorflow:./checkpoint_sagemaker/agent/0_Step-0.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/0_Step-0.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 0
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
Unable to find deepracer checkpoint json
Unable to find the best deepracer checkpoint number. Getting the last checkpoint number
Unable to find deepracer checkpoint json
Unable to find the last deepracer checkpoint number.
Unable to find deepracer checkpoint json
Unable to find the last deepracer checkpoint number.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_0.pb
Best checkpoint number: -1, Last checkpoint number: -1
Copying the frozen checkpoint from ./frozen_models/agent/model_0.pb to /opt/ml/model/agent/model.pb.
Unable to find deepracer checkpoint json
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
[s3] Successfully uploaded .ready to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.ready.
DoorMan: installing SIGINT, SIGTERM
Training> Name=main_level/agent, Worker=0, Episode=1, Total reward=0, Steps=50, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=2, Total reward=0, Steps=92, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=3, Total reward=0, Steps=111, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=4, Total reward=0, Steps=130, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=5, Total reward=0, Steps=156, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=6, Total reward=0, Steps=178, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=7, Total reward=0, Steps=202, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=8, Total reward=0, Steps=221, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=9, Total reward=0, Steps=241, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=10, Total reward=0, Steps=259, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=11, Total reward=0, Steps=284, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=12, Total reward=0, Steps=309, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=13, Total reward=0, Steps=329, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=14, Total reward=0, Steps=366, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=15, Total reward=0, Steps=397, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=16, Total reward=0, Steps=433, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=17, Total reward=0, Steps=463, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=18, Total reward=0, Steps=489, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=19, Total reward=0, Steps=512, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=20, Total reward=0, Steps=558, Training iteration=0
Policy training> Surrogate loss=0.014929104596376419, KL divergence=0.007749468088150024, Entropy=3.035829782485962, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.006507571786642075, KL divergence=0.00932384841144085, Entropy=3.035356283187866, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.04382607340812683, KL divergence=0.010850590653717518, Entropy=3.033794403076172, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.043035246431827545, KL divergence=0.013052891939878464, Entropy=3.0316548347473145, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.062917061150074, KL divergence=0.01693439669907093, Entropy=3.02797794342041, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.03212938457727432, KL divergence=0.008836561813950539, Entropy=3.0358898639678955, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.06541523337364197, KL divergence=0.014925745315849781, Entropy=3.0293631553649902, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.05114273726940155, KL divergence=0.014186909422278404, Entropy=3.030745029449463, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.07806909084320068, KL divergence=0.025910617783665657, Entropy=3.0189762115478516, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.07276329398155212, KL divergence=0.018775474280118942, Entropy=3.0258193016052246, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/1_Step-558.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/1_Step-558.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 1
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_1.pb
Best checkpoint number: 0, Last checkpoint number: 0
Copying the frozen checkpoint from ./frozen_models/agent/model_0.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Training> Name=main_level/agent, Worker=0, Episode=21, Total reward=0, Steps=605, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=22, Total reward=0, Steps=630, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=23, Total reward=0, Steps=648, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=24, Total reward=0, Steps=666, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=25, Total reward=0, Steps=689, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=26, Total reward=0, Steps=705, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=27, Total reward=0, Steps=733, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=28, Total reward=0, Steps=749, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=29, Total reward=0, Steps=770, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=30, Total reward=0, Steps=792, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=31, Total reward=0, Steps=813, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=32, Total reward=0, Steps=853, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=33, Total reward=0, Steps=882, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=34, Total reward=0, Steps=911, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=35, Total reward=0, Steps=943, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=36, Total reward=0, Steps=983, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=37, Total reward=0, Steps=1017, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=38, Total reward=0, Steps=1055, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=39, Total reward=0, Steps=1089, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=40, Total reward=0, Steps=1116, Training iteration=1
Policy training> Surrogate loss=0.016051992774009705, KL divergence=0.010958594270050526, Entropy=3.0253400802612305, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.014752380549907684, KL divergence=0.01799200102686882, Entropy=3.029330253601074, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.029367810115218163, KL divergence=0.01636309176683426, Entropy=3.0211620330810547, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.03330898657441139, KL divergence=0.021653300151228905, Entropy=3.0105793476104736, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.034329481422901154, KL divergence=0.01584031991660595, Entropy=3.0139613151550293, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.0707550048828125, KL divergence=0.014853094704449177, Entropy=3.0164854526519775, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.08638206869363785, KL divergence=0.021632973104715347, Entropy=3.002927780151367, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.10363636165857315, KL divergence=0.023226048797369003, Entropy=3.0050740242004395, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.12310585379600525, KL divergence=0.021491825580596924, Entropy=3.006789207458496, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.10884895920753479, KL divergence=0.026710592210292816, Entropy=2.9972996711730957, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/2_Step-1116.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/2_Step-1116.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 2
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_2.pb
Best checkpoint number: 0, Last checkpoint number: 0
Copying the frozen checkpoint from ./frozen_models/agent/model_0.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Training> Name=main_level/agent, Worker=0, Episode=41, Total reward=0, Steps=1157, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=42, Total reward=0, Steps=1180, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=43, Total reward=0, Steps=1202, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=44, Total reward=0, Steps=1221, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=45, Total reward=0, Steps=1246, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=46, Total reward=0, Steps=1265, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=47, Total reward=0, Steps=1290, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=48, Total reward=0, Steps=1310, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=49, Total reward=0, Steps=1346, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=50, Total reward=0, Steps=1383, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=51, Total reward=0, Steps=1402, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=52, Total reward=0, Steps=1425, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=53, Total reward=0, Steps=1448, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=54, Total reward=0, Steps=1468, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=55, Total reward=0, Steps=1532, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=56, Total reward=0, Steps=1564, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=57, Total reward=0, Steps=1588, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=58, Total reward=0, Steps=1619, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=59, Total reward=0, Steps=1640, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=60, Total reward=0, Steps=1668, Training iteration=2
Policy training> Surrogate loss=0.029858974739909172, KL divergence=0.01349329762160778, Entropy=2.9830715656280518, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.02703205682337284, KL divergence=0.013805124908685684, Entropy=3.007610321044922, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.077902652323246, KL divergence=0.027478236705064774, Entropy=2.9809699058532715, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.08331017941236496, KL divergence=0.021782465279102325, Entropy=2.985016345977783, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.08731012046337128, KL divergence=0.027376335114240646, Entropy=2.9661865234375, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.0996313989162445, KL divergence=0.02644873782992363, Entropy=2.9758200645446777, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.12462548911571503, KL divergence=0.03752797096967697, Entropy=2.956155300140381, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.10520786046981812, KL divergence=0.03128913417458534, Entropy=2.9682798385620117, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.11220114678144455, KL divergence=0.03691471740603447, Entropy=2.960210084915161, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.12366078794002533, KL divergence=0.03834482654929161, Entropy=2.957003116607666, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/3_Step-1668.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/3_Step-1668.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 3
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_3.pb
Best checkpoint number: 1, Last checkpoint number: 1
Copying the frozen checkpoint from ./frozen_models/agent/model_1.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Training> Name=main_level/agent, Worker=0, Episode=61, Total reward=0, Steps=1686, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=62, Total reward=0, Steps=1717, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=63, Total reward=0, Steps=1739, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=64, Total reward=0, Steps=1763, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=65, Total reward=0, Steps=1785, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=66, Total reward=0, Steps=1806, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=67, Total reward=0, Steps=1829, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=68, Total reward=0, Steps=1851, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=69, Total reward=0, Steps=1873, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=70, Total reward=0, Steps=1896, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=71, Total reward=0, Steps=1915, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=72, Total reward=0, Steps=1934, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=73, Total reward=0, Steps=1953, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=74, Total reward=0, Steps=1972, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=75, Total reward=0, Steps=1994, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=76, Total reward=0, Steps=2028, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=77, Total reward=0, Steps=2056, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=78, Total reward=0, Steps=2076, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=79, Total reward=0, Steps=2097, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=80, Total reward=0, Steps=2139, Training iteration=3
Policy training> Surrogate loss=0.022608352825045586, KL divergence=0.007853519171476364, Entropy=2.9616546630859375, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.028033435344696045, KL divergence=0.027146998792886734, Entropy=2.968651294708252, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.09019749611616135, KL divergence=0.022288335487246513, Entropy=2.939340829849243, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.09114934504032135, KL divergence=0.02979707345366478, Entropy=2.9186935424804688, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.11733289808034897, KL divergence=0.04484020918607712, Entropy=2.89026141166687, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.09745948016643524, KL divergence=0.04565814882516861, Entropy=2.9195191860198975, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.11683770269155502, KL divergence=0.044661108404397964, Entropy=2.91945481300354, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1255785971879959, KL divergence=0.04566134884953499, Entropy=2.916311740875244, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.11444427073001862, KL divergence=0.04806327447295189, Entropy=2.9071295261383057, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.10755264759063721, KL divergence=0.04553036019206047, Entropy=2.9033420085906982, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/4_Step-2139.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/4_Step-2139.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 4
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_4.pb
Best checkpoint number: 2, Last checkpoint number: 2
Copying the frozen checkpoint from ./frozen_models/agent/model_2.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'0'}
Training> Name=main_level/agent, Worker=0, Episode=81, Total reward=0, Steps=2165, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=82, Total reward=0, Steps=2191, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=83, Total reward=0, Steps=2210, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=84, Total reward=0, Steps=2236, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=85, Total reward=0, Steps=2268, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=86, Total reward=0, Steps=2286, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=87, Total reward=0, Steps=2309, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=88, Total reward=0, Steps=2354, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=89, Total reward=0, Steps=2377, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=90, Total reward=0, Steps=2427, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=91, Total reward=0, Steps=2451, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=92, Total reward=0, Steps=2475, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=93, Total reward=0, Steps=2497, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=94, Total reward=0, Steps=2524, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=95, Total reward=0, Steps=2550, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=96, Total reward=0, Steps=2598, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=97, Total reward=0, Steps=2643, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=98, Total reward=0, Steps=2705, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=99, Total reward=0, Steps=2735, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=100, Total reward=0, Steps=2791, Training iteration=4
Policy training> Surrogate loss=0.0010561138624325395, KL divergence=0.015391111373901367, Entropy=2.8919167518615723, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.04993617534637451, KL divergence=0.029319357126951218, Entropy=2.9119842052459717, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.08600988984107971, KL divergence=0.03757855296134949, Entropy=2.891139030456543, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.09980480372905731, KL divergence=0.03869425505399704, Entropy=2.905117988586426, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.11982736736536026, KL divergence=0.04273587092757225, Entropy=2.8707873821258545, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1224302425980568, KL divergence=0.04274363070726395, Entropy=2.8992583751678467, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13680598139762878, KL divergence=0.04685573652386665, Entropy=2.8843467235565186, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1317276805639267, KL divergence=0.06433934718370438, Entropy=2.8489489555358887, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.12286261469125748, KL divergence=0.049509722739458084, Entropy=2.896759510040283, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1494760811328888, KL divergence=0.06093255802989006, Entropy=2.871941089630127, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/5_Step-2791.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/5_Step-2791.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 5
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_5.pb
Best checkpoint number: 3, Last checkpoint number: 3
Copying the frozen checkpoint from ./frozen_models/agent/model_3.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'1'}
Training> Name=main_level/agent, Worker=0, Episode=101, Total reward=0, Steps=2842, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=102, Total reward=0, Steps=2888, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=103, Total reward=0, Steps=2909, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=104, Total reward=0, Steps=2934, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=105, Total reward=0, Steps=2959, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=106, Total reward=0, Steps=2978, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=107, Total reward=0, Steps=3003, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=108, Total reward=0, Steps=3026, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=109, Total reward=0, Steps=3078, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=110, Total reward=0, Steps=3104, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=111, Total reward=0, Steps=3131, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=112, Total reward=0, Steps=3163, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=113, Total reward=0, Steps=3186, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=114, Total reward=0, Steps=3228, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=115, Total reward=0, Steps=3250, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=116, Total reward=0, Steps=3275, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=117, Total reward=0, Steps=3311, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=118, Total reward=0, Steps=3344, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=119, Total reward=0, Steps=3395, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=120, Total reward=0, Steps=3417, Training iteration=5
Policy training> Surrogate loss=-0.006171794608235359, KL divergence=0.011297679506242275, Entropy=2.8833415508270264, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.024138713255524635, KL divergence=0.03229543939232826, Entropy=2.9000773429870605, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.07748313248157501, KL divergence=0.037501294165849686, Entropy=2.8360934257507324, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.07494334876537323, KL divergence=0.04421192780137062, Entropy=2.9215869903564453, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.11694979667663574, KL divergence=0.0669930949807167, Entropy=2.8124747276306152, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.10238942503929138, KL divergence=0.051374759525060654, Entropy=2.859003782272339, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13928619027137756, KL divergence=0.05082777515053749, Entropy=2.8560051918029785, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.15382875502109528, KL divergence=0.05709947645664215, Entropy=2.8272645473480225, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14599181711673737, KL divergence=0.05775275453925133, Entropy=2.829695701599121, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.11553578823804855, KL divergence=0.05819835886359215, Entropy=2.8481383323669434, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/6_Step-3417.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/6_Step-3417.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 6
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_6.pb
Best checkpoint number: 4, Last checkpoint number: 4
Copying the frozen checkpoint from ./frozen_models/agent/model_4.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'2'}
Training> Name=main_level/agent, Worker=0, Episode=121, Total reward=0, Steps=3454, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=122, Total reward=0, Steps=3515, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=123, Total reward=0, Steps=3572, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=124, Total reward=0, Steps=3608, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=125, Total reward=0, Steps=3639, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=126, Total reward=0, Steps=3658, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=127, Total reward=0, Steps=3681, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=128, Total reward=0, Steps=3706, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=129, Total reward=0, Steps=3730, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=130, Total reward=0, Steps=3762, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=131, Total reward=0, Steps=3783, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=132, Total reward=0, Steps=3828, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=133, Total reward=0, Steps=3875, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=134, Total reward=0, Steps=3906, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=135, Total reward=0, Steps=3925, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=136, Total reward=0, Steps=3958, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=137, Total reward=0, Steps=3992, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=138, Total reward=0, Steps=4035, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=139, Total reward=0, Steps=4058, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=140, Total reward=0, Steps=4085, Training iteration=6
Policy training> Surrogate loss=-0.0024299800861626863, KL divergence=0.01535152830183506, Entropy=2.8092305660247803, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08451012521982193, KL divergence=0.0447772853076458, Entropy=2.793903112411499, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1160900741815567, KL divergence=0.050399161875247955, Entropy=2.7808377742767334, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12542064487934113, KL divergence=0.04783366993069649, Entropy=2.7958273887634277, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.14623287320137024, KL divergence=0.05774847790598869, Entropy=2.7921090126037598, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.11982405185699463, KL divergence=0.05643995478749275, Entropy=2.7913269996643066, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.11752046644687653, KL divergence=0.05777861922979355, Entropy=2.7859880924224854, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1259291172027588, KL divergence=0.052956294268369675, Entropy=2.8046936988830566, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13966771960258484, KL divergence=0.05919387936592102, Entropy=2.7947890758514404, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13998815417289734, KL divergence=0.05589376017451286, Entropy=2.815103054046631, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/7_Step-4085.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/7_Step-4085.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 7
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_7.pb
Best checkpoint number: 4, Last checkpoint number: 5
Copying the frozen checkpoint from ./frozen_models/agent/model_4.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'3'}
Training> Name=main_level/agent, Worker=0, Episode=141, Total reward=0, Steps=4110, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=142, Total reward=0, Steps=4138, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=143, Total reward=0, Steps=4157, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=144, Total reward=0, Steps=4179, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=145, Total reward=0, Steps=4203, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=146, Total reward=0, Steps=4223, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=147, Total reward=0, Steps=4244, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=148, Total reward=0, Steps=4269, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=149, Total reward=0, Steps=4459, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=150, Total reward=0, Steps=4507, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=151, Total reward=0, Steps=4524, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=152, Total reward=0, Steps=4569, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=153, Total reward=0, Steps=4609, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=154, Total reward=0, Steps=4630, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=155, Total reward=0, Steps=4654, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=156, Total reward=0, Steps=4710, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=157, Total reward=0, Steps=4751, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=158, Total reward=0, Steps=4803, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=159, Total reward=0, Steps=4859, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=160, Total reward=0, Steps=4885, Training iteration=7
Policy training> Surrogate loss=0.02140066586434841, KL divergence=0.01909705437719822, Entropy=2.819681406021118, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.07843390852212906, KL divergence=0.03897591307759285, Entropy=2.743952512741089, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11194216459989548, KL divergence=0.054802194237709045, Entropy=2.7416887283325195, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.11329402774572372, KL divergence=0.05706055462360382, Entropy=2.719191312789917, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13907437026500702, KL divergence=0.05633139610290527, Entropy=2.7128846645355225, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14817874133586884, KL divergence=0.057638317346572876, Entropy=2.7287542819976807, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1402883380651474, KL divergence=0.067960724234581, Entropy=2.6955244541168213, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14669544994831085, KL divergence=0.06534087657928467, Entropy=2.7113616466522217, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.15707331895828247, KL divergence=0.06073577329516411, Entropy=2.735668182373047, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1765875220298767, KL divergence=0.07125142961740494, Entropy=2.6913509368896484, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/8_Step-4885.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/8_Step-4885.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 8
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_8.pb
Best checkpoint number: 6, Last checkpoint number: 6
Copying the frozen checkpoint from ./frozen_models/agent/model_6.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'4'}
Training> Name=main_level/agent, Worker=0, Episode=161, Total reward=0, Steps=4907, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=162, Total reward=0, Steps=4938, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=163, Total reward=0, Steps=4965, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=164, Total reward=0, Steps=4990, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=165, Total reward=0, Steps=5026, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=166, Total reward=0, Steps=5048, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=167, Total reward=0, Steps=5080, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=168, Total reward=0, Steps=5099, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=169, Total reward=0, Steps=5128, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=170, Total reward=0, Steps=5164, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=171, Total reward=0, Steps=5187, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=172, Total reward=0, Steps=5229, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=173, Total reward=0, Steps=5283, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=174, Total reward=0, Steps=5333, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=175, Total reward=0, Steps=5357, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=176, Total reward=0, Steps=5397, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=177, Total reward=0, Steps=5452, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=178, Total reward=0, Steps=5530, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=179, Total reward=0, Steps=5616, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=180, Total reward=0, Steps=5666, Training iteration=8
Policy training> Surrogate loss=0.01739572174847126, KL divergence=0.020451480522751808, Entropy=2.695586919784546, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08138169348239899, KL divergence=0.05386584997177124, Entropy=2.6871845722198486, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.10279536992311478, KL divergence=0.07644401490688324, Entropy=2.633157253265381, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.11835364252328873, KL divergence=0.06924746185541153, Entropy=2.6666548252105713, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12045794725418091, KL divergence=0.09200311452150345, Entropy=2.582913637161255, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13363389670848846, KL divergence=0.07042331248521805, Entropy=2.658599853515625, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13984178006649017, KL divergence=0.08011552691459656, Entropy=2.6423730850219727, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1430944949388504, KL divergence=0.07815231382846832, Entropy=2.6656546592712402, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13621920347213745, KL divergence=0.08163417875766754, Entropy=2.6427128314971924, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14069412648677826, KL divergence=0.08164283633232117, Entropy=2.6475093364715576, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/9_Step-5666.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/9_Step-5666.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 9
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_9.pb
Best checkpoint number: 6, Last checkpoint number: 7
Copying the frozen checkpoint from ./frozen_models/agent/model_6.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'5'}
Training> Name=main_level/agent, Worker=0, Episode=181, Total reward=0, Steps=5727, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=182, Total reward=0, Steps=5758, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=183, Total reward=0, Steps=5781, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=184, Total reward=0, Steps=5802, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=185, Total reward=0, Steps=5832, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=186, Total reward=0, Steps=5851, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=187, Total reward=0, Steps=5888, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=188, Total reward=0, Steps=5954, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=189, Total reward=0, Steps=6009, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=190, Total reward=0, Steps=6045, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=191, Total reward=0, Steps=6094, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=192, Total reward=0, Steps=6114, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=193, Total reward=0, Steps=6148, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=194, Total reward=0, Steps=6180, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=195, Total reward=0, Steps=6244, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=196, Total reward=0, Steps=6290, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=197, Total reward=0, Steps=6317, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=198, Total reward=0, Steps=6363, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=199, Total reward=0, Steps=6389, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=200, Total reward=0, Steps=6413, Training iteration=9
Policy training> Surrogate loss=-0.0018931952072307467, KL divergence=0.01603461429476738, Entropy=2.600118398666382, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.06206005439162254, KL divergence=0.04987640678882599, Entropy=2.560779571533203, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.08735892176628113, KL divergence=0.04953942075371742, Entropy=2.6048147678375244, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.11770574748516083, KL divergence=0.06107267364859581, Entropy=2.5522587299346924, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12724310159683228, KL divergence=0.06714367121458054, Entropy=2.548748016357422, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.12814481556415558, KL divergence=0.0675978809595108, Entropy=2.538520574569702, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.12760843336582184, KL divergence=0.06329620629549026, Entropy=2.5568370819091797, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13432355225086212, KL divergence=0.08065349608659744, Entropy=2.5033011436462402, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13942427933216095, KL divergence=0.06772584468126297, Entropy=2.585153579711914, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14039848744869232, KL divergence=0.09158608317375183, Entropy=2.477877616882324, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/10_Step-6413.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/10_Step-6413.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 10
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_10.pb
Best checkpoint number: 6, Last checkpoint number: 8
Copying the frozen checkpoint from ./frozen_models/agent/model_6.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'7'}
Training> Name=main_level/agent, Worker=0, Episode=201, Total reward=0, Steps=6448, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=202, Total reward=0, Steps=6471, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=203, Total reward=0, Steps=6505, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=204, Total reward=0, Steps=6532, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=205, Total reward=0, Steps=6565, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=206, Total reward=0, Steps=6585, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=207, Total reward=0, Steps=6617, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=208, Total reward=0, Steps=6692, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=209, Total reward=0, Steps=6721, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=210, Total reward=0, Steps=6753, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=211, Total reward=0, Steps=6793, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=212, Total reward=0, Steps=6815, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=213, Total reward=0, Steps=6870, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=214, Total reward=0, Steps=6987, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=215, Total reward=0, Steps=7030, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=216, Total reward=0, Steps=7084, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=217, Total reward=0, Steps=7173, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=218, Total reward=0, Steps=7242, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=219, Total reward=0, Steps=7316, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=220, Total reward=0, Steps=7349, Training iteration=10
Policy training> Surrogate loss=0.0077559067867696285, KL divergence=0.01510006282478571, Entropy=2.637810230255127, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.06739617884159088, KL divergence=0.06052301451563835, Entropy=2.6007437705993652, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.09606010466814041, KL divergence=0.05967675894498825, Entropy=2.627685785293579, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12692318856716156, KL divergence=0.06292694061994553, Entropy=2.5781614780426025, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.14202408492565155, KL divergence=0.062199950218200684, Entropy=2.622399091720581, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1437610238790512, KL divergence=0.06561632454395294, Entropy=2.60957407951355, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13639408349990845, KL divergence=0.067048080265522, Entropy=2.6551930904388428, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14042170345783234, KL divergence=0.07092474400997162, Entropy=2.5975117683410645, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14110822975635529, KL divergence=0.06809107959270477, Entropy=2.634866237640381, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13556639850139618, KL divergence=0.07085921615362167, Entropy=2.6189992427825928, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/11_Step-7349.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/11_Step-7349.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 11
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_11.pb
Best checkpoint number: 6, Last checkpoint number: 9
Copying the frozen checkpoint from ./frozen_models/agent/model_6.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'8'}
Training> Name=main_level/agent, Worker=0, Episode=221, Total reward=0, Steps=7369, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=222, Total reward=0, Steps=7407, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=223, Total reward=0, Steps=7449, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=224, Total reward=0, Steps=7491, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=225, Total reward=0, Steps=7546, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=226, Total reward=0, Steps=7562, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=227, Total reward=0, Steps=7588, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=228, Total reward=0, Steps=7638, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=229, Total reward=0, Steps=7668, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=230, Total reward=0, Steps=7706, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=231, Total reward=0, Steps=7792, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=232, Total reward=0, Steps=7816, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=233, Total reward=0, Steps=7838, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=234, Total reward=0, Steps=7857, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=235, Total reward=0, Steps=7897, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=236, Total reward=0, Steps=7945, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=237, Total reward=0, Steps=7981, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=238, Total reward=0, Steps=8003, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=239, Total reward=0, Steps=8091, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=240, Total reward=0, Steps=8126, Training iteration=11
Policy training> Surrogate loss=0.010199171490967274, KL divergence=0.011829887516796589, Entropy=2.641916275024414, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08798613399267197, KL divergence=0.052485961467027664, Entropy=2.6675140857696533, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.10972265154123306, KL divergence=0.06560438126325607, Entropy=2.5781502723693848, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12777073681354523, KL divergence=0.07448842376470566, Entropy=2.5997421741485596, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13443318009376526, KL divergence=0.07258688658475876, Entropy=2.593343496322632, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13652607798576355, KL divergence=0.06894853711128235, Entropy=2.6074697971343994, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13855718076229095, KL divergence=0.06631199270486832, Entropy=2.6108245849609375, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13500303030014038, KL divergence=0.07068147510290146, Entropy=2.626180410385132, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13448020815849304, KL divergence=0.07590659707784653, Entropy=2.589430332183838, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13998819887638092, KL divergence=0.07083109766244888, Entropy=2.6141622066497803, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/12_Step-8126.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/12_Step-8126.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 12
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_12.pb
Best checkpoint number: 6, Last checkpoint number: 10
Copying the frozen checkpoint from ./frozen_models/agent/model_6.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'9'}
Training> Name=main_level/agent, Worker=0, Episode=241, Total reward=0, Steps=8167, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=242, Total reward=0, Steps=8201, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=243, Total reward=0, Steps=8241, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=244, Total reward=0, Steps=8273, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=245, Total reward=0, Steps=8302, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=246, Total reward=0, Steps=8323, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=247, Total reward=0, Steps=8344, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=248, Total reward=0, Steps=8382, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=249, Total reward=0, Steps=8410, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=250, Total reward=0, Steps=8440, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=251, Total reward=0, Steps=8459, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=252, Total reward=0, Steps=8496, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=253, Total reward=0, Steps=8515, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=254, Total reward=0, Steps=8550, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=255, Total reward=0, Steps=8629, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=256, Total reward=0, Steps=8739, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=257, Total reward=0, Steps=8779, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=258, Total reward=0, Steps=8804, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=259, Total reward=0, Steps=8831, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=260, Total reward=0, Steps=8860, Training iteration=12
Policy training> Surrogate loss=0.007050864864140749, KL divergence=0.017999669536948204, Entropy=2.5665957927703857, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.07916957885026932, KL divergence=0.058932844549417496, Entropy=2.5873241424560547, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.10521779209375381, KL divergence=0.07109255343675613, Entropy=2.5284276008605957, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13380828499794006, KL divergence=0.07200951129198074, Entropy=2.5272109508514404, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12296132743358612, KL divergence=0.06777110695838928, Entropy=2.5692427158355713, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.12849494814872742, KL divergence=0.06822112202644348, Entropy=2.553054094314575, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13096852600574493, KL divergence=0.0703936293721199, Entropy=2.5470759868621826, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14574307203292847, KL divergence=0.061710719019174576, Entropy=2.591118335723877, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13429950177669525, KL divergence=0.07182275503873825, Entropy=2.5232200622558594, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13329018652439117, KL divergence=0.06551390141248703, Entropy=2.5798120498657227, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/13_Step-8860.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/13_Step-8860.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 13
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_13.pb
Best checkpoint number: 6, Last checkpoint number: 11
Copying the frozen checkpoint from ./frozen_models/agent/model_6.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'10'}
Training> Name=main_level/agent, Worker=0, Episode=261, Total reward=0, Steps=8883, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=262, Total reward=0, Steps=8913, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=263, Total reward=0, Steps=8935, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=264, Total reward=0, Steps=8955, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=265, Total reward=0, Steps=8989, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=266, Total reward=0, Steps=9011, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=267, Total reward=0, Steps=9057, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=268, Total reward=0, Steps=9076, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=269, Total reward=0, Steps=9126, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=270, Total reward=0, Steps=9163, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=271, Total reward=0, Steps=9211, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=272, Total reward=0, Steps=9252, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=273, Total reward=0, Steps=9287, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=274, Total reward=0, Steps=9331, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=275, Total reward=0, Steps=9393, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=276, Total reward=0, Steps=9444, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=277, Total reward=0, Steps=9477, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=278, Total reward=0, Steps=9559, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=279, Total reward=0, Steps=9582, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=280, Total reward=0, Steps=9628, Training iteration=13
Policy training> Surrogate loss=0.010399955324828625, KL divergence=0.012901410460472107, Entropy=2.6620194911956787, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.07000777870416641, KL divergence=0.06742040812969208, Entropy=2.4945764541625977, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.10562234371900558, KL divergence=0.04884148761630058, Entropy=2.617178440093994, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.11935597658157349, KL divergence=0.06360381841659546, Entropy=2.547515630722046, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.127818301320076, KL divergence=0.05821185186505318, Entropy=2.573155641555786, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13229350745677948, KL divergence=0.06024444103240967, Entropy=2.5793962478637695, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13533930480480194, KL divergence=0.0620567686855793, Entropy=2.560929298400879, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13661523163318634, KL divergence=0.05995090678334236, Entropy=2.575853109359741, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1372213214635849, KL divergence=0.05777161195874214, Entropy=2.588663101196289, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13815142214298248, KL divergence=0.0568900890648365, Entropy=2.589176893234253, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/14_Step-9628.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/14_Step-9628.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 14
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_14.pb
Best checkpoint number: 6, Last checkpoint number: 12
Copying the frozen checkpoint from ./frozen_models/agent/model_6.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'11'}
Training> Name=main_level/agent, Worker=0, Episode=281, Total reward=0, Steps=9670, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=282, Total reward=0, Steps=9707, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=283, Total reward=0, Steps=9760, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=284, Total reward=0, Steps=9789, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=285, Total reward=0, Steps=9813, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=286, Total reward=0, Steps=9831, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=287, Total reward=0, Steps=9862, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=288, Total reward=0, Steps=9895, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=289, Total reward=0, Steps=9953, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=290, Total reward=0, Steps=10012, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=291, Total reward=0, Steps=10031, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=292, Total reward=0, Steps=10070, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=293, Total reward=0, Steps=10102, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=294, Total reward=0, Steps=10144, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=295, Total reward=0, Steps=10272, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=296, Total reward=0, Steps=10360, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=297, Total reward=0, Steps=10417, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=298, Total reward=0, Steps=10481, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=299, Total reward=0, Steps=10531, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=300, Total reward=0, Steps=10552, Training iteration=14
Policy training> Surrogate loss=0.017176775261759758, KL divergence=0.022371390834450722, Entropy=2.495330333709717, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.0927359089255333, KL divergence=0.05059627443552017, Entropy=2.545081853866577, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11157762259244919, KL divergence=0.0636148676276207, Entropy=2.538545846939087, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12338662147521973, KL divergence=0.08556618541479111, Entropy=2.4684033393859863, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13847610354423523, KL divergence=0.07319144159555435, Entropy=2.513148069381714, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13731379806995392, KL divergence=0.07153553515672684, Entropy=2.4995346069335938, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13424669206142426, KL divergence=0.07155948877334595, Entropy=2.546243667602539, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1399451494216919, KL divergence=0.08166452497243881, Entropy=2.4670708179473877, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14931489527225494, KL divergence=0.06875120848417282, Entropy=2.5423758029937744, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.12700910866260529, KL divergence=0.07922639697790146, Entropy=2.5035033226013184, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/15_Step-10552.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/15_Step-10552.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 15
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_15.pb
Best checkpoint number: 6, Last checkpoint number: 13
Copying the frozen checkpoint from ./frozen_models/agent/model_6.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'12'}
Training> Name=main_level/agent, Worker=0, Episode=301, Total reward=0, Steps=10573, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=302, Total reward=0, Steps=10593, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=303, Total reward=0, Steps=10612, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=304, Total reward=0, Steps=10654, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=305, Total reward=0, Steps=10671, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=306, Total reward=0, Steps=10696, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=307, Total reward=0, Steps=10746, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=308, Total reward=0, Steps=10816, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=309, Total reward=0, Steps=10862, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=310, Total reward=0, Steps=10929, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=311, Total reward=0, Steps=10991, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=312, Total reward=0, Steps=11023, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=313, Total reward=0, Steps=11063, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=314, Total reward=0, Steps=11089, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=315, Total reward=0, Steps=11156, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=316, Total reward=0, Steps=11217, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=317, Total reward=0, Steps=11251, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=318, Total reward=0, Steps=11338, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=319, Total reward=0, Steps=11370, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=320, Total reward=0, Steps=11417, Training iteration=15
Policy training> Surrogate loss=0.012581348419189453, KL divergence=0.024198610335588455, Entropy=2.4359593391418457, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.06921713054180145, KL divergence=0.05586988478899002, Entropy=2.4863412380218506, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.10554923117160797, KL divergence=0.06952457875013351, Entropy=2.4436590671539307, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12161891162395477, KL divergence=0.06796100735664368, Entropy=2.465644598007202, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13249538838863373, KL divergence=0.07453671097755432, Entropy=2.4417378902435303, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13104663789272308, KL divergence=0.07114314287900925, Entropy=2.4474048614501953, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13461916148662567, KL divergence=0.06838473677635193, Entropy=2.469571352005005, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14036737382411957, KL divergence=0.07333463430404663, Entropy=2.4311683177948, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.11620577424764633, KL divergence=0.06711091101169586, Entropy=2.472721576690674, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.12733975052833557, KL divergence=0.06703770905733109, Entropy=2.483621120452881, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/16_Step-11417.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/16_Step-11417.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 16
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_16.pb
Best checkpoint number: 6, Last checkpoint number: 14
Copying the frozen checkpoint from ./frozen_models/agent/model_6.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'13'}
Training> Name=main_level/agent, Worker=0, Episode=321, Total reward=0, Steps=11490, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=322, Total reward=0, Steps=11524, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=323, Total reward=0, Steps=11543, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=324, Total reward=0, Steps=11562, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=325, Total reward=0, Steps=11591, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=326, Total reward=0, Steps=11616, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=327, Total reward=0, Steps=11635, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=328, Total reward=0, Steps=11668, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=329, Total reward=0, Steps=11691, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=330, Total reward=0, Steps=11737, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=331, Total reward=0, Steps=11791, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=332, Total reward=0, Steps=11888, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=333, Total reward=0, Steps=11934, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=334, Total reward=0, Steps=11969, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=335, Total reward=0, Steps=12030, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=336, Total reward=0, Steps=12062, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=337, Total reward=0, Steps=12107, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=338, Total reward=0, Steps=12131, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=339, Total reward=0, Steps=12157, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=340, Total reward=0, Steps=12219, Training iteration=16
Policy training> Surrogate loss=0.02381843887269497, KL divergence=0.02935202419757843, Entropy=2.405769109725952, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.07284284383058548, KL divergence=0.04395047202706337, Entropy=2.493004560470581, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.09911371022462845, KL divergence=0.087064228951931, Entropy=2.3312370777130127, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12449517101049423, KL divergence=0.061458561569452286, Entropy=2.474261999130249, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.14808201789855957, KL divergence=0.07329118251800537, Entropy=2.3969576358795166, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1249086856842041, KL divergence=0.06323578208684921, Entropy=2.4763667583465576, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13491986691951752, KL divergence=0.08163082599639893, Entropy=2.3612258434295654, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13487787544727325, KL divergence=0.06771072000265121, Entropy=2.448035478591919, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.12762828171253204, KL divergence=0.0738130435347557, Entropy=2.436359167098999, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13050000369548798, KL divergence=0.06927832216024399, Entropy=2.4744975566864014, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/17_Step-12219.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/17_Step-12219.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 17
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_17.pb
Best checkpoint number: 15, Last checkpoint number: 15
Copying the frozen checkpoint from ./frozen_models/agent/model_15.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'14'}
Training> Name=main_level/agent, Worker=0, Episode=341, Total reward=0, Steps=12286, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=342, Total reward=0, Steps=12324, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=343, Total reward=0, Steps=12348, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=344, Total reward=0, Steps=12392, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=345, Total reward=0, Steps=12424, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=346, Total reward=0, Steps=12445, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=347, Total reward=0, Steps=12534, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=348, Total reward=0, Steps=12576, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=349, Total reward=0, Steps=12606, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=350, Total reward=0, Steps=12650, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=351, Total reward=0, Steps=12674, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=352, Total reward=0, Steps=12699, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=353, Total reward=0, Steps=12744, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=354, Total reward=0, Steps=12789, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=355, Total reward=0, Steps=12841, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=356, Total reward=0, Steps=12876, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=357, Total reward=0, Steps=12950, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=358, Total reward=0, Steps=12983, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=359, Total reward=0, Steps=13005, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=360, Total reward=0, Steps=13032, Training iteration=17
Policy training> Surrogate loss=0.0011673277476802468, KL divergence=0.020231928676366806, Entropy=2.404034376144409, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.1026366725564003, KL divergence=0.038115523755550385, Entropy=2.4448935985565186, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1100131943821907, KL divergence=0.06107552349567413, Entropy=2.3710837364196777, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12967149913311005, KL divergence=0.06809977442026138, Entropy=2.4181482791900635, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1192149817943573, KL divergence=0.07133125513792038, Entropy=2.4019100666046143, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14269396662712097, KL divergence=0.07806128263473511, Entropy=2.3990676403045654, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.12379691004753113, KL divergence=0.07458236068487167, Entropy=2.414813756942749, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.12463370710611343, KL divergence=0.07687251269817352, Entropy=2.4157485961914062, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1324780136346817, KL divergence=0.07534763962030411, Entropy=2.4438679218292236, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13801229000091553, KL divergence=0.07753884792327881, Entropy=2.45438289642334, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/18_Step-13032.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/18_Step-13032.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 18
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_18.pb
Best checkpoint number: 15, Last checkpoint number: 16
Copying the frozen checkpoint from ./frozen_models/agent/model_15.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'6'}
Training> Name=main_level/agent, Worker=0, Episode=361, Total reward=0, Steps=13076, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=362, Total reward=0, Steps=13119, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=363, Total reward=0, Steps=13189, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=364, Total reward=0, Steps=13234, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=365, Total reward=0, Steps=13273, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=366, Total reward=0, Steps=13316, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=367, Total reward=0, Steps=13352, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=368, Total reward=0, Steps=13385, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=369, Total reward=0, Steps=13476, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=370, Total reward=0, Steps=13513, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=371, Total reward=0, Steps=13536, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=372, Total reward=0, Steps=13608, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=373, Total reward=0, Steps=13660, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=374, Total reward=0, Steps=13680, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=375, Total reward=0, Steps=13760, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=376, Total reward=0, Steps=13795, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=377, Total reward=0, Steps=13872, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=378, Total reward=0, Steps=13926, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=379, Total reward=0, Steps=13966, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=380, Total reward=0, Steps=14049, Training iteration=18
Policy training> Surrogate loss=0.008854459971189499, KL divergence=0.02602291852235794, Entropy=2.3963232040405273, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.06462351977825165, KL divergence=0.07331681251525879, Entropy=2.3410000801086426, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.10416272282600403, KL divergence=0.06746018677949905, Entropy=2.3635849952697754, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.11366704851388931, KL divergence=0.07281195372343063, Entropy=2.34012770652771, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13784733414649963, KL divergence=0.07962281256914139, Entropy=2.33315110206604, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1355515867471695, KL divergence=0.08305288851261139, Entropy=2.3238186836242676, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13421259820461273, KL divergence=0.07943494617938995, Entropy=2.353346347808838, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1374024599790573, KL divergence=0.08445978909730911, Entropy=2.339489459991455, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13736489415168762, KL divergence=0.08741078525781631, Entropy=2.342698574066162, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13621404767036438, KL divergence=0.08398471772670746, Entropy=2.348845958709717, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/19_Step-14049.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/19_Step-14049.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 19
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_19.pb
Best checkpoint number: 17, Last checkpoint number: 17
Copying the frozen checkpoint from ./frozen_models/agent/model_17.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'15'}
Training> Name=main_level/agent, Worker=0, Episode=381, Total reward=0, Steps=14090, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=382, Total reward=0, Steps=14146, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=383, Total reward=0, Steps=14210, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=384, Total reward=0, Steps=14257, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=385, Total reward=0, Steps=14287, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=386, Total reward=0, Steps=14303, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=387, Total reward=0, Steps=14337, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=388, Total reward=0, Steps=14471, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=389, Total reward=0, Steps=14521, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=390, Total reward=0, Steps=14563, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=391, Total reward=0, Steps=14803, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=392, Total reward=0, Steps=14842, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=393, Total reward=0, Steps=14884, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=394, Total reward=0, Steps=14910, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=395, Total reward=0, Steps=14976, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=396, Total reward=0, Steps=15001, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=397, Total reward=0, Steps=15065, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=398, Total reward=0, Steps=15156, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=399, Total reward=0, Steps=15186, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=400, Total reward=0, Steps=15271, Training iteration=19
Policy training> Surrogate loss=0.011983269825577736, KL divergence=0.028345374390482903, Entropy=2.3569576740264893, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.06539992988109589, KL divergence=0.07574537396430969, Entropy=2.424886703491211, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1152789443731308, KL divergence=0.06714412569999695, Entropy=2.3964226245880127, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1366315633058548, KL divergence=0.0687098279595375, Entropy=2.366987466812134, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.14059652388095856, KL divergence=0.0718119665980339, Entropy=2.3452816009521484, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14512832462787628, KL divergence=0.07098181545734406, Entropy=2.376654624938965, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.14928558468818665, KL divergence=0.07757740467786789, Entropy=2.337059497833252, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.15121057629585266, KL divergence=0.07362855970859528, Entropy=2.3711700439453125, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.15244685113430023, KL divergence=0.07479357719421387, Entropy=2.371001720428467, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.15393519401550293, KL divergence=0.0725964680314064, Entropy=2.3757712841033936, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/20_Step-15271.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/20_Step-15271.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 20
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_20.pb
Best checkpoint number: 17, Last checkpoint number: 18
Copying the frozen checkpoint from ./frozen_models/agent/model_17.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'16'}
Training> Name=main_level/agent, Worker=0, Episode=401, Total reward=0, Steps=15357, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=402, Total reward=0, Steps=15416, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=403, Total reward=0, Steps=15472, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=404, Total reward=0, Steps=15520, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=405, Total reward=0, Steps=15539, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=406, Total reward=0, Steps=15556, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=407, Total reward=0, Steps=15589, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=408, Total reward=0, Steps=15641, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=409, Total reward=0, Steps=15677, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=410, Total reward=0, Steps=15818, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=411, Total reward=0, Steps=15850, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=412, Total reward=0, Steps=15942, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=413, Total reward=0, Steps=16024, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=414, Total reward=0, Steps=16057, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=415, Total reward=0, Steps=16089, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=416, Total reward=0, Steps=16128, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=417, Total reward=0, Steps=16194, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=418, Total reward=0, Steps=16220, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=419, Total reward=0, Steps=16299, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=420, Total reward=0, Steps=16349, Training iteration=20
Policy training> Surrogate loss=0.026761502027511597, KL divergence=0.023987358435988426, Entropy=2.4060027599334717, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09004565328359604, KL divergence=0.06257610023021698, Entropy=2.4076433181762695, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1089029535651207, KL divergence=0.07740715146064758, Entropy=2.3925657272338867, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13492430746555328, KL divergence=0.07687794417142868, Entropy=2.3965821266174316, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1304626762866974, KL divergence=0.0764230340719223, Entropy=2.430561065673828, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.12337467074394226, KL divergence=0.08276224136352539, Entropy=2.4039409160614014, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13085883855819702, KL divergence=0.07841640710830688, Entropy=2.4398114681243896, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13116927444934845, KL divergence=0.07891940325498581, Entropy=2.407557487487793, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.15185609459877014, KL divergence=0.07935830950737, Entropy=2.464928150177002, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14116977155208588, KL divergence=0.08070259541273117, Entropy=2.448936939239502, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/21_Step-16349.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/21_Step-16349.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 21
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_21.pb
Best checkpoint number: 17, Last checkpoint number: 19
Copying the frozen checkpoint from ./frozen_models/agent/model_17.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'18'}
Training> Name=main_level/agent, Worker=0, Episode=421, Total reward=0, Steps=16374, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=422, Total reward=0, Steps=16464, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=423, Total reward=0, Steps=16505, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=424, Total reward=0, Steps=16524, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=425, Total reward=0, Steps=16555, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=426, Total reward=0, Steps=16574, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=427, Total reward=0, Steps=16604, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=428, Total reward=0, Steps=16779, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=429, Total reward=0, Steps=16855, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=430, Total reward=0, Steps=16894, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=431, Total reward=0, Steps=16929, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=432, Total reward=0, Steps=17018, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=433, Total reward=0, Steps=17092, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=434, Total reward=0, Steps=17112, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=435, Total reward=0, Steps=17194, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=436, Total reward=0, Steps=17275, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=437, Total reward=0, Steps=17318, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=438, Total reward=0, Steps=17395, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=439, Total reward=0, Steps=17506, Training iteration=21
Training> Name=main_level/agent, Worker=0, Episode=440, Total reward=0, Steps=17537, Training iteration=21
Policy training> Surrogate loss=0.022103194147348404, KL divergence=0.022370167076587677, Entropy=2.4755072593688965, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.0881047323346138, KL divergence=0.061177875846624374, Entropy=2.4476571083068848, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.13110727071762085, KL divergence=0.08430591225624084, Entropy=2.3715975284576416, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13480572402477264, KL divergence=0.08220009505748749, Entropy=2.3925161361694336, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13460710644721985, KL divergence=0.07921009510755539, Entropy=2.388813018798828, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13227616250514984, KL divergence=0.08235529810190201, Entropy=2.3874905109405518, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.14418309926986694, KL divergence=0.08182190358638763, Entropy=2.369072675704956, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1371515840291977, KL divergence=0.07563021034002304, Entropy=2.4028594493865967, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13928189873695374, KL divergence=0.07195627689361572, Entropy=2.422161102294922, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1410018801689148, KL divergence=0.07867070287466049, Entropy=2.3966970443725586, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/22_Step-17537.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/22_Step-17537.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 22
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_22.pb
Best checkpoint number: 17, Last checkpoint number: 20
Copying the frozen checkpoint from ./frozen_models/agent/model_17.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'19'}
Training> Name=main_level/agent, Worker=0, Episode=441, Total reward=0, Steps=17593, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=442, Total reward=0, Steps=17654, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=443, Total reward=0, Steps=17699, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=444, Total reward=0, Steps=17743, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=445, Total reward=0, Steps=17792, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=446, Total reward=0, Steps=17814, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=447, Total reward=0, Steps=17860, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=448, Total reward=0, Steps=18077, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=449, Total reward=0, Steps=18135, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=450, Total reward=0, Steps=18200, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=451, Total reward=0, Steps=18267, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=452, Total reward=0, Steps=18311, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=453, Total reward=0, Steps=18369, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=454, Total reward=0, Steps=18441, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=455, Total reward=0, Steps=18593, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=456, Total reward=0, Steps=18661, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=457, Total reward=0, Steps=18702, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=458, Total reward=0, Steps=18749, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=459, Total reward=0, Steps=18847, Training iteration=22
Training> Name=main_level/agent, Worker=0, Episode=460, Total reward=0, Steps=18878, Training iteration=22
Policy training> Surrogate loss=0.02663635089993477, KL divergence=0.02121562324464321, Entropy=2.4359917640686035, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09153630584478378, KL divergence=0.06277617812156677, Entropy=2.438880443572998, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11061837524175644, KL divergence=0.061790209263563156, Entropy=2.4491922855377197, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13125079870224, KL divergence=0.06641526520252228, Entropy=2.406059980392456, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1351604461669922, KL divergence=0.061783887445926666, Entropy=2.4299731254577637, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14897476136684418, KL divergence=0.0653626099228859, Entropy=2.4118380546569824, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.15135502815246582, KL divergence=0.06315167248249054, Entropy=2.4392330646514893, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.15018948912620544, KL divergence=0.06511465460062027, Entropy=2.432936191558838, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14283666014671326, KL divergence=0.061760611832141876, Entropy=2.450087308883667, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14445343613624573, KL divergence=0.06650672852993011, Entropy=2.4180331230163574, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/23_Step-18878.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/23_Step-18878.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 23
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_23.pb
Best checkpoint number: 17, Last checkpoint number: 21
Copying the frozen checkpoint from ./frozen_models/agent/model_17.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'20'}
Training> Name=main_level/agent, Worker=0, Episode=461, Total reward=0, Steps=18934, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=462, Total reward=0, Steps=18977, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=463, Total reward=0, Steps=19011, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=464, Total reward=0, Steps=19044, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=465, Total reward=0, Steps=19072, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=466, Total reward=0, Steps=19144, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=467, Total reward=0, Steps=19376, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=468, Total reward=0, Steps=19434, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=469, Total reward=0, Steps=19473, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=470, Total reward=0, Steps=19506, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=471, Total reward=0, Steps=19553, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=472, Total reward=0, Steps=19583, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=473, Total reward=0, Steps=19642, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=474, Total reward=0, Steps=19729, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=475, Total reward=0, Steps=19768, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=476, Total reward=0, Steps=19793, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=477, Total reward=0, Steps=19840, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=478, Total reward=0, Steps=19883, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=479, Total reward=0, Steps=19908, Training iteration=23
Training> Name=main_level/agent, Worker=0, Episode=480, Total reward=0, Steps=19996, Training iteration=23
Policy training> Surrogate loss=0.011562855914235115, KL divergence=0.030162950977683067, Entropy=2.3537027835845947, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08924980461597443, KL divergence=0.09058067202568054, Entropy=2.2012434005737305, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.10960235446691513, KL divergence=0.07255123555660248, Entropy=2.308523654937744, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13409817218780518, KL divergence=0.08744173496961594, Entropy=2.2329084873199463, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13560187816619873, KL divergence=0.07738770544528961, Entropy=2.308712959289551, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14224083721637726, KL divergence=0.08535396307706833, Entropy=2.2678728103637695, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.14702542126178741, KL divergence=0.07861577719449997, Entropy=2.316579818725586, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.15368607640266418, KL divergence=0.08563012629747391, Entropy=2.27590274810791, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.15142139792442322, KL divergence=0.08084703981876373, Entropy=2.309175968170166, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14745232462882996, KL divergence=0.0788196548819542, Entropy=2.3307905197143555, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/24_Step-19996.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/24_Step-19996.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 24
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_24.pb
Best checkpoint number: 17, Last checkpoint number: 22
Copying the frozen checkpoint from ./frozen_models/agent/model_17.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'21'}
Training> Name=main_level/agent, Worker=0, Episode=481, Total reward=0, Steps=20044, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=482, Total reward=0, Steps=20062, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=483, Total reward=0, Steps=20124, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=484, Total reward=0, Steps=20170, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=485, Total reward=0, Steps=20193, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=486, Total reward=0, Steps=20217, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=487, Total reward=0, Steps=20306, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=488, Total reward=0, Steps=20385, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=489, Total reward=0, Steps=20450, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=490, Total reward=0, Steps=20482, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=491, Total reward=0, Steps=20534, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=492, Total reward=0, Steps=20600, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=493, Total reward=0, Steps=20730, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=494, Total reward=0, Steps=20866, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=495, Total reward=0, Steps=20929, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=496, Total reward=0, Steps=20980, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=497, Total reward=0, Steps=21041, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=498, Total reward=0, Steps=21104, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=499, Total reward=0, Steps=21186, Training iteration=24
Training> Name=main_level/agent, Worker=0, Episode=500, Total reward=0, Steps=21234, Training iteration=24
Policy training> Surrogate loss=0.00932901632040739, KL divergence=0.02482399344444275, Entropy=2.400360345840454, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08967210352420807, KL divergence=0.07923844456672668, Entropy=2.3860392570495605, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11770263314247131, KL divergence=0.09453142434358597, Entropy=2.3241488933563232, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12862694263458252, KL divergence=0.08092699199914932, Entropy=2.373985767364502, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13639402389526367, KL divergence=0.08553481847047806, Entropy=2.3404762744903564, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13937297463417053, KL divergence=0.08087485283613205, Entropy=2.356154441833496, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.14488519728183746, KL divergence=0.0801958441734314, Entropy=2.3559114933013916, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13805381953716278, KL divergence=0.07963047176599503, Entropy=2.3696701526641846, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14443090558052063, KL divergence=0.0780852660536766, Entropy=2.3840441703796387, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14279980957508087, KL divergence=0.07727983593940735, Entropy=2.394253969192505, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/25_Step-21234.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/25_Step-21234.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 25
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_25.pb
Best checkpoint number: 17, Last checkpoint number: 23
Copying the frozen checkpoint from ./frozen_models/agent/model_17.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'22'}
Training> Name=main_level/agent, Worker=0, Episode=501, Total reward=0, Steps=21264, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=502, Total reward=0, Steps=21316, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=503, Total reward=0, Steps=21366, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=504, Total reward=0, Steps=21421, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=505, Total reward=0, Steps=21449, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=506, Total reward=0, Steps=21469, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=507, Total reward=0, Steps=21504, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=508, Total reward=0, Steps=21586, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=509, Total reward=0, Steps=21616, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=510, Total reward=0, Steps=21690, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=511, Total reward=0, Steps=21759, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=512, Total reward=0, Steps=21799, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=513, Total reward=0, Steps=21835, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=514, Total reward=0, Steps=21861, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=515, Total reward=0, Steps=21954, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=516, Total reward=0, Steps=22016, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=517, Total reward=0, Steps=22078, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=518, Total reward=0, Steps=22157, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=519, Total reward=0, Steps=22236, Training iteration=25
Training> Name=main_level/agent, Worker=0, Episode=520, Total reward=0, Steps=22336, Training iteration=25
Policy training> Surrogate loss=0.011357448995113373, KL divergence=0.016885943710803986, Entropy=2.3982551097869873, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08780401945114136, KL divergence=0.06090280041098595, Entropy=2.4144399166107178, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11686856299638748, KL divergence=0.06777504831552505, Entropy=2.3972396850585938, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12210677564144135, KL divergence=0.06721776723861694, Entropy=2.4037222862243652, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13654527068138123, KL divergence=0.06975052505731583, Entropy=2.3990728855133057, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.12569569051265717, KL divergence=0.07161170244216919, Entropy=2.399550437927246, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13659337162971497, KL divergence=0.07164520025253296, Entropy=2.394624710083008, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13777418434619904, KL divergence=0.07153922319412231, Entropy=2.4040181636810303, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1327725201845169, KL divergence=0.07212895900011063, Entropy=2.3989667892456055, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13593830168247223, KL divergence=0.06963080167770386, Entropy=2.4363529682159424, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/26_Step-22336.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/26_Step-22336.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 26
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_26.pb
Best checkpoint number: 17, Last checkpoint number: 24
Copying the frozen checkpoint from ./frozen_models/agent/model_17.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'23'}
Training> Name=main_level/agent, Worker=0, Episode=521, Total reward=0, Steps=22367, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=522, Total reward=0, Steps=22404, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=523, Total reward=0, Steps=22443, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=524, Total reward=0, Steps=22492, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=525, Total reward=0, Steps=22521, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=526, Total reward=0, Steps=22546, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=527, Total reward=0, Steps=22586, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=528, Total reward=0, Steps=22643, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=529, Total reward=0, Steps=22684, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=530, Total reward=0, Steps=22744, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=531, Total reward=0, Steps=22765, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=532, Total reward=0, Steps=22857, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=533, Total reward=0, Steps=22956, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=534, Total reward=0, Steps=23048, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=535, Total reward=0, Steps=23124, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=536, Total reward=0, Steps=23188, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=537, Total reward=0, Steps=23235, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=538, Total reward=0, Steps=23353, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=539, Total reward=0, Steps=23407, Training iteration=26
Training> Name=main_level/agent, Worker=0, Episode=540, Total reward=0, Steps=23458, Training iteration=26
Policy training> Surrogate loss=0.016351385042071342, KL divergence=0.012715389020740986, Entropy=2.43896746635437, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.10266484320163727, KL divergence=0.04543974623084068, Entropy=2.4012537002563477, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1216970905661583, KL divergence=0.06518896669149399, Entropy=2.352029800415039, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1306108832359314, KL divergence=0.06448859721422195, Entropy=2.436613082885742, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13269779086112976, KL divergence=0.06535780429840088, Entropy=2.4356296062469482, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13529443740844727, KL divergence=0.06655552238225937, Entropy=2.439671754837036, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13752785325050354, KL divergence=0.06672520190477371, Entropy=2.4274678230285645, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14348043501377106, KL divergence=0.06330496072769165, Entropy=2.454904556274414, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1339031308889389, KL divergence=0.06377404928207397, Entropy=2.4567642211914062, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13486391305923462, KL divergence=0.06446737051010132, Entropy=2.454625368118286, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/27_Step-23458.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/27_Step-23458.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 27
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_27.pb
Best checkpoint number: 17, Last checkpoint number: 25
Copying the frozen checkpoint from ./frozen_models/agent/model_17.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'24'}
Training> Name=main_level/agent, Worker=0, Episode=541, Total reward=0, Steps=23501, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=542, Total reward=0, Steps=23531, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=543, Total reward=0, Steps=23571, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=544, Total reward=0, Steps=23591, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=545, Total reward=0, Steps=23613, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=546, Total reward=0, Steps=23632, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=547, Total reward=0, Steps=23712, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=548, Total reward=0, Steps=23750, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=549, Total reward=0, Steps=23837, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=550, Total reward=0, Steps=23860, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=551, Total reward=0, Steps=23984, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=552, Total reward=0, Steps=24035, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=553, Total reward=0, Steps=24103, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=554, Total reward=0, Steps=24173, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=555, Total reward=0, Steps=24200, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=556, Total reward=0, Steps=24224, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=557, Total reward=0, Steps=24273, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=558, Total reward=0, Steps=24315, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=559, Total reward=0, Steps=24367, Training iteration=27
Training> Name=main_level/agent, Worker=0, Episode=560, Total reward=0, Steps=24397, Training iteration=27
Policy training> Surrogate loss=0.016753286123275757, KL divergence=0.01498742401599884, Entropy=2.4211843013763428, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.07723388820886612, KL divergence=0.0551079623401165, Entropy=2.3427770137786865, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11736487597227097, KL divergence=0.049514979124069214, Entropy=2.4057648181915283, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1333681344985962, KL divergence=0.06628379225730896, Entropy=2.2813351154327393, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13053058087825775, KL divergence=0.06418293714523315, Entropy=2.3863656520843506, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13560804724693298, KL divergence=0.06672479212284088, Entropy=2.3169379234313965, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.14232291281223297, KL divergence=0.06436841934919357, Entropy=2.3519721031188965, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14113539457321167, KL divergence=0.065046526491642, Entropy=2.365919828414917, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14299514889717102, KL divergence=0.06570452451705933, Entropy=2.3598201274871826, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13362635672092438, KL divergence=0.06441942602396011, Entropy=2.3753225803375244, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/28_Step-24397.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/28_Step-24397.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 28
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_28.pb
Best checkpoint number: 17, Last checkpoint number: 26
Copying the frozen checkpoint from ./frozen_models/agent/model_17.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'25'}
Training> Name=main_level/agent, Worker=0, Episode=561, Total reward=0, Steps=24468, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=562, Total reward=0, Steps=24506, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=563, Total reward=0, Steps=24531, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=564, Total reward=0, Steps=24577, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=565, Total reward=0, Steps=24614, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=566, Total reward=0, Steps=24666, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=567, Total reward=0, Steps=24735, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=568, Total reward=0, Steps=24795, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=569, Total reward=0, Steps=24875, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=570, Total reward=0, Steps=24919, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=571, Total reward=0, Steps=24978, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=572, Total reward=0, Steps=25030, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=573, Total reward=0, Steps=25047, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=574, Total reward=0, Steps=25223, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=575, Total reward=0, Steps=25270, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=576, Total reward=0, Steps=25364, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=577, Total reward=0, Steps=25396, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=578, Total reward=0, Steps=25420, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=579, Total reward=0, Steps=25470, Training iteration=28
Training> Name=main_level/agent, Worker=0, Episode=580, Total reward=0, Steps=25494, Training iteration=28
Policy training> Surrogate loss=0.0014015570050105453, KL divergence=0.01731080375611782, Entropy=2.4826533794403076, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09062925726175308, KL divergence=0.055999062955379486, Entropy=2.418795108795166, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1276789754629135, KL divergence=0.05980807915329933, Entropy=2.4586403369903564, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12821727991104126, KL divergence=0.06637295335531235, Entropy=2.4442238807678223, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1358053982257843, KL divergence=0.07181664556264877, Entropy=2.4186689853668213, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1409303843975067, KL divergence=0.06824939697980881, Entropy=2.434281826019287, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.14074209332466125, KL divergence=0.0670643001794815, Entropy=2.4535038471221924, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14173348248004913, KL divergence=0.06584212929010391, Entropy=2.455728530883789, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14230400323867798, KL divergence=0.0658847764134407, Entropy=2.4600188732147217, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1461651474237442, KL divergence=0.06676353514194489, Entropy=2.4497501850128174, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/29_Step-25494.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/29_Step-25494.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 29
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_29.pb
Best checkpoint number: 17, Last checkpoint number: 27
Copying the frozen checkpoint from ./frozen_models/agent/model_17.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'26'}
Training> Name=main_level/agent, Worker=0, Episode=581, Total reward=0, Steps=25535, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=582, Total reward=0, Steps=25580, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=583, Total reward=0, Steps=25637, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=584, Total reward=0, Steps=25667, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=585, Total reward=0, Steps=25688, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=586, Total reward=0, Steps=25707, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=587, Total reward=0, Steps=25803, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=588, Total reward=0, Steps=25830, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=589, Total reward=0, Steps=25866, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=590, Total reward=0, Steps=25905, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=591, Total reward=0, Steps=25938, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=592, Total reward=0, Steps=26000, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=593, Total reward=0, Steps=26055, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=594, Total reward=0, Steps=26091, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=595, Total reward=0, Steps=26122, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=596, Total reward=0, Steps=26168, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=597, Total reward=0, Steps=26194, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=598, Total reward=0, Steps=26221, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=599, Total reward=0, Steps=26261, Training iteration=29
Training> Name=main_level/agent, Worker=0, Episode=600, Total reward=0, Steps=26343, Training iteration=29
Policy training> Surrogate loss=0.005206518806517124, KL divergence=0.018583856523036957, Entropy=2.4217803478240967, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08536676317453384, KL divergence=0.04777395725250244, Entropy=2.4068315029144287, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11184913665056229, KL divergence=0.05471424758434296, Entropy=2.3874752521514893, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.11714585870504379, KL divergence=0.06943854689598083, Entropy=2.3309378623962402, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1181812658905983, KL divergence=0.06154131144285202, Entropy=2.3887038230895996, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.12818406522274017, KL divergence=0.06313186138868332, Entropy=2.370649576187134, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.12968920171260834, KL divergence=0.06123043969273567, Entropy=2.388411521911621, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1388395130634308, KL divergence=0.06467142701148987, Entropy=2.378643274307251, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13989907503128052, KL divergence=0.06541693955659866, Entropy=2.380160331726074, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13334320485591888, KL divergence=0.07118581980466843, Entropy=2.3514208793640137, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/30_Step-26343.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/30_Step-26343.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 30
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_30.pb
Best checkpoint number: 17, Last checkpoint number: 28
Copying the frozen checkpoint from ./frozen_models/agent/model_17.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'27'}
Training> Name=main_level/agent, Worker=0, Episode=601, Total reward=0, Steps=26433, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=602, Total reward=0, Steps=26471, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=603, Total reward=0, Steps=26510, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=604, Total reward=0, Steps=26552, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=605, Total reward=0, Steps=26572, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=606, Total reward=0, Steps=26594, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=607, Total reward=0, Steps=26621, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=608, Total reward=0, Steps=26833, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=609, Total reward=0, Steps=26856, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=610, Total reward=0, Steps=26900, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=611, Total reward=0, Steps=27108, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=612, Total reward=0, Steps=27182, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=613, Total reward=0, Steps=27264, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=614, Total reward=0, Steps=27335, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=615, Total reward=0, Steps=27398, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=616, Total reward=0, Steps=27421, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=617, Total reward=0, Steps=27507, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=618, Total reward=0, Steps=27555, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=619, Total reward=0, Steps=27578, Training iteration=30
Training> Name=main_level/agent, Worker=0, Episode=620, Total reward=0, Steps=27631, Training iteration=30
Policy training> Surrogate loss=0.02297133207321167, KL divergence=0.02653280459344387, Entropy=2.427004814147949, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09364691376686096, KL divergence=0.06023354083299637, Entropy=2.368961811065674, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11767735332250595, KL divergence=0.07046929746866226, Entropy=2.398799419403076, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13093020021915436, KL divergence=0.07539932429790497, Entropy=2.4010910987854004, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1424054503440857, KL divergence=0.08241327106952667, Entropy=2.35426664352417, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14427393674850464, KL divergence=0.07757650315761566, Entropy=2.3720154762268066, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.15024223923683167, KL divergence=0.08315642178058624, Entropy=2.367037296295166, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.15453970432281494, KL divergence=0.07764865458011627, Entropy=2.400254726409912, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.15251712501049042, KL divergence=0.07658255100250244, Entropy=2.4082257747650146, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.15181632339954376, KL divergence=0.08381672203540802, Entropy=2.364942789077759, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/31_Step-27631.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/31_Step-27631.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 31
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_31.pb
Best checkpoint number: 17, Last checkpoint number: 29
Copying the frozen checkpoint from ./frozen_models/agent/model_17.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'28'}
Training> Name=main_level/agent, Worker=0, Episode=621, Total reward=0, Steps=27718, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=622, Total reward=0, Steps=27762, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=623, Total reward=0, Steps=27819, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=624, Total reward=0, Steps=27867, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=625, Total reward=0, Steps=27895, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=626, Total reward=0, Steps=27912, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=627, Total reward=0, Steps=27978, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=628, Total reward=0, Steps=28033, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=629, Total reward=0, Steps=28059, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=630, Total reward=0, Steps=28092, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=631, Total reward=0, Steps=28120, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=632, Total reward=0, Steps=28153, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=633, Total reward=0, Steps=28176, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=634, Total reward=0, Steps=28229, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=635, Total reward=0, Steps=28315, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=636, Total reward=0, Steps=28376, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=637, Total reward=0, Steps=28412, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=638, Total reward=0, Steps=28448, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=639, Total reward=0, Steps=28498, Training iteration=31
Training> Name=main_level/agent, Worker=0, Episode=640, Total reward=0, Steps=28532, Training iteration=31
Policy training> Surrogate loss=0.012737962417304516, KL divergence=0.01291267666965723, Entropy=2.4969258308410645, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09378689527511597, KL divergence=0.045467011630535126, Entropy=2.4985806941986084, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11917364597320557, KL divergence=0.0523051954805851, Entropy=2.4804484844207764, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12476866692304611, KL divergence=0.053840428590774536, Entropy=2.4831368923187256, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13062217831611633, KL divergence=0.05266658589243889, Entropy=2.493662118911743, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.12733641266822815, KL divergence=0.05909862369298935, Entropy=2.4259679317474365, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1290142834186554, KL divergence=0.05487590655684471, Entropy=2.4758622646331787, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13341493904590607, KL divergence=0.054373301565647125, Entropy=2.4764912128448486, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13570347428321838, KL divergence=0.05538925155997276, Entropy=2.4622247219085693, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13760900497436523, KL divergence=0.05457054451107979, Entropy=2.4738965034484863, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/32_Step-28532.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/32_Step-28532.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 32
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_32.pb
Best checkpoint number: 17, Last checkpoint number: 30
Copying the frozen checkpoint from ./frozen_models/agent/model_17.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'29'}
Training> Name=main_level/agent, Worker=0, Episode=641, Total reward=0, Steps=28568, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=642, Total reward=0, Steps=28593, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=643, Total reward=0, Steps=28625, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=644, Total reward=0, Steps=28656, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=645, Total reward=0, Steps=28679, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=646, Total reward=0, Steps=28701, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=647, Total reward=0, Steps=28731, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=648, Total reward=0, Steps=28781, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=649, Total reward=0, Steps=28941, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=650, Total reward=0, Steps=28970, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=651, Total reward=0, Steps=29032, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=652, Total reward=0, Steps=29129, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=653, Total reward=0, Steps=29307, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=654, Total reward=0, Steps=29329, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=655, Total reward=0, Steps=29380, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=656, Total reward=0, Steps=29444, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=657, Total reward=0, Steps=29560, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=658, Total reward=0, Steps=29609, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=659, Total reward=0, Steps=29706, Training iteration=32
Training> Name=main_level/agent, Worker=0, Episode=660, Total reward=0, Steps=29738, Training iteration=32
Policy training> Surrogate loss=0.017167698591947556, KL divergence=0.02571258321404457, Entropy=2.389491081237793, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.10010718554258347, KL divergence=0.05369477719068527, Entropy=2.425523281097412, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.13131363689899445, KL divergence=0.06773488968610764, Entropy=2.357668161392212, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1327398717403412, KL divergence=0.0635833814740181, Entropy=2.3752994537353516, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.15931524336338043, KL divergence=0.06768569350242615, Entropy=2.388185977935791, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14201872050762177, KL divergence=0.06650768965482712, Entropy=2.434030294418335, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.15839272737503052, KL divergence=0.06737342476844788, Entropy=2.4243357181549072, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.15614615380764008, KL divergence=0.0682159960269928, Entropy=2.422844886779785, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.16985079646110535, KL divergence=0.0679275244474411, Entropy=2.423121452331543, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.16221213340759277, KL divergence=0.06813248991966248, Entropy=2.429292917251587, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/33_Step-29738.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/33_Step-29738.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 33
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_33.pb
Best checkpoint number: 31, Last checkpoint number: 31
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'17'}
Training> Name=main_level/agent, Worker=0, Episode=661, Total reward=0, Steps=29760, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=662, Total reward=0, Steps=29786, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=663, Total reward=0, Steps=29828, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=664, Total reward=0, Steps=29855, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=665, Total reward=0, Steps=29913, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=666, Total reward=0, Steps=29930, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=667, Total reward=0, Steps=30037, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=668, Total reward=0, Steps=30112, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=669, Total reward=0, Steps=30160, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=670, Total reward=0, Steps=30237, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=671, Total reward=0, Steps=30287, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=672, Total reward=0, Steps=30349, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=673, Total reward=0, Steps=30397, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=674, Total reward=0, Steps=30425, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=675, Total reward=0, Steps=30473, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=676, Total reward=0, Steps=30497, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=677, Total reward=0, Steps=30532, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=678, Total reward=0, Steps=30607, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=679, Total reward=0, Steps=30634, Training iteration=33
Training> Name=main_level/agent, Worker=0, Episode=680, Total reward=0, Steps=30712, Training iteration=33
Policy training> Surrogate loss=-0.004604014568030834, KL divergence=0.024018175899982452, Entropy=2.4029998779296875, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08061669766902924, KL divergence=0.08100199699401855, Entropy=2.4393997192382812, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12050838023424149, KL divergence=0.11862535774707794, Entropy=2.2734375, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13392053544521332, KL divergence=0.0842503234744072, Entropy=2.422952175140381, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.14306004345417023, KL divergence=0.08668036758899689, Entropy=2.3820316791534424, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14335432648658752, KL divergence=0.07519438117742538, Entropy=2.4371440410614014, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.15014226734638214, KL divergence=0.08118090778589249, Entropy=2.4167847633361816, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14483730494976044, KL divergence=0.07724855095148087, Entropy=2.4399425983428955, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1502545326948166, KL divergence=0.0833410918712616, Entropy=2.4256043434143066, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14087460935115814, KL divergence=0.07935064285993576, Entropy=2.4467756748199463, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/34_Step-30712.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/34_Step-30712.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 34
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_34.pb
Best checkpoint number: 31, Last checkpoint number: 32
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'30'}
Training> Name=main_level/agent, Worker=0, Episode=681, Total reward=0, Steps=30769, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=682, Total reward=0, Steps=30839, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=683, Total reward=0, Steps=30900, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=684, Total reward=0, Steps=30948, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=685, Total reward=0, Steps=30981, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=686, Total reward=0, Steps=31030, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=687, Total reward=0, Steps=31070, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=688, Total reward=0, Steps=31195, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=689, Total reward=0, Steps=31234, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=690, Total reward=0, Steps=31278, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=691, Total reward=0, Steps=31327, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=692, Total reward=0, Steps=31374, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=693, Total reward=0, Steps=31573, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=694, Total reward=0, Steps=31603, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=695, Total reward=0, Steps=31771, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=696, Total reward=0, Steps=31865, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=697, Total reward=0, Steps=31896, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=698, Total reward=0, Steps=32025, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=699, Total reward=0, Steps=32083, Training iteration=34
Training> Name=main_level/agent, Worker=0, Episode=700, Total reward=0, Steps=32140, Training iteration=34
Policy training> Surrogate loss=0.022725211456418037, KL divergence=0.02086072601377964, Entropy=2.3850367069244385, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09525559097528458, KL divergence=0.054566070437431335, Entropy=2.4645674228668213, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12581034004688263, KL divergence=0.06714201718568802, Entropy=2.393916606903076, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.14011351764202118, KL divergence=0.06375259906053543, Entropy=2.4217302799224854, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.14894793927669525, KL divergence=0.06549745053052902, Entropy=2.40035343170166, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13702258467674255, KL divergence=0.06417591869831085, Entropy=2.4254322052001953, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1430044323205948, KL divergence=0.06607627868652344, Entropy=2.434353828430176, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14411784708499908, KL divergence=0.06414297223091125, Entropy=2.434661865234375, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.15035836398601532, KL divergence=0.0621623620390892, Entropy=2.4436984062194824, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.148492231965065, KL divergence=0.06241816282272339, Entropy=2.4402859210968018, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/35_Step-32140.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/35_Step-32140.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 35
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_35.pb
Best checkpoint number: 31, Last checkpoint number: 33
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'32'}
Training> Name=main_level/agent, Worker=0, Episode=701, Total reward=0, Steps=32191, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=702, Total reward=0, Steps=32228, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=703, Total reward=0, Steps=32291, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=704, Total reward=0, Steps=32332, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=705, Total reward=0, Steps=32390, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=706, Total reward=0, Steps=32413, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=707, Total reward=0, Steps=32444, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=708, Total reward=0, Steps=32516, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=709, Total reward=0, Steps=32564, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=710, Total reward=0, Steps=32600, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=711, Total reward=0, Steps=32622, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=712, Total reward=0, Steps=32646, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=713, Total reward=0, Steps=32673, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=714, Total reward=0, Steps=32702, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=715, Total reward=0, Steps=32824, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=716, Total reward=0, Steps=32885, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=717, Total reward=0, Steps=33019, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=718, Total reward=0, Steps=33053, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=719, Total reward=0, Steps=33093, Training iteration=35
Training> Name=main_level/agent, Worker=0, Episode=720, Total reward=0, Steps=33161, Training iteration=35
Policy training> Surrogate loss=0.01615564152598381, KL divergence=0.010546130128204823, Entropy=2.4774842262268066, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09775958210229874, KL divergence=0.0402316190302372, Entropy=2.5148110389709473, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11918549984693527, KL divergence=0.04354487732052803, Entropy=2.48669695854187, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1310616284608841, KL divergence=0.04601965844631195, Entropy=2.496232271194458, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1367097645998001, KL divergence=0.04979519918560982, Entropy=2.4677631855010986, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13554902374744415, KL divergence=0.04945146292448044, Entropy=2.4912567138671875, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1357787698507309, KL divergence=0.05141163244843483, Entropy=2.4748375415802, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.15191766619682312, KL divergence=0.049031805247068405, Entropy=2.5072999000549316, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.15017053484916687, KL divergence=0.05174725502729416, Entropy=2.4731478691101074, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14333289861679077, KL divergence=0.04905730113387108, Entropy=2.504378080368042, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/36_Step-33161.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/36_Step-33161.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 36
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_36.pb
Best checkpoint number: 31, Last checkpoint number: 34
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'33'}
Training> Name=main_level/agent, Worker=0, Episode=721, Total reward=0, Steps=33242, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=722, Total reward=0, Steps=33299, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=723, Total reward=0, Steps=33321, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=724, Total reward=0, Steps=33372, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=725, Total reward=0, Steps=33406, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=726, Total reward=0, Steps=33429, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=727, Total reward=0, Steps=33478, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=728, Total reward=0, Steps=33505, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=729, Total reward=0, Steps=33621, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=730, Total reward=0, Steps=33819, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=731, Total reward=0, Steps=33897, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=732, Total reward=0, Steps=33924, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=733, Total reward=0, Steps=33948, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=734, Total reward=0, Steps=34048, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=735, Total reward=0, Steps=34077, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=736, Total reward=0, Steps=34170, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=737, Total reward=0, Steps=34202, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=738, Total reward=0, Steps=34306, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=739, Total reward=0, Steps=34392, Training iteration=36
Training> Name=main_level/agent, Worker=0, Episode=740, Total reward=0, Steps=34471, Training iteration=36
Policy training> Surrogate loss=0.005838572978973389, KL divergence=0.01887216605246067, Entropy=2.4412474632263184, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09275560081005096, KL divergence=0.062304358929395676, Entropy=2.36704683303833, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1300026923418045, KL divergence=0.061961036175489426, Entropy=2.403132438659668, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13451892137527466, KL divergence=0.06761448085308075, Entropy=2.4127197265625, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.15138843655586243, KL divergence=0.06536287069320679, Entropy=2.3949685096740723, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14529405534267426, KL divergence=0.0625864565372467, Entropy=2.4184539318084717, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.14892981946468353, KL divergence=0.06495081633329391, Entropy=2.4143240451812744, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14332915842533112, KL divergence=0.05935130640864372, Entropy=2.449382781982422, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.15334230661392212, KL divergence=0.06295545399188995, Entropy=2.422118663787842, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14434495568275452, KL divergence=0.061435598880052567, Entropy=2.4463651180267334, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/37_Step-34471.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/37_Step-34471.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 37
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_37.pb
Best checkpoint number: 31, Last checkpoint number: 35
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'34'}
Training> Name=main_level/agent, Worker=0, Episode=741, Total reward=0, Steps=34492, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=742, Total reward=0, Steps=34521, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=743, Total reward=0, Steps=34586, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=744, Total reward=0, Steps=34628, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=745, Total reward=0, Steps=34656, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=746, Total reward=0, Steps=34697, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=747, Total reward=0, Steps=34784, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=748, Total reward=0, Steps=34814, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=749, Total reward=0, Steps=34852, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=750, Total reward=0, Steps=34886, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=751, Total reward=0, Steps=34929, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=752, Total reward=0, Steps=35030, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=753, Total reward=0, Steps=35058, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=754, Total reward=0, Steps=35097, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=755, Total reward=0, Steps=35175, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=756, Total reward=0, Steps=35210, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=757, Total reward=0, Steps=35248, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=758, Total reward=0, Steps=35348, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=759, Total reward=0, Steps=35448, Training iteration=37
Training> Name=main_level/agent, Worker=0, Episode=760, Total reward=0, Steps=35476, Training iteration=37
Policy training> Surrogate loss=0.005754584446549416, KL divergence=0.023480214178562164, Entropy=2.3663575649261475, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.10117463022470474, KL divergence=0.062165796756744385, Entropy=2.4254369735717773, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11938965320587158, KL divergence=0.0678434669971466, Entropy=2.3459596633911133, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.11692631989717484, KL divergence=0.0679265633225441, Entropy=2.34261155128479, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12921364605426788, KL divergence=0.06394965946674347, Entropy=2.3736488819122314, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13511568307876587, KL divergence=0.06648702174425125, Entropy=2.3647713661193848, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13642896711826324, KL divergence=0.06123889982700348, Entropy=2.394843101501465, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1496775895357132, KL divergence=0.06769130378961563, Entropy=2.3605797290802, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13540592789649963, KL divergence=0.05758102610707283, Entropy=2.415207624435425, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1420527994632721, KL divergence=0.06766322255134583, Entropy=2.348353624343872, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/38_Step-35476.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/38_Step-35476.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 38
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_38.pb
Best checkpoint number: 31, Last checkpoint number: 36
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'35'}
Training> Name=main_level/agent, Worker=0, Episode=761, Total reward=0, Steps=35513, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=762, Total reward=0, Steps=35588, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=763, Total reward=0, Steps=35628, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=764, Total reward=0, Steps=35671, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=765, Total reward=0, Steps=35709, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=766, Total reward=0, Steps=35728, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=767, Total reward=0, Steps=35771, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=768, Total reward=0, Steps=35846, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=769, Total reward=0, Steps=35897, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=770, Total reward=0, Steps=35955, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=771, Total reward=0, Steps=35979, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=772, Total reward=0, Steps=36098, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=773, Total reward=0, Steps=36122, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=774, Total reward=0, Steps=36183, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=775, Total reward=0, Steps=36222, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=776, Total reward=0, Steps=36283, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=777, Total reward=0, Steps=36337, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=778, Total reward=0, Steps=36383, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=779, Total reward=0, Steps=36458, Training iteration=38
Training> Name=main_level/agent, Worker=0, Episode=780, Total reward=0, Steps=36478, Training iteration=38
Policy training> Surrogate loss=0.005536922253668308, KL divergence=0.008357561193406582, Entropy=2.533266544342041, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09761716425418854, KL divergence=0.04210568219423294, Entropy=2.5650930404663086, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11290941387414932, KL divergence=0.04835943877696991, Entropy=2.5028016567230225, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13740791380405426, KL divergence=0.04844367504119873, Entropy=2.5303146839141846, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13615036010742188, KL divergence=0.05028291791677475, Entropy=2.5410008430480957, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1395331174135208, KL divergence=0.050372496247291565, Entropy=2.5260159969329834, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.12889130413532257, KL divergence=0.051562365144491196, Entropy=2.517444133758545, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14000897109508514, KL divergence=0.050776585936546326, Entropy=2.537776231765747, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14461079239845276, KL divergence=0.05012403056025505, Entropy=2.544750928878784, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.12766729295253754, KL divergence=0.05011055991053581, Entropy=2.5417444705963135, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/39_Step-36478.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/39_Step-36478.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 39
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_39.pb
Best checkpoint number: 31, Last checkpoint number: 37
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'36'}
Training> Name=main_level/agent, Worker=0, Episode=781, Total reward=0, Steps=36511, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=782, Total reward=0, Steps=36567, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=783, Total reward=0, Steps=36628, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=784, Total reward=0, Steps=36678, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=785, Total reward=0, Steps=36701, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=786, Total reward=0, Steps=36751, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=787, Total reward=0, Steps=36808, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=788, Total reward=0, Steps=36894, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=789, Total reward=0, Steps=36937, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=790, Total reward=0, Steps=37018, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=791, Total reward=0, Steps=37137, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=792, Total reward=0, Steps=37351, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=793, Total reward=0, Steps=37401, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=794, Total reward=0, Steps=37438, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=795, Total reward=0, Steps=37481, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=796, Total reward=0, Steps=37528, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=797, Total reward=0, Steps=37673, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=798, Total reward=0, Steps=37727, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=799, Total reward=0, Steps=37848, Training iteration=39
Training> Name=main_level/agent, Worker=0, Episode=800, Total reward=0, Steps=37867, Training iteration=39
Policy training> Surrogate loss=0.014940367080271244, KL divergence=0.014487060718238354, Entropy=2.4270260334014893, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09129714965820312, KL divergence=0.05070691555738449, Entropy=2.3941726684570312, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12099797278642654, KL divergence=0.04616323113441467, Entropy=2.4091100692749023, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13230708241462708, KL divergence=0.05049595981836319, Entropy=2.4011693000793457, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13348963856697083, KL divergence=0.04897383973002434, Entropy=2.388000011444092, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13181424140930176, KL divergence=0.04959786683320999, Entropy=2.39898419380188, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.15149852633476257, KL divergence=0.04756636917591095, Entropy=2.4013426303863525, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14431515336036682, KL divergence=0.0523943230509758, Entropy=2.3930504322052, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1437925398349762, KL divergence=0.04806651547551155, Entropy=2.4193172454833984, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14866487681865692, KL divergence=0.049683962017297745, Entropy=2.4389514923095703, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/40_Step-37867.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/40_Step-37867.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 40
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_40.pb
Best checkpoint number: 31, Last checkpoint number: 38
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'37'}
Training> Name=main_level/agent, Worker=0, Episode=801, Total reward=0, Steps=37907, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=802, Total reward=0, Steps=37959, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=803, Total reward=0, Steps=38017, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=804, Total reward=0, Steps=38066, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=805, Total reward=0, Steps=38149, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=806, Total reward=0, Steps=38166, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=807, Total reward=0, Steps=38200, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=808, Total reward=0, Steps=38224, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=809, Total reward=0, Steps=38277, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=810, Total reward=0, Steps=38352, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=811, Total reward=0, Steps=38408, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=812, Total reward=0, Steps=38520, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=813, Total reward=0, Steps=38604, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=814, Total reward=0, Steps=38649, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=815, Total reward=0, Steps=38716, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=816, Total reward=0, Steps=38753, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=817, Total reward=0, Steps=38825, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=818, Total reward=0, Steps=38940, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=819, Total reward=0, Steps=39074, Training iteration=40
Training> Name=main_level/agent, Worker=0, Episode=820, Total reward=0, Steps=39120, Training iteration=40
Policy training> Surrogate loss=0.025201372802257538, KL divergence=0.024041825905442238, Entropy=2.4964892864227295, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09706281125545502, KL divergence=0.051396530121564865, Entropy=2.4591100215911865, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12477197498083115, KL divergence=0.05255896598100662, Entropy=2.4569272994995117, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1314409226179123, KL divergence=0.06362767517566681, Entropy=2.4605166912078857, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13060183823108673, KL divergence=0.061780884861946106, Entropy=2.437957763671875, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14829887449741364, KL divergence=0.05652198567986488, Entropy=2.461193799972534, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1463269144296646, KL divergence=0.058258056640625, Entropy=2.4427998065948486, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1478460729122162, KL divergence=0.05590668320655823, Entropy=2.466611623764038, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1365704983472824, KL divergence=0.054490044713020325, Entropy=2.466951847076416, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1429804563522339, KL divergence=0.05354774743318558, Entropy=2.479706048965454, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/41_Step-39120.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/41_Step-39120.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 41
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_41.pb
Best checkpoint number: 31, Last checkpoint number: 39
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'38'}
Training> Name=main_level/agent, Worker=0, Episode=821, Total reward=0, Steps=39209, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=822, Total reward=0, Steps=39262, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=823, Total reward=0, Steps=39288, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=824, Total reward=0, Steps=39311, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=825, Total reward=0, Steps=39333, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=826, Total reward=0, Steps=39381, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=827, Total reward=0, Steps=39483, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=828, Total reward=0, Steps=39584, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=829, Total reward=0, Steps=39724, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=830, Total reward=0, Steps=39783, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=831, Total reward=0, Steps=39870, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=832, Total reward=0, Steps=39921, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=833, Total reward=0, Steps=39946, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=834, Total reward=0, Steps=39986, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=835, Total reward=0, Steps=40092, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=836, Total reward=0, Steps=40184, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=837, Total reward=0, Steps=40221, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=838, Total reward=0, Steps=40316, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=839, Total reward=0, Steps=40358, Training iteration=41
Training> Name=main_level/agent, Worker=0, Episode=840, Total reward=0, Steps=40457, Training iteration=41
Policy training> Surrogate loss=0.015801966190338135, KL divergence=0.02059459127485752, Entropy=2.449774980545044, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09130515158176422, KL divergence=0.04576217383146286, Entropy=2.453505039215088, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.13666649162769318, KL divergence=0.04989936202764511, Entropy=2.409971237182617, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13321103155612946, KL divergence=0.04908321425318718, Entropy=2.4401755332946777, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1367402821779251, KL divergence=0.053846221417188644, Entropy=2.4136884212493896, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14002405107021332, KL divergence=0.051125578582286835, Entropy=2.451728343963623, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1476883888244629, KL divergence=0.05452819541096687, Entropy=2.4200708866119385, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1538405418395996, KL divergence=0.053862374275922775, Entropy=2.430455207824707, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1491675078868866, KL divergence=0.056732069700956345, Entropy=2.418112277984619, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14594195783138275, KL divergence=0.056118328124284744, Entropy=2.4335761070251465, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/42_Step-40457.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/42_Step-40457.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 42
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_42.pb
Best checkpoint number: 31, Last checkpoint number: 40
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'39'}
Training> Name=main_level/agent, Worker=0, Episode=841, Total reward=0, Steps=40514, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=842, Total reward=0, Steps=40555, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=843, Total reward=0, Steps=40617, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=844, Total reward=0, Steps=40659, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=845, Total reward=0, Steps=40693, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=846, Total reward=0, Steps=40736, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=847, Total reward=0, Steps=40784, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=848, Total reward=0, Steps=40862, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=849, Total reward=0, Steps=40888, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=850, Total reward=0, Steps=40925, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=851, Total reward=0, Steps=41008, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=852, Total reward=0, Steps=41040, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=853, Total reward=0, Steps=41071, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=854, Total reward=0, Steps=41144, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=855, Total reward=0, Steps=41298, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=856, Total reward=0, Steps=41355, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=857, Total reward=0, Steps=41382, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=858, Total reward=0, Steps=41436, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=859, Total reward=0, Steps=41476, Training iteration=42
Training> Name=main_level/agent, Worker=0, Episode=860, Total reward=0, Steps=41532, Training iteration=42
Policy training> Surrogate loss=0.0019117067568004131, KL divergence=0.011908384039998055, Entropy=2.4090707302093506, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09746948629617691, KL divergence=0.048406608402729034, Entropy=2.348909378051758, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11525285243988037, KL divergence=0.057848453521728516, Entropy=2.3404417037963867, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12030603736639023, KL divergence=0.06220091134309769, Entropy=2.3510117530822754, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13439826667308807, KL divergence=0.05958368629217148, Entropy=2.35231351852417, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.11475353688001633, KL divergence=0.06470958888530731, Entropy=2.3424184322357178, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.12767073512077332, KL divergence=0.06794507801532745, Entropy=2.320115327835083, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.12605877220630646, KL divergence=0.06192745640873909, Entropy=2.3446731567382812, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13693612813949585, KL divergence=0.06000342220067978, Entropy=2.3612966537475586, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.15008486807346344, KL divergence=0.058609068393707275, Entropy=2.3683342933654785, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/43_Step-41532.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/43_Step-41532.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 43
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_43.pb
Best checkpoint number: 31, Last checkpoint number: 41
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'40'}
Training> Name=main_level/agent, Worker=0, Episode=861, Total reward=0, Steps=41574, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=862, Total reward=0, Steps=41624, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=863, Total reward=0, Steps=41653, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=864, Total reward=0, Steps=41703, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=865, Total reward=0, Steps=41726, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=866, Total reward=0, Steps=41774, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=867, Total reward=0, Steps=41878, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=868, Total reward=0, Steps=41962, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=869, Total reward=0, Steps=42175, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=870, Total reward=0, Steps=42215, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=871, Total reward=0, Steps=42295, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=872, Total reward=0, Steps=42322, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=873, Total reward=0, Steps=42342, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=874, Total reward=0, Steps=42479, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=875, Total reward=0, Steps=42683, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=876, Total reward=0, Steps=42852, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=877, Total reward=0, Steps=42874, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=878, Total reward=0, Steps=42960, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=879, Total reward=0, Steps=43050, Training iteration=43
Training> Name=main_level/agent, Worker=0, Episode=880, Total reward=0, Steps=43130, Training iteration=43
Policy training> Surrogate loss=0.0061958483420312405, KL divergence=0.023938080295920372, Entropy=2.3561794757843018, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08829093724489212, KL divergence=0.054927486926317215, Entropy=2.327918529510498, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11493998020887375, KL divergence=0.05925941467285156, Entropy=2.3239004611968994, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12326914817094803, KL divergence=0.06979572772979736, Entropy=2.272199869155884, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12937842309474945, KL divergence=0.06545951217412949, Entropy=2.304385185241699, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13374409079551697, KL divergence=0.06538069248199463, Entropy=2.301503896713257, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1385229378938675, KL divergence=0.06318508833646774, Entropy=2.324191093444824, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1413409560918808, KL divergence=0.06440842151641846, Entropy=2.3169105052948, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14271442592144012, KL divergence=0.06490366905927658, Entropy=2.3182425498962402, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1377410590648651, KL divergence=0.06423980742692947, Entropy=2.3333492279052734, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/44_Step-43130.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/44_Step-43130.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 44
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_44.pb
Best checkpoint number: 31, Last checkpoint number: 42
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'41'}
Training> Name=main_level/agent, Worker=0, Episode=881, Total reward=0, Steps=43183, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=882, Total reward=0, Steps=43209, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=883, Total reward=0, Steps=43274, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=884, Total reward=0, Steps=43356, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=885, Total reward=0, Steps=43397, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=886, Total reward=0, Steps=43479, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=887, Total reward=0, Steps=43650, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=888, Total reward=0, Steps=43784, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=889, Total reward=0, Steps=43823, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=890, Total reward=0, Steps=43884, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=891, Total reward=0, Steps=43934, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=892, Total reward=0, Steps=43987, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=893, Total reward=0, Steps=44099, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=894, Total reward=0, Steps=44208, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=895, Total reward=0, Steps=44325, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=896, Total reward=0, Steps=44396, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=897, Total reward=0, Steps=44547, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=898, Total reward=0, Steps=44569, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=899, Total reward=0, Steps=44647, Training iteration=44
Training> Name=main_level/agent, Worker=0, Episode=900, Total reward=0, Steps=44719, Training iteration=44
Policy training> Surrogate loss=0.021431446075439453, KL divergence=0.026636973023414612, Entropy=2.2827019691467285, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.083286814391613, KL divergence=0.07092073559761047, Entropy=2.2512881755828857, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.10844579339027405, KL divergence=0.06819058954715729, Entropy=2.215203285217285, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12306367605924606, KL divergence=0.07224152237176895, Entropy=2.2046525478363037, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13099446892738342, KL divergence=0.07086864858865738, Entropy=2.2231266498565674, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13063007593154907, KL divergence=0.07006875425577164, Entropy=2.2183239459991455, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13038097321987152, KL divergence=0.06825356930494308, Entropy=2.241598129272461, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13091185688972473, KL divergence=0.06847306340932846, Entropy=2.229987382888794, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13807085156440735, KL divergence=0.06536491960287094, Entropy=2.253153085708618, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13519901037216187, KL divergence=0.06672648340463638, Entropy=2.2564356327056885, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/45_Step-44719.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/45_Step-44719.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 45
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_45.pb
Best checkpoint number: 31, Last checkpoint number: 43
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'42'}
Training> Name=main_level/agent, Worker=0, Episode=901, Total reward=0, Steps=44749, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=902, Total reward=0, Steps=44831, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=903, Total reward=0, Steps=44891, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=904, Total reward=0, Steps=44941, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=905, Total reward=0, Steps=44962, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=906, Total reward=0, Steps=45018, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=907, Total reward=0, Steps=45188, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=908, Total reward=0, Steps=45304, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=909, Total reward=0, Steps=45579, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=910, Total reward=0, Steps=45667, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=911, Total reward=0, Steps=45825, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=912, Total reward=0, Steps=45890, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=913, Total reward=0, Steps=46038, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=914, Total reward=0, Steps=46118, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=915, Total reward=0, Steps=46230, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=916, Total reward=0, Steps=46342, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=917, Total reward=0, Steps=46435, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=918, Total reward=0, Steps=46503, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=919, Total reward=0, Steps=46572, Training iteration=45
Training> Name=main_level/agent, Worker=0, Episode=920, Total reward=0, Steps=46683, Training iteration=45
Policy training> Surrogate loss=0.01711326092481613, KL divergence=0.035421907901763916, Entropy=2.3192708492279053, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.07846274971961975, KL divergence=0.07173259556293488, Entropy=2.300753355026245, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12205351144075394, KL divergence=0.06453028321266174, Entropy=2.308488607406616, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12869951128959656, KL divergence=0.070670947432518, Entropy=2.2832205295562744, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12898245453834534, KL divergence=0.07040290534496307, Entropy=2.288322925567627, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.137735515832901, KL divergence=0.07126801460981369, Entropy=2.2952229976654053, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13376228511333466, KL divergence=0.07383715361356735, Entropy=2.2963552474975586, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.138251394033432, KL divergence=0.07297178357839584, Entropy=2.320338010787964, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.141950324177742, KL divergence=0.07317562401294708, Entropy=2.3080549240112305, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1418653130531311, KL divergence=0.07654650509357452, Entropy=2.324327230453491, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/46_Step-46683.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/46_Step-46683.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 46
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_46.pb
Best checkpoint number: 31, Last checkpoint number: 44
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'43'}
Training> Name=main_level/agent, Worker=0, Episode=921, Total reward=0, Steps=46771, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=922, Total reward=0, Steps=46850, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=923, Total reward=0, Steps=46881, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=924, Total reward=0, Steps=46919, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=925, Total reward=0, Steps=46967, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=926, Total reward=0, Steps=47007, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=927, Total reward=0, Steps=47140, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=928, Total reward=0, Steps=47246, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=929, Total reward=0, Steps=47336, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=930, Total reward=0, Steps=47373, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=931, Total reward=0, Steps=47443, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=932, Total reward=0, Steps=47509, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=933, Total reward=0, Steps=47638, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=934, Total reward=0, Steps=47715, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=935, Total reward=0, Steps=47863, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=936, Total reward=0, Steps=47942, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=937, Total reward=0, Steps=48054, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=938, Total reward=0, Steps=48122, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=939, Total reward=0, Steps=48195, Training iteration=46
Training> Name=main_level/agent, Worker=0, Episode=940, Total reward=0, Steps=48250, Training iteration=46
Policy training> Surrogate loss=0.016564929857850075, KL divergence=0.024957789108157158, Entropy=2.3152246475219727, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09156125783920288, KL divergence=0.05818692967295647, Entropy=2.2937848567962646, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.10919877141714096, KL divergence=0.05567140504717827, Entropy=2.299372434616089, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1256713569164276, KL divergence=0.05545751750469208, Entropy=2.3131916522979736, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13864858448505402, KL divergence=0.0587913803756237, Entropy=2.3023993968963623, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.12794481217861176, KL divergence=0.05980308726429939, Entropy=2.292966365814209, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1351841241121292, KL divergence=0.061988938599824905, Entropy=2.3002138137817383, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1385282427072525, KL divergence=0.05989474058151245, Entropy=2.316343307495117, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1350611448287964, KL divergence=0.0621647946536541, Entropy=2.296250343322754, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13914650678634644, KL divergence=0.0593472383916378, Entropy=2.325655698776245, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/47_Step-48250.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/47_Step-48250.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 47
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_47.pb
Best checkpoint number: 31, Last checkpoint number: 45
Copying the frozen checkpoint from ./frozen_models/agent/model_31.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'44'}
Training> Name=main_level/agent, Worker=0, Episode=941, Total reward=0, Steps=48347, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=942, Total reward=0, Steps=48381, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=943, Total reward=0, Steps=48441, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=944, Total reward=0, Steps=48481, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=945, Total reward=0, Steps=48509, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=946, Total reward=0, Steps=48528, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=947, Total reward=0, Steps=48642, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=948, Total reward=0, Steps=48764, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=949, Total reward=0, Steps=48892, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=950, Total reward=0, Steps=48936, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=951, Total reward=0, Steps=48961, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=952, Total reward=0, Steps=48991, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=953, Total reward=0, Steps=49012, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=954, Total reward=0, Steps=49126, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=955, Total reward=0, Steps=49312, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=956, Total reward=0, Steps=49457, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=957, Total reward=0, Steps=49547, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=958, Total reward=0, Steps=49645, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=959, Total reward=0, Steps=49702, Training iteration=47
Training> Name=main_level/agent, Worker=0, Episode=960, Total reward=0, Steps=49765, Training iteration=47
Policy training> Surrogate loss=0.017497796565294266, KL divergence=0.021583613008260727, Entropy=2.321974277496338, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08116522431373596, KL divergence=0.0665712058544159, Entropy=2.3085618019104004, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11785881221294403, KL divergence=0.06428367644548416, Entropy=2.3082339763641357, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12211928516626358, KL divergence=0.06695689260959625, Entropy=2.2901298999786377, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13017131388187408, KL divergence=0.06561441719532013, Entropy=2.2905564308166504, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13342133164405823, KL divergence=0.06543371826410294, Entropy=2.2994885444641113, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.12235604226589203, KL divergence=0.06414778530597687, Entropy=2.3062124252319336, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1312798261642456, KL divergence=0.06523444503545761, Entropy=2.3111953735351562, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.12703807651996613, KL divergence=0.06242318078875542, Entropy=2.333465576171875, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13684067130088806, KL divergence=0.061416663229465485, Entropy=2.3474831581115723, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/48_Step-49765.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/48_Step-49765.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 48
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_48.pb
Best checkpoint number: 46, Last checkpoint number: 46
Copying the frozen checkpoint from ./frozen_models/agent/model_46.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'45'}
Training> Name=main_level/agent, Worker=0, Episode=961, Total reward=0, Steps=49806, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=962, Total reward=0, Steps=49883, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=963, Total reward=0, Steps=49941, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=964, Total reward=0, Steps=49990, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=965, Total reward=0, Steps=50019, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=966, Total reward=0, Steps=50039, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=967, Total reward=0, Steps=50081, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=968, Total reward=0, Steps=50177, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=969, Total reward=0, Steps=50450, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=970, Total reward=0, Steps=50516, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=971, Total reward=0, Steps=50558, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=972, Total reward=0, Steps=50718, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=973, Total reward=0, Steps=50753, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=974, Total reward=0, Steps=50871, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=975, Total reward=0, Steps=51006, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=976, Total reward=0, Steps=51077, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=977, Total reward=0, Steps=51129, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=978, Total reward=0, Steps=51214, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=979, Total reward=0, Steps=51324, Training iteration=48
Training> Name=main_level/agent, Worker=0, Episode=980, Total reward=0, Steps=51419, Training iteration=48
Policy training> Surrogate loss=0.014044161885976791, KL divergence=0.018066363409161568, Entropy=2.3659961223602295, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09319693595170975, KL divergence=0.051471248269081116, Entropy=2.3561301231384277, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.10705426335334778, KL divergence=0.06091226637363434, Entropy=2.3395802974700928, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1225917637348175, KL divergence=0.06262383610010147, Entropy=2.34419584274292, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1352580189704895, KL divergence=0.0634593591094017, Entropy=2.3135695457458496, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14061272144317627, KL divergence=0.061034902930259705, Entropy=2.346514940261841, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.12536311149597168, KL divergence=0.06508854776620865, Entropy=2.34714937210083, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14389710128307343, KL divergence=0.06239838898181915, Entropy=2.3600265979766846, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.12607042491436005, KL divergence=0.06106188893318176, Entropy=2.373979091644287, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1370667964220047, KL divergence=0.060164693742990494, Entropy=2.378544569015503, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/49_Step-51419.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/49_Step-51419.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 49
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_49.pb
Best checkpoint number: 46, Last checkpoint number: 47
Copying the frozen checkpoint from ./frozen_models/agent/model_46.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'47'}
Training> Name=main_level/agent, Worker=0, Episode=981, Total reward=0, Steps=51451, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=982, Total reward=0, Steps=51529, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=983, Total reward=0, Steps=51589, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=984, Total reward=0, Steps=51632, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=985, Total reward=0, Steps=51649, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=986, Total reward=0, Steps=51694, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=987, Total reward=0, Steps=51786, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=988, Total reward=0, Steps=51870, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=989, Total reward=0, Steps=52102, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=990, Total reward=0, Steps=52239, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=991, Total reward=0, Steps=52281, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=992, Total reward=0, Steps=52301, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=993, Total reward=0, Steps=52323, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=994, Total reward=0, Steps=52463, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=995, Total reward=0, Steps=52614, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=996, Total reward=0, Steps=52737, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=997, Total reward=0, Steps=52878, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=998, Total reward=0, Steps=52954, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=999, Total reward=0, Steps=53070, Training iteration=49
Training> Name=main_level/agent, Worker=0, Episode=1000, Total reward=0, Steps=53130, Training iteration=49
Policy training> Surrogate loss=0.00938514806330204, KL divergence=0.026823630556464195, Entropy=2.337462902069092, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08364804089069366, KL divergence=0.06867900490760803, Entropy=2.312908411026001, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1064501628279686, KL divergence=0.06406618654727936, Entropy=2.3168625831604004, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12350426614284515, KL divergence=0.06749548017978668, Entropy=2.3062448501586914, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12726062536239624, KL divergence=0.06764639914035797, Entropy=2.2985477447509766, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1325983852148056, KL divergence=0.06755973398685455, Entropy=2.3294177055358887, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1277705878019333, KL divergence=0.06988415867090225, Entropy=2.3143742084503174, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.133537158370018, KL divergence=0.07087397575378418, Entropy=2.3130910396575928, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1392834335565567, KL divergence=0.0691847875714302, Entropy=2.332137107849121, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1365378051996231, KL divergence=0.0708247572183609, Entropy=2.33097767829895, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/50_Step-53130.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/50_Step-53130.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 50
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_50.pb
Best checkpoint number: 46, Last checkpoint number: 48
Copying the frozen checkpoint from ./frozen_models/agent/model_46.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'31'}
Training> Name=main_level/agent, Worker=0, Episode=1001, Total reward=0, Steps=53186, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1002, Total reward=0, Steps=53261, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1003, Total reward=0, Steps=53286, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1004, Total reward=0, Steps=53323, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1005, Total reward=0, Steps=53386, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1006, Total reward=0, Steps=53510, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1007, Total reward=0, Steps=53617, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1008, Total reward=0, Steps=53800, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1009, Total reward=0, Steps=53852, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1010, Total reward=0, Steps=53915, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1011, Total reward=0, Steps=53937, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1012, Total reward=0, Steps=54154, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1013, Total reward=0, Steps=54236, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1014, Total reward=0, Steps=54279, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1015, Total reward=0, Steps=54467, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1016, Total reward=0, Steps=54505, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1017, Total reward=0, Steps=54564, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1018, Total reward=0, Steps=54634, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1019, Total reward=0, Steps=54694, Training iteration=50
Training> Name=main_level/agent, Worker=0, Episode=1020, Total reward=0, Steps=54722, Training iteration=50
Policy training> Surrogate loss=0.017428837716579437, KL divergence=0.025875715538859367, Entropy=2.297276258468628, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.0842963382601738, KL divergence=0.052728962153196335, Entropy=2.2867863178253174, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.10535792261362076, KL divergence=0.05620051920413971, Entropy=2.3269975185394287, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1232968345284462, KL divergence=0.057301830500364304, Entropy=2.3026840686798096, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12909634411334991, KL divergence=0.06080293655395508, Entropy=2.3033087253570557, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13180620968341827, KL divergence=0.06176495552062988, Entropy=2.2954654693603516, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.12633846700191498, KL divergence=0.05918736383318901, Entropy=2.325922727584839, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.12283971160650253, KL divergence=0.05914810299873352, Entropy=2.334233522415161, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.12610433995723724, KL divergence=0.06025915965437889, Entropy=2.348653793334961, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.12681205570697784, KL divergence=0.06013497710227966, Entropy=2.341359853744507, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/51_Step-54722.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/51_Step-54722.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 51
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_51.pb
Best checkpoint number: 46, Last checkpoint number: 49
Copying the frozen checkpoint from ./frozen_models/agent/model_46.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'48'}
Training> Name=main_level/agent, Worker=0, Episode=1021, Total reward=0, Steps=54811, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1022, Total reward=0, Steps=54917, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1023, Total reward=0, Steps=54957, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1024, Total reward=0, Steps=54992, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1025, Total reward=0, Steps=55039, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1026, Total reward=0, Steps=55083, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1027, Total reward=0, Steps=55201, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1028, Total reward=0, Steps=55251, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1029, Total reward=0, Steps=55334, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1030, Total reward=0, Steps=55473, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1031, Total reward=0, Steps=55567, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1032, Total reward=0, Steps=55605, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1033, Total reward=0, Steps=55743, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1034, Total reward=0, Steps=55782, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1035, Total reward=0, Steps=55814, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1036, Total reward=0, Steps=55843, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1037, Total reward=0, Steps=55888, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1038, Total reward=0, Steps=55925, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1039, Total reward=0, Steps=56037, Training iteration=51
Training> Name=main_level/agent, Worker=0, Episode=1040, Total reward=0, Steps=56133, Training iteration=51
Policy training> Surrogate loss=0.018317965790629387, KL divergence=0.028176002204418182, Entropy=2.2736308574676514, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09128546714782715, KL divergence=0.06041388586163521, Entropy=2.2425451278686523, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1144939586520195, KL divergence=0.070297010242939, Entropy=2.2417690753936768, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12654775381088257, KL divergence=0.06514196842908859, Entropy=2.2345314025878906, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13305114209651947, KL divergence=0.06708072870969772, Entropy=2.2511165142059326, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1326562762260437, KL divergence=0.06903618574142456, Entropy=2.2484610080718994, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13341973721981049, KL divergence=0.06869804114103317, Entropy=2.249319314956665, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13640576601028442, KL divergence=0.06751631945371628, Entropy=2.264876365661621, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1372521072626114, KL divergence=0.06661126762628555, Entropy=2.2760937213897705, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13756385445594788, KL divergence=0.06624578684568405, Entropy=2.283241033554077, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/52_Step-56133.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/52_Step-56133.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 52
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_52.pb
Best checkpoint number: 46, Last checkpoint number: 50
Copying the frozen checkpoint from ./frozen_models/agent/model_46.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'49'}
Training> Name=main_level/agent, Worker=0, Episode=1041, Total reward=0, Steps=56208, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1042, Total reward=0, Steps=56283, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1043, Total reward=0, Steps=56342, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1044, Total reward=0, Steps=56373, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1045, Total reward=0, Steps=56408, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1046, Total reward=0, Steps=56505, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1047, Total reward=0, Steps=56589, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1048, Total reward=0, Steps=56671, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1049, Total reward=0, Steps=56733, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1050, Total reward=0, Steps=56830, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1051, Total reward=0, Steps=56853, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1052, Total reward=0, Steps=57016, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1053, Total reward=0, Steps=57207, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1054, Total reward=0, Steps=57245, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1055, Total reward=0, Steps=57279, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1056, Total reward=0, Steps=57381, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1057, Total reward=0, Steps=57406, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1058, Total reward=0, Steps=57514, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1059, Total reward=0, Steps=57631, Training iteration=52
Training> Name=main_level/agent, Worker=0, Episode=1060, Total reward=0, Steps=57711, Training iteration=52
Policy training> Surrogate loss=0.019794845953583717, KL divergence=0.02069888822734356, Entropy=2.334707498550415, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.0976283922791481, KL divergence=0.05458590388298035, Entropy=2.2826154232025146, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12314683198928833, KL divergence=0.05879766121506691, Entropy=2.3050239086151123, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12948139011859894, KL divergence=0.062196239829063416, Entropy=2.311537504196167, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1324731409549713, KL divergence=0.0625753179192543, Entropy=2.2841131687164307, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13397203385829926, KL divergence=0.06273447722196579, Entropy=2.2946064472198486, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.14222726225852966, KL divergence=0.06461413204669952, Entropy=2.2959144115448, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13295920193195343, KL divergence=0.0650162398815155, Entropy=2.299428701400757, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.12830626964569092, KL divergence=0.06549743562936783, Entropy=2.32118821144104, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13856838643550873, KL divergence=0.06707128882408142, Entropy=2.3053057193756104, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/53_Step-57711.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/53_Step-57711.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 53
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_53.pb
Best checkpoint number: 46, Last checkpoint number: 51
Copying the frozen checkpoint from ./frozen_models/agent/model_46.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'50'}
Training> Name=main_level/agent, Worker=0, Episode=1061, Total reward=0, Steps=57757, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1062, Total reward=0, Steps=57778, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1063, Total reward=0, Steps=57813, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1064, Total reward=0, Steps=58052, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1065, Total reward=0, Steps=58077, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1066, Total reward=0, Steps=58172, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1067, Total reward=0, Steps=58353, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1068, Total reward=0, Steps=58502, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1069, Total reward=0, Steps=58554, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1070, Total reward=0, Steps=58596, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1071, Total reward=0, Steps=58646, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1072, Total reward=0, Steps=58676, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1073, Total reward=0, Steps=58732, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1074, Total reward=0, Steps=58825, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1075, Total reward=0, Steps=59078, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1076, Total reward=0, Steps=59193, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1077, Total reward=0, Steps=59358, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1078, Total reward=0, Steps=59432, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1079, Total reward=0, Steps=59555, Training iteration=53
Training> Name=main_level/agent, Worker=0, Episode=1080, Total reward=0, Steps=59660, Training iteration=53
Policy training> Surrogate loss=0.02392769604921341, KL divergence=0.040087293833494186, Entropy=2.2552995681762695, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08045734465122223, KL divergence=0.06383506208658218, Entropy=2.174699068069458, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11182615160942078, KL divergence=0.07079591602087021, Entropy=2.214402914047241, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1288561373949051, KL divergence=0.06733466684818268, Entropy=2.2014496326446533, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13199765980243683, KL divergence=0.07159876078367233, Entropy=2.1876144409179688, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13297609984874725, KL divergence=0.06955692917108536, Entropy=2.218641757965088, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1331007480621338, KL divergence=0.07092375308275223, Entropy=2.2136237621307373, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13593269884586334, KL divergence=0.0678773894906044, Entropy=2.2346789836883545, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14002183079719543, KL divergence=0.06816551834344864, Entropy=2.245884418487549, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13411475718021393, KL divergence=0.06807787716388702, Entropy=2.250786066055298, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/54_Step-59660.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/54_Step-59660.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 54
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_54.pb
Best checkpoint number: 46, Last checkpoint number: 52
Copying the frozen checkpoint from ./frozen_models/agent/model_46.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'51'}
Training> Name=main_level/agent, Worker=0, Episode=1081, Total reward=0, Steps=59694, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1082, Total reward=0, Steps=59776, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1083, Total reward=0, Steps=59831, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1084, Total reward=0, Steps=59886, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1085, Total reward=0, Steps=59919, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1086, Total reward=0, Steps=60101, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1087, Total reward=0, Steps=60306, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1088, Total reward=0, Steps=60332, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1089, Total reward=0, Steps=60410, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1090, Total reward=0, Steps=60469, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1091, Total reward=0, Steps=60612, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1092, Total reward=0, Steps=60848, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1093, Total reward=0, Steps=61038, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1094, Total reward=0, Steps=61207, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1095, Total reward=0, Steps=61262, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1096, Total reward=0, Steps=61361, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1097, Total reward=0, Steps=61470, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1098, Total reward=0, Steps=61518, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1099, Total reward=0, Steps=61597, Training iteration=54
Training> Name=main_level/agent, Worker=0, Episode=1100, Total reward=0, Steps=61623, Training iteration=54
Policy training> Surrogate loss=0.022434543818235397, KL divergence=0.032816823571920395, Entropy=2.2638208866119385, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08596571534872055, KL divergence=0.07179834693670273, Entropy=2.1922197341918945, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.10975616425275803, KL divergence=0.07536127418279648, Entropy=2.210742473602295, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12114706635475159, KL divergence=0.0721902847290039, Entropy=2.220064401626587, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12479550391435623, KL divergence=0.07155559211969376, Entropy=2.216524362564087, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13123482465744019, KL divergence=0.07025232166051865, Entropy=2.237298011779785, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.130715474486351, KL divergence=0.06918177008628845, Entropy=2.237429618835449, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1381785124540329, KL divergence=0.06915069371461868, Entropy=2.2383902072906494, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13981275260448456, KL divergence=0.06925638020038605, Entropy=2.2398931980133057, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1425948441028595, KL divergence=0.06764035671949387, Entropy=2.242535352706909, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/55_Step-61623.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/55_Step-61623.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 55
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_55.pb
Best checkpoint number: 46, Last checkpoint number: 53
Copying the frozen checkpoint from ./frozen_models/agent/model_46.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'52'}
Training> Name=main_level/agent, Worker=0, Episode=1101, Total reward=0, Steps=61696, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1102, Total reward=0, Steps=61726, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1103, Total reward=0, Steps=61793, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1104, Total reward=0, Steps=61863, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1105, Total reward=0, Steps=61923, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1106, Total reward=0, Steps=62001, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1107, Total reward=0, Steps=62042, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1108, Total reward=0, Steps=62126, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1109, Total reward=0, Steps=62285, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1110, Total reward=0, Steps=62484, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1111, Total reward=0, Steps=62573, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1112, Total reward=0, Steps=62636, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1113, Total reward=0, Steps=62798, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1114, Total reward=0, Steps=62892, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1115, Total reward=0, Steps=62944, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1116, Total reward=0, Steps=63266, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1117, Total reward=0, Steps=63309, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1118, Total reward=0, Steps=63404, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1119, Total reward=0, Steps=63497, Training iteration=55
Training> Name=main_level/agent, Worker=0, Episode=1120, Total reward=0, Steps=63543, Training iteration=55
Policy training> Surrogate loss=0.008848439902067184, KL divergence=0.030397694557905197, Entropy=2.1472010612487793, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09000030159950256, KL divergence=0.08752263337373734, Entropy=2.1371400356292725, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1190652847290039, KL divergence=0.08253743499517441, Entropy=2.1317594051361084, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12707072496414185, KL divergence=0.07962686568498611, Entropy=2.1713805198669434, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13214026391506195, KL divergence=0.08041740953922272, Entropy=2.154139995574951, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13514254987239838, KL divergence=0.07899883389472961, Entropy=2.1576991081237793, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13689765334129333, KL divergence=0.07875200361013412, Entropy=2.1632585525512695, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13776476681232452, KL divergence=0.07926224172115326, Entropy=2.1648449897766113, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13873815536499023, KL divergence=0.07986802607774734, Entropy=2.1742403507232666, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13911722600460052, KL divergence=0.07854633778333664, Entropy=2.1786413192749023, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/56_Step-63543.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/56_Step-63543.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 56
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_56.pb
Best checkpoint number: 46, Last checkpoint number: 54
Copying the frozen checkpoint from ./frozen_models/agent/model_46.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'53'}
Training> Name=main_level/agent, Worker=0, Episode=1121, Total reward=0, Steps=63682, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1122, Total reward=0, Steps=63752, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1123, Total reward=0, Steps=63818, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1124, Total reward=0, Steps=63879, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1125, Total reward=0, Steps=63906, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1126, Total reward=0, Steps=63943, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1127, Total reward=0, Steps=63972, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1128, Total reward=0, Steps=64174, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1129, Total reward=0, Steps=64393, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1130, Total reward=0, Steps=64491, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1131, Total reward=0, Steps=64675, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1132, Total reward=0, Steps=64896, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1133, Total reward=0, Steps=64951, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1134, Total reward=0, Steps=65108, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1135, Total reward=0, Steps=65178, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1136, Total reward=0, Steps=65316, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1137, Total reward=0, Steps=65394, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1138, Total reward=0, Steps=65468, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1139, Total reward=0, Steps=65567, Training iteration=56
Training> Name=main_level/agent, Worker=0, Episode=1140, Total reward=0, Steps=65616, Training iteration=56
Policy training> Surrogate loss=0.014829151332378387, KL divergence=0.0192999467253685, Entropy=2.1989152431488037, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.0900183618068695, KL divergence=0.06409565359354019, Entropy=2.1895456314086914, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11409062147140503, KL divergence=0.07054413855075836, Entropy=2.1294007301330566, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12669526040554047, KL divergence=0.06879018247127533, Entropy=2.164914131164551, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13180650770664215, KL divergence=0.07180353999137878, Entropy=2.1544852256774902, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.12983812391757965, KL divergence=0.06988413631916046, Entropy=2.15625, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13014596700668335, KL divergence=0.07091844826936722, Entropy=2.158371925354004, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13418525457382202, KL divergence=0.07111060619354248, Entropy=2.159789800643921, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13824915885925293, KL divergence=0.07278066873550415, Entropy=2.1669459342956543, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13423947989940643, KL divergence=0.07192966341972351, Entropy=2.178562641143799, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/57_Step-65616.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/57_Step-65616.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 57
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_57.pb
Best checkpoint number: 46, Last checkpoint number: 55
Copying the frozen checkpoint from ./frozen_models/agent/model_46.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'54'}
Training> Name=main_level/agent, Worker=0, Episode=1141, Total reward=0, Steps=65702, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1142, Total reward=0, Steps=65749, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1143, Total reward=0, Steps=65812, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1144, Total reward=0, Steps=65866, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1145, Total reward=0, Steps=65895, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1146, Total reward=0, Steps=65914, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1147, Total reward=0, Steps=66032, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1148, Total reward=0, Steps=66108, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1149, Total reward=0, Steps=66165, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1150, Total reward=0, Steps=66320, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1151, Total reward=0, Steps=66474, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1152, Total reward=0, Steps=66507, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1153, Total reward=0, Steps=66631, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1154, Total reward=0, Steps=66686, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1155, Total reward=0, Steps=66782, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1156, Total reward=0, Steps=66890, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1157, Total reward=0, Steps=66955, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1158, Total reward=0, Steps=67026, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1159, Total reward=0, Steps=67092, Training iteration=57
Training> Name=main_level/agent, Worker=0, Episode=1160, Total reward=0, Steps=67151, Training iteration=57
Policy training> Surrogate loss=0.0025076898746192455, KL divergence=0.020426560193300247, Entropy=2.209021806716919, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08485116809606552, KL divergence=0.060854870826005936, Entropy=2.1660306453704834, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11150871217250824, KL divergence=0.066581591963768, Entropy=2.1761436462402344, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1249888688325882, KL divergence=0.06776460260152817, Entropy=2.1353344917297363, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12389364093542099, KL divergence=0.07361581176519394, Entropy=2.144380807876587, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1345875859260559, KL divergence=0.07228124886751175, Entropy=2.1708452701568604, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13146564364433289, KL divergence=0.07315624505281448, Entropy=2.147063970565796, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13297896087169647, KL divergence=0.07442260533571243, Entropy=2.174105644226074, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13693049550056458, KL divergence=0.07332058995962143, Entropy=2.175821304321289, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.12517262995243073, KL divergence=0.07342296838760376, Entropy=2.191906690597534, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/58_Step-67151.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/58_Step-67151.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 58
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_58.pb
Best checkpoint number: 46, Last checkpoint number: 56
Copying the frozen checkpoint from ./frozen_models/agent/model_46.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'55'}
Training> Name=main_level/agent, Worker=0, Episode=1161, Total reward=0, Steps=67245, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1162, Total reward=0, Steps=67272, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1163, Total reward=0, Steps=67335, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1164, Total reward=0, Steps=67373, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1165, Total reward=0, Steps=67453, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1166, Total reward=0, Steps=67493, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1167, Total reward=0, Steps=67526, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1168, Total reward=0, Steps=67595, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1169, Total reward=0, Steps=67650, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1170, Total reward=0, Steps=67718, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1171, Total reward=0, Steps=67764, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1172, Total reward=0, Steps=67795, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1173, Total reward=0, Steps=67836, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1174, Total reward=0, Steps=67973, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1175, Total reward=0, Steps=68068, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1176, Total reward=0, Steps=68143, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1177, Total reward=0, Steps=68214, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1178, Total reward=0, Steps=68303, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1179, Total reward=0, Steps=68416, Training iteration=58
Training> Name=main_level/agent, Worker=0, Episode=1180, Total reward=0, Steps=68471, Training iteration=58
Policy training> Surrogate loss=0.008360354229807854, KL divergence=0.016302019357681274, Entropy=2.31522798538208, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08862243592739105, KL divergence=0.061873454600572586, Entropy=2.2832086086273193, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11317002773284912, KL divergence=0.06875181198120117, Entropy=2.30204176902771, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1320984661579132, KL divergence=0.07095682621002197, Entropy=2.287912607192993, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1298414170742035, KL divergence=0.07079458236694336, Entropy=2.290996551513672, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13182227313518524, KL divergence=0.07127714902162552, Entropy=2.272351026535034, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13721999526023865, KL divergence=0.06753983348608017, Entropy=2.3033509254455566, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13821899890899658, KL divergence=0.06706757098436356, Entropy=2.298429012298584, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13646551966667175, KL divergence=0.06780409812927246, Entropy=2.311542510986328, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13653329014778137, KL divergence=0.06784196943044662, Entropy=2.332043409347534, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/59_Step-68471.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/59_Step-68471.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 59
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_59.pb
Best checkpoint number: 57, Last checkpoint number: 57
Copying the frozen checkpoint from ./frozen_models/agent/model_57.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'56'}
Training> Name=main_level/agent, Worker=0, Episode=1181, Total reward=0, Steps=68515, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1182, Total reward=0, Steps=68557, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1183, Total reward=0, Steps=68651, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1184, Total reward=0, Steps=68685, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1185, Total reward=0, Steps=68715, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1186, Total reward=0, Steps=68756, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1187, Total reward=0, Steps=68875, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1188, Total reward=0, Steps=68947, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1189, Total reward=0, Steps=68979, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1190, Total reward=0, Steps=69056, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1191, Total reward=0, Steps=69169, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1192, Total reward=0, Steps=69219, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1193, Total reward=0, Steps=69339, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1194, Total reward=0, Steps=69448, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1195, Total reward=0, Steps=69489, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1196, Total reward=0, Steps=69537, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1197, Total reward=0, Steps=69572, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1198, Total reward=0, Steps=69683, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1199, Total reward=0, Steps=69784, Training iteration=59
Training> Name=main_level/agent, Worker=0, Episode=1200, Total reward=0, Steps=69892, Training iteration=59
Policy training> Surrogate loss=0.0288117416203022, KL divergence=0.02065502293407917, Entropy=2.2557551860809326, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.0986035093665123, KL divergence=0.05885152518749237, Entropy=2.234189748764038, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11788540333509445, KL divergence=0.06542696803808212, Entropy=2.229412794113159, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12407840043306351, KL divergence=0.06639416515827179, Entropy=2.226656913757324, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12463903427124023, KL divergence=0.06454608589410782, Entropy=2.256669521331787, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.133492574095726, KL divergence=0.06625282019376755, Entropy=2.242482900619507, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13240931928157806, KL divergence=0.06409420818090439, Entropy=2.261286735534668, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.12916089594364166, KL divergence=0.06644129008054733, Entropy=2.2690281867980957, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1337893009185791, KL divergence=0.0644543319940567, Entropy=2.2755937576293945, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13305312395095825, KL divergence=0.06643759459257126, Entropy=2.2792489528656006, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/60_Step-69892.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/60_Step-69892.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 60
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_60.pb
Best checkpoint number: 57, Last checkpoint number: 58
Copying the frozen checkpoint from ./frozen_models/agent/model_57.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'46'}
Training> Name=main_level/agent, Worker=0, Episode=1201, Total reward=0, Steps=69990, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1202, Total reward=0, Steps=70025, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1203, Total reward=0, Steps=70084, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1204, Total reward=0, Steps=70128, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1205, Total reward=0, Steps=70162, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1206, Total reward=0, Steps=70192, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1207, Total reward=0, Steps=70235, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1208, Total reward=0, Steps=70297, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1209, Total reward=0, Steps=70445, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1210, Total reward=0, Steps=70582, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1211, Total reward=0, Steps=70694, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1212, Total reward=0, Steps=70818, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1213, Total reward=0, Steps=71005, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1214, Total reward=0, Steps=71033, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1215, Total reward=0, Steps=71105, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1216, Total reward=0, Steps=71233, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1217, Total reward=0, Steps=71267, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1218, Total reward=0, Steps=71368, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1219, Total reward=0, Steps=71469, Training iteration=60
Training> Name=main_level/agent, Worker=0, Episode=1220, Total reward=0, Steps=71529, Training iteration=60
Policy training> Surrogate loss=0.007985664531588554, KL divergence=0.023257456719875336, Entropy=2.3410332202911377, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09090601652860641, KL divergence=0.05996910110116005, Entropy=2.3315067291259766, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1187550351023674, KL divergence=0.06544453650712967, Entropy=2.2888002395629883, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13089877367019653, KL divergence=0.0630824938416481, Entropy=2.328606605529785, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13673175871372223, KL divergence=0.06494630873203278, Entropy=2.3351054191589355, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13208967447280884, KL divergence=0.06349290162324905, Entropy=2.3533153533935547, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13517147302627563, KL divergence=0.06579828262329102, Entropy=2.361008644104004, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1387024074792862, KL divergence=0.06859046220779419, Entropy=2.3601956367492676, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14315560460090637, KL divergence=0.0692385733127594, Entropy=2.3306729793548584, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1363767832517624, KL divergence=0.06820178031921387, Entropy=2.3674471378326416, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/61_Step-71529.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/61_Step-71529.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 61
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_61.pb
Best checkpoint number: 57, Last checkpoint number: 59
Copying the frozen checkpoint from ./frozen_models/agent/model_57.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'58'}
Training> Name=main_level/agent, Worker=0, Episode=1221, Total reward=0, Steps=71621, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1222, Total reward=0, Steps=71698, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1223, Total reward=0, Steps=71812, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1224, Total reward=0, Steps=71869, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1225, Total reward=0, Steps=71897, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1226, Total reward=0, Steps=71914, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1227, Total reward=0, Steps=71979, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1228, Total reward=0, Steps=72158, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1229, Total reward=0, Steps=72188, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1230, Total reward=0, Steps=72246, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1231, Total reward=0, Steps=72270, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1232, Total reward=0, Steps=72388, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1233, Total reward=0, Steps=72416, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1234, Total reward=0, Steps=72619, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1235, Total reward=0, Steps=72795, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1236, Total reward=0, Steps=72853, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1237, Total reward=0, Steps=72960, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1238, Total reward=0, Steps=72989, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1239, Total reward=0, Steps=73023, Training iteration=61
Training> Name=main_level/agent, Worker=0, Episode=1240, Total reward=0, Steps=73069, Training iteration=61
Policy training> Surrogate loss=0.014933978207409382, KL divergence=0.02225085161626339, Entropy=2.3160934448242188, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09236320108175278, KL divergence=0.05650676414370537, Entropy=2.3473517894744873, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1181027889251709, KL divergence=0.05776669457554817, Entropy=2.3082258701324463, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12860965728759766, KL divergence=0.0539817251265049, Entropy=2.3230514526367188, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13102395832538605, KL divergence=0.056811969727277756, Entropy=2.331275224685669, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13420729339122772, KL divergence=0.058985475450754166, Entropy=2.3216552734375, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13556309044361115, KL divergence=0.05883024260401726, Entropy=2.3551042079925537, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13682009279727936, KL divergence=0.06373488157987595, Entropy=2.307978630065918, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13642819225788116, KL divergence=0.06081795692443848, Entropy=2.3451192378997803, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1350036859512329, KL divergence=0.06248043105006218, Entropy=2.343470335006714, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/62_Step-73069.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/62_Step-73069.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 62
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_62.pb
Best checkpoint number: 57, Last checkpoint number: 60
Copying the frozen checkpoint from ./frozen_models/agent/model_57.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'59'}
Training> Name=main_level/agent, Worker=0, Episode=1241, Total reward=0, Steps=73211, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1242, Total reward=0, Steps=73297, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1243, Total reward=0, Steps=73352, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1244, Total reward=0, Steps=73427, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1245, Total reward=0, Steps=73481, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1246, Total reward=0, Steps=73591, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1247, Total reward=0, Steps=73852, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1248, Total reward=0, Steps=73921, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1249, Total reward=0, Steps=73946, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1250, Total reward=0, Steps=73998, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1251, Total reward=0, Steps=74026, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1252, Total reward=0, Steps=74127, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1253, Total reward=0, Steps=74344, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1254, Total reward=0, Steps=74536, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1255, Total reward=0, Steps=74703, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1256, Total reward=0, Steps=74871, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1257, Total reward=0, Steps=74917, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1258, Total reward=0, Steps=75064, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1259, Total reward=0, Steps=75122, Training iteration=62
Training> Name=main_level/agent, Worker=0, Episode=1260, Total reward=0, Steps=75227, Training iteration=62
Policy training> Surrogate loss=0.011719807982444763, KL divergence=0.027442878112196922, Entropy=2.3023834228515625, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08821582049131393, KL divergence=0.05598839372396469, Entropy=2.305694580078125, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11955922842025757, KL divergence=0.052763741463422775, Entropy=2.2762882709503174, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12588192522525787, KL divergence=0.05635366216301918, Entropy=2.2786734104156494, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.131393164396286, KL divergence=0.056801021099090576, Entropy=2.2830278873443604, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13616003096103668, KL divergence=0.05690848454833031, Entropy=2.2910947799682617, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13231481611728668, KL divergence=0.057445500046014786, Entropy=2.309861183166504, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13848362863063812, KL divergence=0.058214642107486725, Entropy=2.3167150020599365, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1376149207353592, KL divergence=0.05832085385918617, Entropy=2.318749189376831, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13696353137493134, KL divergence=0.05776000767946243, Entropy=2.3404746055603027, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/63_Step-75227.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/63_Step-75227.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 63
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_63.pb
Best checkpoint number: 57, Last checkpoint number: 61
Copying the frozen checkpoint from ./frozen_models/agent/model_57.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'60'}
Training> Name=main_level/agent, Worker=0, Episode=1261, Total reward=0, Steps=75312, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1262, Total reward=0, Steps=75358, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1263, Total reward=0, Steps=75431, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1264, Total reward=0, Steps=75474, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1265, Total reward=0, Steps=75532, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1266, Total reward=0, Steps=75802, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1267, Total reward=0, Steps=75904, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1268, Total reward=0, Steps=76023, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1269, Total reward=0, Steps=76100, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1270, Total reward=0, Steps=76168, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1271, Total reward=0, Steps=76190, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1272, Total reward=0, Steps=76324, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1273, Total reward=0, Steps=76497, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1274, Total reward=0, Steps=76593, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1275, Total reward=0, Steps=76687, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1276, Total reward=0, Steps=76716, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1277, Total reward=0, Steps=76801, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1278, Total reward=0, Steps=76989, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1279, Total reward=0, Steps=77066, Training iteration=63
Training> Name=main_level/agent, Worker=0, Episode=1280, Total reward=0, Steps=77173, Training iteration=63
Policy training> Surrogate loss=0.011496875435113907, KL divergence=0.021240347996354103, Entropy=2.3694493770599365, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08930106461048126, KL divergence=0.054921917617321014, Entropy=2.3505990505218506, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12004774063825607, KL divergence=0.05788310244679451, Entropy=2.311028480529785, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12636798620224, KL divergence=0.057067833840847015, Entropy=2.3105874061584473, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12627415359020233, KL divergence=0.05689667537808418, Entropy=2.3070030212402344, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1307528018951416, KL divergence=0.05774533748626709, Entropy=2.308950185775757, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.12389950454235077, KL divergence=0.05801768973469734, Entropy=2.307525396347046, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1329856961965561, KL divergence=0.058462612330913544, Entropy=2.312985420227051, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13332341611385345, KL divergence=0.057559989392757416, Entropy=2.318150281906128, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1342272162437439, KL divergence=0.05834097042679787, Entropy=2.330989360809326, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/64_Step-77173.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/64_Step-77173.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 64
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_64.pb
Best checkpoint number: 57, Last checkpoint number: 62
Copying the frozen checkpoint from ./frozen_models/agent/model_57.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'61'}
Training> Name=main_level/agent, Worker=0, Episode=1281, Total reward=0, Steps=77266, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1282, Total reward=0, Steps=77313, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1283, Total reward=0, Steps=77348, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1284, Total reward=0, Steps=77397, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1285, Total reward=0, Steps=77425, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1286, Total reward=0, Steps=77505, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1287, Total reward=0, Steps=77807, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1288, Total reward=0, Steps=77870, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1289, Total reward=0, Steps=77927, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1290, Total reward=0, Steps=78081, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1291, Total reward=0, Steps=78190, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1292, Total reward=0, Steps=78210, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1293, Total reward=0, Steps=78273, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1294, Total reward=0, Steps=78330, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1295, Total reward=0, Steps=78383, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1296, Total reward=0, Steps=78464, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1297, Total reward=0, Steps=78526, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1298, Total reward=0, Steps=78574, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1299, Total reward=0, Steps=78873, Training iteration=64
Training> Name=main_level/agent, Worker=0, Episode=1300, Total reward=0, Steps=78984, Training iteration=64
Policy training> Surrogate loss=0.015571758151054382, KL divergence=0.01989246904850006, Entropy=2.3285603523254395, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09348015487194061, KL divergence=0.0585046112537384, Entropy=2.312751531600952, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11687786877155304, KL divergence=0.05666341260075569, Entropy=2.3477165699005127, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12923981249332428, KL divergence=0.05656440183520317, Entropy=2.3519561290740967, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1311608999967575, KL divergence=0.057109106332063675, Entropy=2.3367652893066406, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13623328506946564, KL divergence=0.05659475550055504, Entropy=2.3445794582366943, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13481754064559937, KL divergence=0.05819563940167427, Entropy=2.343355894088745, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1384396255016327, KL divergence=0.05767926573753357, Entropy=2.352174997329712, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1358143836259842, KL divergence=0.05716204270720482, Entropy=2.3651866912841797, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1373956948518753, KL divergence=0.05681540444493294, Entropy=2.3697471618652344, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/65_Step-78984.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/65_Step-78984.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 65
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_65.pb
Best checkpoint number: 57, Last checkpoint number: 63
Copying the frozen checkpoint from ./frozen_models/agent/model_57.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'62'}
Training> Name=main_level/agent, Worker=0, Episode=1301, Total reward=0, Steps=79081, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1302, Total reward=0, Steps=79116, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1303, Total reward=0, Steps=79149, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1304, Total reward=0, Steps=79200, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1305, Total reward=0, Steps=79232, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1306, Total reward=0, Steps=79251, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1307, Total reward=0, Steps=79336, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1308, Total reward=0, Steps=79391, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1309, Total reward=0, Steps=79437, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1310, Total reward=0, Steps=79594, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1311, Total reward=0, Steps=79621, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1312, Total reward=0, Steps=79666, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1313, Total reward=0, Steps=79689, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1314, Total reward=0, Steps=79744, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1315, Total reward=0, Steps=79774, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1316, Total reward=0, Steps=79825, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1317, Total reward=0, Steps=79886, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1318, Total reward=0, Steps=79979, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1319, Total reward=0, Steps=80001, Training iteration=65
Training> Name=main_level/agent, Worker=0, Episode=1320, Total reward=0, Steps=80063, Training iteration=65
Policy training> Surrogate loss=0.0018890462815761566, KL divergence=0.014265907928347588, Entropy=2.3090951442718506, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09451359510421753, KL divergence=0.04331508278846741, Entropy=2.343027353286743, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12529878318309784, KL divergence=0.055686481297016144, Entropy=2.308079242706299, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12750080227851868, KL divergence=0.05974076688289642, Entropy=2.33168363571167, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1438179910182953, KL divergence=0.075153648853302, Entropy=2.2412288188934326, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1354730725288391, KL divergence=0.06328792870044708, Entropy=2.3167033195495605, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1361510306596756, KL divergence=0.06231977790594101, Entropy=2.322486639022827, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1270865947008133, KL divergence=0.059819113463163376, Entropy=2.332200288772583, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14554063975811005, KL divergence=0.0615386962890625, Entropy=2.3297104835510254, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13082504272460938, KL divergence=0.061270616948604584, Entropy=2.3215246200561523, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/66_Step-80063.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/66_Step-80063.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 66
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_66.pb
Best checkpoint number: 57, Last checkpoint number: 64
Copying the frozen checkpoint from ./frozen_models/agent/model_57.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'63'}
Training> Name=main_level/agent, Worker=0, Episode=1321, Total reward=0, Steps=80151, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1322, Total reward=0, Steps=80233, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1323, Total reward=0, Steps=80298, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1324, Total reward=0, Steps=80339, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1325, Total reward=0, Steps=80399, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1326, Total reward=0, Steps=80439, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1327, Total reward=0, Steps=80511, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1328, Total reward=0, Steps=80589, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1329, Total reward=0, Steps=80701, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1330, Total reward=0, Steps=80746, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1331, Total reward=0, Steps=80818, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1332, Total reward=0, Steps=80970, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1333, Total reward=0, Steps=81145, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1334, Total reward=0, Steps=81292, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1335, Total reward=0, Steps=81323, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1336, Total reward=0, Steps=81363, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1337, Total reward=0, Steps=81463, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1338, Total reward=0, Steps=81579, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1339, Total reward=0, Steps=81658, Training iteration=66
Training> Name=main_level/agent, Worker=0, Episode=1340, Total reward=0, Steps=81690, Training iteration=66
Policy training> Surrogate loss=0.014748807065188885, KL divergence=0.024485768750309944, Entropy=2.200385570526123, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.10020659118890762, KL divergence=0.07237447053194046, Entropy=2.202016830444336, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11675051599740982, KL divergence=0.07648295164108276, Entropy=2.181323528289795, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12685243785381317, KL divergence=0.07429298758506775, Entropy=2.211658477783203, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13480547070503235, KL divergence=0.07343354821205139, Entropy=2.2251994609832764, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13340386748313904, KL divergence=0.08100917190313339, Entropy=2.201960563659668, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1304590255022049, KL divergence=0.07798407226800919, Entropy=2.231302499771118, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13807904720306396, KL divergence=0.08483409881591797, Entropy=2.2287185192108154, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1352423131465912, KL divergence=0.08254288882017136, Entropy=2.2459158897399902, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13588283956050873, KL divergence=0.08149035274982452, Entropy=2.2550840377807617, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/67_Step-81690.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/67_Step-81690.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 67
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_67.pb
Best checkpoint number: 57, Last checkpoint number: 65
Copying the frozen checkpoint from ./frozen_models/agent/model_57.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'64'}
Training> Name=main_level/agent, Worker=0, Episode=1341, Total reward=0, Steps=81783, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1342, Total reward=0, Steps=81856, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1343, Total reward=0, Steps=81888, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1344, Total reward=0, Steps=81963, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1345, Total reward=0, Steps=81983, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1346, Total reward=0, Steps=82215, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1347, Total reward=0, Steps=82246, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1348, Total reward=0, Steps=82392, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1349, Total reward=0, Steps=82546, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1350, Total reward=0, Steps=82785, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1351, Total reward=0, Steps=82918, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1352, Total reward=0, Steps=83112, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1353, Total reward=0, Steps=83155, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1354, Total reward=0, Steps=83441, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1355, Total reward=0, Steps=83525, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1356, Total reward=0, Steps=83688, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1357, Total reward=0, Steps=83800, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1358, Total reward=0, Steps=83887, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1359, Total reward=0, Steps=83962, Training iteration=67
Training> Name=main_level/agent, Worker=0, Episode=1360, Total reward=0, Steps=84026, Training iteration=67
Policy training> Surrogate loss=0.015990592539310455, KL divergence=0.028733322396874428, Entropy=2.3129801750183105, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.08832281827926636, KL divergence=0.06180260702967644, Entropy=2.2946457862854004, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1093817949295044, KL divergence=0.0553402379155159, Entropy=2.302403688430786, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12452176213264465, KL divergence=0.05824432149529457, Entropy=2.3065404891967773, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12449802458286285, KL divergence=0.06326184421777725, Entropy=2.3139376640319824, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1271630972623825, KL divergence=0.06090768054127693, Entropy=2.3224923610687256, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13448067009449005, KL divergence=0.06088176742196083, Entropy=2.3309240341186523, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1364978551864624, KL divergence=0.06239333376288414, Entropy=2.335385322570801, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13584552705287933, KL divergence=0.062005415558815, Entropy=2.3343393802642822, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13445954024791718, KL divergence=0.06309579312801361, Entropy=2.3398518562316895, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/68_Step-84026.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/68_Step-84026.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 68
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_68.pb
Best checkpoint number: 57, Last checkpoint number: 66
Copying the frozen checkpoint from ./frozen_models/agent/model_57.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'65'}
Training> Name=main_level/agent, Worker=0, Episode=1361, Total reward=0, Steps=84074, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1362, Total reward=0, Steps=84138, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1363, Total reward=0, Steps=84217, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1364, Total reward=0, Steps=84290, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1365, Total reward=0, Steps=84327, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1366, Total reward=0, Steps=84383, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1367, Total reward=0, Steps=84502, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1368, Total reward=0, Steps=84546, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1369, Total reward=0, Steps=84714, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1370, Total reward=0, Steps=84757, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1371, Total reward=0, Steps=84904, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1372, Total reward=0, Steps=84948, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1373, Total reward=0, Steps=84998, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1374, Total reward=0, Steps=85020, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1375, Total reward=0, Steps=85124, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1376, Total reward=0, Steps=85167, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1377, Total reward=0, Steps=85320, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1378, Total reward=0, Steps=85359, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1379, Total reward=0, Steps=85430, Training iteration=68
Training> Name=main_level/agent, Worker=0, Episode=1380, Total reward=0, Steps=85475, Training iteration=68
Policy training> Surrogate loss=0.003796627977862954, KL divergence=0.026277489960193634, Entropy=2.332540512084961, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.10599574446678162, KL divergence=0.06794994324445724, Entropy=2.302408218383789, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11796390265226364, KL divergence=0.06332702934741974, Entropy=2.3212296962738037, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13127435743808746, KL divergence=0.07583007216453552, Entropy=2.2508554458618164, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1361539363861084, KL divergence=0.06689861416816711, Entropy=2.306485176086426, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13752685487270355, KL divergence=0.0646904781460762, Entropy=2.306466817855835, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1332375556230545, KL divergence=0.06405552476644516, Entropy=2.314368963241577, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.15024825930595398, KL divergence=0.06288226693868637, Entropy=2.3096988201141357, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1422906517982483, KL divergence=0.06241551786661148, Entropy=2.316718816757202, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14128971099853516, KL divergence=0.06163211166858673, Entropy=2.328788995742798, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/69_Step-85475.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/69_Step-85475.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 69
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_69.pb
Best checkpoint number: 57, Last checkpoint number: 67
Copying the frozen checkpoint from ./frozen_models/agent/model_57.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'66'}
Training> Name=main_level/agent, Worker=0, Episode=1381, Total reward=0, Steps=85531, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1382, Total reward=0, Steps=85602, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1383, Total reward=0, Steps=85639, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1384, Total reward=0, Steps=85672, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1385, Total reward=0, Steps=85705, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1386, Total reward=0, Steps=86002, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1387, Total reward=0, Steps=86121, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1388, Total reward=0, Steps=86390, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1389, Total reward=0, Steps=86494, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1390, Total reward=0, Steps=86627, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1391, Total reward=0, Steps=86866, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1392, Total reward=0, Steps=86935, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1393, Total reward=0, Steps=87089, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1394, Total reward=0, Steps=87124, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1395, Total reward=0, Steps=87200, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1396, Total reward=0, Steps=87364, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1397, Total reward=0, Steps=87466, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1398, Total reward=0, Steps=87576, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1399, Total reward=0, Steps=87694, Training iteration=69
Training> Name=main_level/agent, Worker=0, Episode=1400, Total reward=0, Steps=87738, Training iteration=69
Policy training> Surrogate loss=0.02144221030175686, KL divergence=0.0273202545940876, Entropy=2.26562237739563, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.0976245105266571, KL divergence=0.055886197835206985, Entropy=2.2784886360168457, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12190021574497223, KL divergence=0.05709679797291756, Entropy=2.2793984413146973, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.129837766289711, KL divergence=0.05512479320168495, Entropy=2.276123523712158, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1323513239622116, KL divergence=0.057717110961675644, Entropy=2.2807788848876953, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1359693706035614, KL divergence=0.05599140375852585, Entropy=2.2917773723602295, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13514472544193268, KL divergence=0.060189615935087204, Entropy=2.2748546600341797, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13395217061042786, KL divergence=0.05842891335487366, Entropy=2.2881033420562744, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1394553929567337, KL divergence=0.059948667883872986, Entropy=2.2933056354522705, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13950809836387634, KL divergence=0.05856994912028313, Entropy=2.3140485286712646, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/70_Step-87738.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/70_Step-87738.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 70
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_70.pb
Best checkpoint number: 68, Last checkpoint number: 68
Copying the frozen checkpoint from ./frozen_models/agent/model_68.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'67'}
Training> Name=main_level/agent, Worker=0, Episode=1401, Total reward=0, Steps=87810, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1402, Total reward=0, Steps=87890, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1403, Total reward=0, Steps=87986, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1404, Total reward=0, Steps=88013, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1405, Total reward=0, Steps=88076, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1406, Total reward=0, Steps=88122, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1407, Total reward=0, Steps=88150, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1408, Total reward=0, Steps=88290, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1409, Total reward=0, Steps=88362, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1410, Total reward=0, Steps=88458, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1411, Total reward=0, Steps=88497, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1412, Total reward=0, Steps=88569, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1413, Total reward=0, Steps=88622, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1414, Total reward=0, Steps=88721, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1415, Total reward=0, Steps=88871, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1416, Total reward=0, Steps=89014, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1417, Total reward=0, Steps=89046, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1418, Total reward=0, Steps=89117, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1419, Total reward=0, Steps=89219, Training iteration=70
Training> Name=main_level/agent, Worker=0, Episode=1420, Total reward=0, Steps=89256, Training iteration=70
Policy training> Surrogate loss=0.014980657957494259, KL divergence=0.018547380343079567, Entropy=2.28649640083313, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.10025369375944138, KL divergence=0.06564881652593613, Entropy=2.2223784923553467, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12548741698265076, KL divergence=0.06250085681676865, Entropy=2.2845520973205566, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.11992058902978897, KL divergence=0.07080339640378952, Entropy=2.2104218006134033, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1361653357744217, KL divergence=0.06588835269212723, Entropy=2.278726577758789, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13972771167755127, KL divergence=0.06797716021537781, Entropy=2.242234945297241, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13718201220035553, KL divergence=0.06797736138105392, Entropy=2.2715401649475098, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13592444360256195, KL divergence=0.06852462142705917, Entropy=2.278480052947998, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1437424272298813, KL divergence=0.07119133323431015, Entropy=2.269982099533081, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13788484036922455, KL divergence=0.07045450806617737, Entropy=2.295771598815918, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/71_Step-89256.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/71_Step-89256.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 71
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_71.pb
Best checkpoint number: 68, Last checkpoint number: 69
Copying the frozen checkpoint from ./frozen_models/agent/model_68.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'57'}
Training> Name=main_level/agent, Worker=0, Episode=1421, Total reward=0, Steps=89297, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1422, Total reward=0, Steps=89318, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1423, Total reward=0, Steps=89364, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1424, Total reward=0, Steps=89415, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1425, Total reward=0, Steps=89447, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1426, Total reward=0, Steps=89474, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1427, Total reward=0, Steps=89503, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1428, Total reward=0, Steps=89570, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1429, Total reward=0, Steps=89605, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1430, Total reward=0, Steps=89685, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1431, Total reward=0, Steps=89906, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1432, Total reward=0, Steps=90066, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1433, Total reward=0, Steps=90108, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1434, Total reward=0, Steps=90247, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1435, Total reward=0, Steps=90428, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1436, Total reward=0, Steps=90482, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1437, Total reward=0, Steps=90597, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1438, Total reward=0, Steps=90660, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1439, Total reward=0, Steps=90683, Training iteration=71
Training> Name=main_level/agent, Worker=0, Episode=1440, Total reward=0, Steps=90758, Training iteration=71
Policy training> Surrogate loss=0.005322545301169157, KL divergence=0.019262924790382385, Entropy=2.3499996662139893, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09991645067930222, KL divergence=0.05304548516869545, Entropy=2.3372151851654053, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1182439848780632, KL divergence=0.06250622123479843, Entropy=2.312767744064331, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1276950091123581, KL divergence=0.059949468821287155, Entropy=2.3379404544830322, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1280103176832199, KL divergence=0.05756828933954239, Entropy=2.361912488937378, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13039901852607727, KL divergence=0.056738920509815216, Entropy=2.358093500137329, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.12768995761871338, KL divergence=0.05886159837245941, Entropy=2.355863332748413, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1317107230424881, KL divergence=0.05936645343899727, Entropy=2.3545219898223877, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13854189217090607, KL divergence=0.05844449624419212, Entropy=2.361922264099121, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13111992180347443, KL divergence=0.05643916502594948, Entropy=2.394115686416626, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/72_Step-90758.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/72_Step-90758.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 72
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_72.pb
Best checkpoint number: 68, Last checkpoint number: 70
Copying the frozen checkpoint from ./frozen_models/agent/model_68.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'69'}
Training> Name=main_level/agent, Worker=0, Episode=1441, Total reward=0, Steps=90861, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1442, Total reward=0, Steps=91117, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1443, Total reward=0, Steps=91157, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1444, Total reward=0, Steps=91197, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1445, Total reward=0, Steps=91471, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1446, Total reward=0, Steps=91490, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1447, Total reward=0, Steps=91586, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1448, Total reward=0, Steps=91647, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1449, Total reward=0, Steps=91690, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1450, Total reward=0, Steps=91730, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1451, Total reward=0, Steps=91782, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1452, Total reward=0, Steps=91999, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1453, Total reward=0, Steps=92067, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1454, Total reward=0, Steps=92215, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1455, Total reward=0, Steps=92329, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1456, Total reward=0, Steps=92357, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1457, Total reward=0, Steps=92412, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1458, Total reward=0, Steps=92450, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1459, Total reward=0, Steps=92486, Training iteration=72
Training> Name=main_level/agent, Worker=0, Episode=1460, Total reward=0, Steps=92517, Training iteration=72
Policy training> Surrogate loss=0.016908420249819756, KL divergence=0.021995019167661667, Entropy=2.2742650508880615, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.10447477549314499, KL divergence=0.06230559200048447, Entropy=2.2169406414031982, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1253436803817749, KL divergence=0.06762440502643585, Entropy=2.2233006954193115, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1326170414686203, KL divergence=0.0705629289150238, Entropy=2.2007761001586914, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1368902325630188, KL divergence=0.07081610709428787, Entropy=2.201464891433716, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1407589614391327, KL divergence=0.06927987933158875, Entropy=2.208789587020874, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1335815191268921, KL divergence=0.06912296265363693, Entropy=2.222177743911743, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14489033818244934, KL divergence=0.07057911157608032, Entropy=2.215871572494507, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13602198660373688, KL divergence=0.06900720298290253, Entropy=2.230020523071289, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13616302609443665, KL divergence=0.07250882685184479, Entropy=2.219862937927246, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/73_Step-92517.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/73_Step-92517.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 73
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_73.pb
Best checkpoint number: 68, Last checkpoint number: 71
Copying the frozen checkpoint from ./frozen_models/agent/model_68.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'70'}
Training> Name=main_level/agent, Worker=0, Episode=1461, Total reward=0, Steps=92553, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1462, Total reward=0, Steps=92577, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1463, Total reward=0, Steps=92649, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1464, Total reward=0, Steps=92699, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1465, Total reward=0, Steps=92721, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1466, Total reward=0, Steps=92742, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1467, Total reward=0, Steps=92834, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1468, Total reward=0, Steps=93007, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1469, Total reward=0, Steps=93200, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1470, Total reward=0, Steps=93238, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1471, Total reward=0, Steps=93378, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1472, Total reward=0, Steps=93456, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1473, Total reward=0, Steps=93524, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1474, Total reward=0, Steps=93577, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1475, Total reward=0, Steps=93671, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1476, Total reward=0, Steps=93914, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1477, Total reward=0, Steps=93955, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1478, Total reward=0, Steps=94012, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1479, Total reward=0, Steps=94121, Training iteration=73
Training> Name=main_level/agent, Worker=0, Episode=1480, Total reward=0, Steps=94213, Training iteration=73
Policy training> Surrogate loss=0.01219344325363636, KL divergence=0.018893133848905563, Entropy=2.2913293838500977, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.10715818405151367, KL divergence=0.06419268250465393, Entropy=2.239636182785034, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12022185325622559, KL divergence=0.07533830404281616, Entropy=2.232513427734375, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12704996764659882, KL divergence=0.07894254475831985, Entropy=2.2441353797912598, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1271517127752304, KL divergence=0.0838712528347969, Entropy=2.2278993129730225, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14193154871463776, KL divergence=0.08165769279003143, Entropy=2.2431647777557373, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13682371377944946, KL divergence=0.0793779268860817, Entropy=2.265638828277588, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1360614001750946, KL divergence=0.07904652506113052, Entropy=2.2731308937072754, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1418491005897522, KL divergence=0.08081413060426712, Entropy=2.272599458694458, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13582153618335724, KL divergence=0.08001995086669922, Entropy=2.287747621536255, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/74_Step-94213.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/74_Step-94213.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 74
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_74.pb
Best checkpoint number: 68, Last checkpoint number: 72
Copying the frozen checkpoint from ./frozen_models/agent/model_68.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'71'}
Training> Name=main_level/agent, Worker=0, Episode=1481, Total reward=0, Steps=94294, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1482, Total reward=0, Steps=94325, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1483, Total reward=0, Steps=94363, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1484, Total reward=0, Steps=94410, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1485, Total reward=0, Steps=94533, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1486, Total reward=0, Steps=94574, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1487, Total reward=0, Steps=94706, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1488, Total reward=0, Steps=94809, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1489, Total reward=0, Steps=94981, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1490, Total reward=0, Steps=95083, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1491, Total reward=0, Steps=95278, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1492, Total reward=0, Steps=95367, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1493, Total reward=0, Steps=95469, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1494, Total reward=0, Steps=95588, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1495, Total reward=0, Steps=95720, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1496, Total reward=0, Steps=95816, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1497, Total reward=0, Steps=95882, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1498, Total reward=0, Steps=95901, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1499, Total reward=0, Steps=95986, Training iteration=74
Training> Name=main_level/agent, Worker=0, Episode=1500, Total reward=0, Steps=96069, Training iteration=74
Policy training> Surrogate loss=0.009895024821162224, KL divergence=0.030170731246471405, Entropy=2.1456756591796875, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09924496710300446, KL divergence=0.07869044691324234, Entropy=2.1076436042785645, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1204574853181839, KL divergence=0.0896984413266182, Entropy=2.1034817695617676, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1285276859998703, KL divergence=0.0932498425245285, Entropy=2.111424446105957, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1315034180879593, KL divergence=0.09200482070446014, Entropy=2.1258656978607178, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13385234773159027, KL divergence=0.09243030846118927, Entropy=2.131369113922119, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1351909190416336, KL divergence=0.09300322085618973, Entropy=2.1493124961853027, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13577525317668915, KL divergence=0.09283566474914551, Entropy=2.146928548812866, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1361517459154129, KL divergence=0.09078478813171387, Entropy=2.1788666248321533, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1365366131067276, KL divergence=0.09059847146272659, Entropy=2.185202121734619, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/75_Step-96069.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/75_Step-96069.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 75
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_75.pb
Best checkpoint number: 68, Last checkpoint number: 73
Copying the frozen checkpoint from ./frozen_models/agent/model_68.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'72'}
Training> Name=main_level/agent, Worker=0, Episode=1501, Total reward=0, Steps=96158, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1502, Total reward=0, Steps=96185, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1503, Total reward=0, Steps=96236, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1504, Total reward=0, Steps=96456, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1505, Total reward=0, Steps=96492, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1506, Total reward=0, Steps=96512, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1507, Total reward=0, Steps=96765, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1508, Total reward=0, Steps=96837, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1509, Total reward=0, Steps=97030, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1510, Total reward=0, Steps=97119, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1511, Total reward=0, Steps=97145, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1512, Total reward=0, Steps=97318, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1513, Total reward=0, Steps=97385, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1514, Total reward=0, Steps=97498, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1515, Total reward=0, Steps=97535, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1516, Total reward=0, Steps=97590, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1517, Total reward=0, Steps=97642, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1518, Total reward=0, Steps=97783, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1519, Total reward=0, Steps=97823, Training iteration=75
Training> Name=main_level/agent, Worker=0, Episode=1520, Total reward=0, Steps=97874, Training iteration=75
Policy training> Surrogate loss=0.01129770465195179, KL divergence=0.02324279211461544, Entropy=2.315678358078003, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09854672104120255, KL divergence=0.07180976867675781, Entropy=2.284263849258423, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11974885314702988, KL divergence=0.07412129640579224, Entropy=2.2689948081970215, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12991131842136383, KL divergence=0.07657287269830704, Entropy=2.258023262023926, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1316215544939041, KL divergence=0.07356152683496475, Entropy=2.2767906188964844, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13454656302928925, KL divergence=0.07567224651575089, Entropy=2.2846827507019043, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13961012661457062, KL divergence=0.07205002754926682, Entropy=2.314209222793579, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13520167768001556, KL divergence=0.07589209079742432, Entropy=2.292381763458252, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13486208021640778, KL divergence=0.07239904254674911, Entropy=2.3261711597442627, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13829030096530914, KL divergence=0.07317937910556793, Entropy=2.3195035457611084, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/76_Step-97874.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/76_Step-97874.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 76
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_76.pb
Best checkpoint number: 68, Last checkpoint number: 74
Copying the frozen checkpoint from ./frozen_models/agent/model_68.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'73'}
Training> Name=main_level/agent, Worker=0, Episode=1521, Total reward=0, Steps=97981, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1522, Total reward=0, Steps=98041, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1523, Total reward=0, Steps=98078, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1524, Total reward=0, Steps=98102, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1525, Total reward=0, Steps=98125, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1526, Total reward=0, Steps=98144, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1527, Total reward=0, Steps=98206, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1528, Total reward=0, Steps=98279, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1529, Total reward=0, Steps=98425, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1530, Total reward=0, Steps=98455, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1531, Total reward=0, Steps=98514, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1532, Total reward=0, Steps=98630, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1533, Total reward=0, Steps=98661, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1534, Total reward=0, Steps=98795, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1535, Total reward=0, Steps=98905, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1536, Total reward=0, Steps=99044, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1537, Total reward=0, Steps=99123, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1538, Total reward=0, Steps=99177, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1539, Total reward=0, Steps=99286, Training iteration=76
Training> Name=main_level/agent, Worker=0, Episode=1540, Total reward=0, Steps=99345, Training iteration=76
Policy training> Surrogate loss=0.006072198040783405, KL divergence=0.016278676688671112, Entropy=2.3684422969818115, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.10100161284208298, KL divergence=0.05519469082355499, Entropy=2.3347978591918945, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12527331709861755, KL divergence=0.06412560492753983, Entropy=2.3327832221984863, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.11836910247802734, KL divergence=0.06328734010457993, Entropy=2.340963125228882, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12135397642850876, KL divergence=0.06682901829481125, Entropy=2.3711788654327393, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13741494715213776, KL divergence=0.06662207096815109, Entropy=2.3573174476623535, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1311928629875183, KL divergence=0.06526138633489609, Entropy=2.387269973754883, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.12990514934062958, KL divergence=0.06590159982442856, Entropy=2.3821256160736084, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13557596504688263, KL divergence=0.06477157771587372, Entropy=2.399930477142334, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1367577463388443, KL divergence=0.06409599632024765, Entropy=2.3851914405822754, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/77_Step-99345.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/77_Step-99345.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 77
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_77.pb
Best checkpoint number: 68, Last checkpoint number: 75
Copying the frozen checkpoint from ./frozen_models/agent/model_68.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'74'}
Training> Name=main_level/agent, Worker=0, Episode=1541, Total reward=0, Steps=99410, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1542, Total reward=0, Steps=99495, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1543, Total reward=0, Steps=99549, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1544, Total reward=0, Steps=99583, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1545, Total reward=0, Steps=99640, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1546, Total reward=0, Steps=99684, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1547, Total reward=0, Steps=99772, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1548, Total reward=0, Steps=99840, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1549, Total reward=0, Steps=99872, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1550, Total reward=0, Steps=99936, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1551, Total reward=0, Steps=100025, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1552, Total reward=0, Steps=100066, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1553, Total reward=0, Steps=100098, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1554, Total reward=0, Steps=100217, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1555, Total reward=0, Steps=100358, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1556, Total reward=0, Steps=100427, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1557, Total reward=0, Steps=100528, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1558, Total reward=0, Steps=100580, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1559, Total reward=0, Steps=100667, Training iteration=77
Training> Name=main_level/agent, Worker=0, Episode=1560, Total reward=0, Steps=100741, Training iteration=77
Policy training> Surrogate loss=0.010999993421137333, KL divergence=0.023067807778716087, Entropy=2.284668207168579, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.0976838618516922, KL divergence=0.05814395472407341, Entropy=2.3067519664764404, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12449190765619278, KL divergence=0.07821677625179291, Entropy=2.263241767883301, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13056038320064545, KL divergence=0.07360659539699554, Entropy=2.29272723197937, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1325993835926056, KL divergence=0.07277481257915497, Entropy=2.286802053451538, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13718339800834656, KL divergence=0.06631702929735184, Entropy=2.329209566116333, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.12959901988506317, KL divergence=0.06762532889842987, Entropy=2.315337657928467, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1296614557504654, KL divergence=0.06712855398654938, Entropy=2.3295371532440186, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13620129227638245, KL divergence=0.06995242834091187, Entropy=2.3237781524658203, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13990184664726257, KL divergence=0.06881340593099594, Entropy=2.3370931148529053, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/78_Step-100741.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/78_Step-100741.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 78
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_78.pb
Best checkpoint number: 68, Last checkpoint number: 76
Copying the frozen checkpoint from ./frozen_models/agent/model_68.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'75'}
Training> Name=main_level/agent, Worker=0, Episode=1561, Total reward=0, Steps=100862, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1562, Total reward=0, Steps=100903, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1563, Total reward=0, Steps=100969, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1564, Total reward=0, Steps=101014, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1565, Total reward=0, Steps=101041, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1566, Total reward=0, Steps=101088, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1567, Total reward=0, Steps=101408, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1568, Total reward=0, Steps=101501, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1569, Total reward=0, Steps=101630, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1570, Total reward=0, Steps=101670, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1571, Total reward=0, Steps=101853, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1572, Total reward=0, Steps=101919, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1573, Total reward=0, Steps=102101, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1574, Total reward=0, Steps=102200, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1575, Total reward=0, Steps=102376, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1576, Total reward=0, Steps=102423, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1577, Total reward=0, Steps=102531, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1578, Total reward=0, Steps=102629, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1579, Total reward=0, Steps=102707, Training iteration=78
Training> Name=main_level/agent, Worker=0, Episode=1580, Total reward=0, Steps=102806, Training iteration=78
Policy training> Surrogate loss=0.016767462715506554, KL divergence=0.021444831043481827, Entropy=2.337712287902832, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09302619844675064, KL divergence=0.058079563081264496, Entropy=2.2701869010925293, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11704611778259277, KL divergence=0.057378560304641724, Entropy=2.2654664516448975, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.129825159907341, KL divergence=0.05718880146741867, Entropy=2.3002614974975586, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13243897259235382, KL divergence=0.05923504754900932, Entropy=2.2831645011901855, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13132403790950775, KL divergence=0.06103336811065674, Entropy=2.291384696960449, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13463176786899567, KL divergence=0.06406345963478088, Entropy=2.3155014514923096, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13309355080127716, KL divergence=0.06425174325704575, Entropy=2.3005685806274414, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13790254294872284, KL divergence=0.06396334618330002, Entropy=2.320474147796631, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14213888347148895, KL divergence=0.06405092775821686, Entropy=2.3193039894104004, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/79_Step-102806.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/79_Step-102806.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 79
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_79.pb
Best checkpoint number: 68, Last checkpoint number: 77
Copying the frozen checkpoint from ./frozen_models/agent/model_68.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'76'}
Training> Name=main_level/agent, Worker=0, Episode=1581, Total reward=0, Steps=102850, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1582, Total reward=0, Steps=102931, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1583, Total reward=0, Steps=103004, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1584, Total reward=0, Steps=103087, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1585, Total reward=0, Steps=103141, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1586, Total reward=0, Steps=103184, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1587, Total reward=0, Steps=103247, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1588, Total reward=0, Steps=103416, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1589, Total reward=0, Steps=103457, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1590, Total reward=0, Steps=103654, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1591, Total reward=0, Steps=103720, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1592, Total reward=0, Steps=103797, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1593, Total reward=0, Steps=103834, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1594, Total reward=0, Steps=103868, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1595, Total reward=0, Steps=103931, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1596, Total reward=0, Steps=103989, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1597, Total reward=0, Steps=104132, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1598, Total reward=0, Steps=104177, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1599, Total reward=0, Steps=104268, Training iteration=79
Training> Name=main_level/agent, Worker=0, Episode=1600, Total reward=0, Steps=104337, Training iteration=79
Policy training> Surrogate loss=0.015280723571777344, KL divergence=0.017949258908629417, Entropy=2.318010091781616, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.11262881010770798, KL divergence=0.06307495385408401, Entropy=2.2376933097839355, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11718328297138214, KL divergence=0.07050152868032455, Entropy=2.236191511154175, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13196687400341034, KL divergence=0.07231388241052628, Entropy=2.2432448863983154, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12842071056365967, KL divergence=0.06902390718460083, Entropy=2.274914026260376, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.12021411955356598, KL divergence=0.0691460594534874, Entropy=2.256263017654419, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13627459108829498, KL divergence=0.07047077268362045, Entropy=2.2657508850097656, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13384480774402618, KL divergence=0.0679723396897316, Entropy=2.2829134464263916, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.12638063728809357, KL divergence=0.06478531658649445, Entropy=2.2977685928344727, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13048794865608215, KL divergence=0.06419514864683151, Entropy=2.2935993671417236, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/80_Step-104337.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/80_Step-104337.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 80
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_80.pb
Best checkpoint number: 68, Last checkpoint number: 78
Copying the frozen checkpoint from ./frozen_models/agent/model_68.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'77'}
Training> Name=main_level/agent, Worker=0, Episode=1601, Total reward=0, Steps=104363, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1602, Total reward=0, Steps=104386, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1603, Total reward=0, Steps=104451, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1604, Total reward=0, Steps=104497, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1605, Total reward=0, Steps=104537, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1606, Total reward=0, Steps=104555, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1607, Total reward=0, Steps=104615, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1608, Total reward=0, Steps=104707, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1609, Total reward=0, Steps=104918, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1610, Total reward=0, Steps=105027, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1611, Total reward=0, Steps=105054, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1612, Total reward=0, Steps=105261, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1613, Total reward=0, Steps=105343, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1614, Total reward=0, Steps=105383, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1615, Total reward=0, Steps=105511, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1616, Total reward=0, Steps=105677, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1617, Total reward=0, Steps=105786, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1618, Total reward=0, Steps=105925, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1619, Total reward=0, Steps=106027, Training iteration=80
Training> Name=main_level/agent, Worker=0, Episode=1620, Total reward=0, Steps=106144, Training iteration=80
Policy training> Surrogate loss=0.0065564657561481, KL divergence=0.019947638735175133, Entropy=2.3225769996643066, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09794146567583084, KL divergence=0.06043621897697449, Entropy=2.2598984241485596, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11785001307725906, KL divergence=0.05875537917017937, Entropy=2.295398712158203, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1260179579257965, KL divergence=0.06348782032728195, Entropy=2.2665417194366455, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.12934793531894684, KL divergence=0.06490495800971985, Entropy=2.275040626525879, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13213245570659637, KL divergence=0.06585850566625595, Entropy=2.278684139251709, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13350620865821838, KL divergence=0.06594600528478622, Entropy=2.293745756149292, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13183912634849548, KL divergence=0.06928106397390366, Entropy=2.2756760120391846, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13493014872074127, KL divergence=0.06829389184713364, Entropy=2.2942795753479004, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13071635365486145, KL divergence=0.06945659965276718, Entropy=2.299882411956787, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/81_Step-106144.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/81_Step-106144.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 81
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_81.pb
Best checkpoint number: 79, Last checkpoint number: 79
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'78'}
Training> Name=main_level/agent, Worker=0, Episode=1621, Total reward=0, Steps=106248, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1622, Total reward=0, Steps=106519, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1623, Total reward=0, Steps=106564, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1624, Total reward=0, Steps=106587, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1625, Total reward=0, Steps=106620, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1626, Total reward=0, Steps=106645, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1627, Total reward=0, Steps=106673, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1628, Total reward=0, Steps=106740, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1629, Total reward=0, Steps=106836, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1630, Total reward=0, Steps=106867, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1631, Total reward=0, Steps=106952, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1632, Total reward=0, Steps=107001, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1633, Total reward=0, Steps=107031, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1634, Total reward=0, Steps=107122, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1635, Total reward=0, Steps=107245, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1636, Total reward=0, Steps=107513, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1637, Total reward=0, Steps=107558, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1638, Total reward=0, Steps=107604, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1639, Total reward=0, Steps=107684, Training iteration=81
Training> Name=main_level/agent, Worker=0, Episode=1640, Total reward=0, Steps=107725, Training iteration=81
Policy training> Surrogate loss=0.01939164660871029, KL divergence=0.01815442554652691, Entropy=2.3578169345855713, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.10326769202947617, KL divergence=0.0662585198879242, Entropy=2.291377544403076, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12213098257780075, KL divergence=0.06826648116111755, Entropy=2.3158280849456787, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12232285737991333, KL divergence=0.07310796529054642, Entropy=2.304819345474243, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1352258175611496, KL divergence=0.07089918106794357, Entropy=2.330869436264038, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13624830543994904, KL divergence=0.07083246856927872, Entropy=2.332509756088257, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1314123421907425, KL divergence=0.07184643298387527, Entropy=2.3359005451202393, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14237278699874878, KL divergence=0.07096899300813675, Entropy=2.3580474853515625, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1364106833934784, KL divergence=0.07191982120275497, Entropy=2.356933355331421, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14095854759216309, KL divergence=0.07171962410211563, Entropy=2.3641974925994873, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/82_Step-107725.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/82_Step-107725.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 82
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_82.pb
Best checkpoint number: 79, Last checkpoint number: 80
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'68'}
Training> Name=main_level/agent, Worker=0, Episode=1641, Total reward=0, Steps=107814, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1642, Total reward=0, Steps=107913, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1643, Total reward=0, Steps=107970, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1644, Total reward=0, Steps=108007, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1645, Total reward=0, Steps=108048, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1646, Total reward=0, Steps=108071, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1647, Total reward=0, Steps=108179, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1648, Total reward=0, Steps=108326, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1649, Total reward=0, Steps=108376, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1650, Total reward=0, Steps=108412, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1651, Total reward=0, Steps=108547, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1652, Total reward=0, Steps=108642, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1653, Total reward=0, Steps=108960, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1654, Total reward=0, Steps=109083, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1655, Total reward=0, Steps=109240, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1656, Total reward=0, Steps=109261, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1657, Total reward=0, Steps=109314, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1658, Total reward=0, Steps=109366, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1659, Total reward=0, Steps=109388, Training iteration=82
Training> Name=main_level/agent, Worker=0, Episode=1660, Total reward=0, Steps=109455, Training iteration=82
Policy training> Surrogate loss=0.015321475453674793, KL divergence=0.02225564233958721, Entropy=2.3377199172973633, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.1015612930059433, KL divergence=0.06526428461074829, Entropy=2.2721142768859863, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12487698346376419, KL divergence=0.0668485090136528, Entropy=2.2918663024902344, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1288178712129593, KL divergence=0.06540795415639877, Entropy=2.2861618995666504, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13377737998962402, KL divergence=0.06641560792922974, Entropy=2.2732107639312744, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13699638843536377, KL divergence=0.06362596899271011, Entropy=2.299696922302246, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13677914440631866, KL divergence=0.06270721554756165, Entropy=2.3136463165283203, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13913117349147797, KL divergence=0.06374534964561462, Entropy=2.303521156311035, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13859206438064575, KL divergence=0.06430400907993317, Entropy=2.3178327083587646, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13891707360744476, KL divergence=0.06537133455276489, Entropy=2.3028345108032227, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/83_Step-109455.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/83_Step-109455.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 83
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_83.pb
Best checkpoint number: 79, Last checkpoint number: 81
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'80'}
Training> Name=main_level/agent, Worker=0, Episode=1661, Total reward=0, Steps=109500, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1662, Total reward=0, Steps=109547, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1663, Total reward=0, Steps=109593, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1664, Total reward=0, Steps=109640, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1665, Total reward=0, Steps=109670, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1666, Total reward=0, Steps=109691, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1667, Total reward=0, Steps=109950, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1668, Total reward=0, Steps=110209, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1669, Total reward=0, Steps=110361, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1670, Total reward=0, Steps=110469, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1671, Total reward=0, Steps=110492, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1672, Total reward=0, Steps=110533, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1673, Total reward=0, Steps=110641, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1674, Total reward=0, Steps=110706, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1675, Total reward=0, Steps=110744, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1676, Total reward=0, Steps=110937, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1677, Total reward=0, Steps=110977, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1678, Total reward=0, Steps=111131, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1679, Total reward=0, Steps=111175, Training iteration=83
Training> Name=main_level/agent, Worker=0, Episode=1680, Total reward=0, Steps=111250, Training iteration=83
Policy training> Surrogate loss=0.01613951101899147, KL divergence=0.023286914452910423, Entropy=2.3179705142974854, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09749039262533188, KL divergence=0.0649857372045517, Entropy=2.243394374847412, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12355460971593857, KL divergence=0.062279943376779556, Entropy=2.2720513343811035, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13068349659442902, KL divergence=0.06507641077041626, Entropy=2.2654216289520264, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13336597383022308, KL divergence=0.06256365776062012, Entropy=2.2944142818450928, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13480016589164734, KL divergence=0.066969133913517, Entropy=2.2719550132751465, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13650956749916077, KL divergence=0.0637064129114151, Entropy=2.2981247901916504, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13678637146949768, KL divergence=0.06399377435445786, Entropy=2.303314208984375, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13632753491401672, KL divergence=0.0661175325512886, Entropy=2.294078826904297, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13797494769096375, KL divergence=0.06475044786930084, Entropy=2.325986623764038, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/84_Step-111250.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/84_Step-111250.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 84
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_84.pb
Best checkpoint number: 79, Last checkpoint number: 82
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'81'}
Training> Name=main_level/agent, Worker=0, Episode=1681, Total reward=0, Steps=111293, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1682, Total reward=0, Steps=111369, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1683, Total reward=0, Steps=111427, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1684, Total reward=0, Steps=111518, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1685, Total reward=0, Steps=111556, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1686, Total reward=0, Steps=111582, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1687, Total reward=0, Steps=111660, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1688, Total reward=0, Steps=111748, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1689, Total reward=0, Steps=111800, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1690, Total reward=0, Steps=111854, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1691, Total reward=0, Steps=111943, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1692, Total reward=0, Steps=112024, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1693, Total reward=0, Steps=112055, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1694, Total reward=0, Steps=112097, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1695, Total reward=0, Steps=112124, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1696, Total reward=0, Steps=112243, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1697, Total reward=0, Steps=112325, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1698, Total reward=0, Steps=112353, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1699, Total reward=0, Steps=112376, Training iteration=84
Training> Name=main_level/agent, Worker=0, Episode=1700, Total reward=0, Steps=112403, Training iteration=84
Policy training> Surrogate loss=0.015780458226799965, KL divergence=0.01195188332349062, Entropy=2.4360904693603516, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.1064528152346611, KL divergence=0.05147608742117882, Entropy=2.4339444637298584, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.13156664371490479, KL divergence=0.0685424953699112, Entropy=2.3712563514709473, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13651496171951294, KL divergence=0.07244652509689331, Entropy=2.3702704906463623, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.137700155377388, KL divergence=0.06875420361757278, Entropy=2.40421724319458, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.137568399310112, KL divergence=0.06904416531324387, Entropy=2.3983285427093506, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1403386890888214, KL divergence=0.06758294254541397, Entropy=2.405139684677124, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.139814555644989, KL divergence=0.06498033553361893, Entropy=2.4291958808898926, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14142952859401703, KL divergence=0.06515740603208542, Entropy=2.4333221912384033, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14309123158454895, KL divergence=0.06617462635040283, Entropy=2.42405104637146, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/85_Step-112403.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/85_Step-112403.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 85
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_85.pb
Best checkpoint number: 79, Last checkpoint number: 83
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'82'}
Training> Name=main_level/agent, Worker=0, Episode=1701, Total reward=0, Steps=112483, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1702, Total reward=0, Steps=112504, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1703, Total reward=0, Steps=112564, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1704, Total reward=0, Steps=112597, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1705, Total reward=0, Steps=112645, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1706, Total reward=0, Steps=112667, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1707, Total reward=0, Steps=112750, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1708, Total reward=0, Steps=112813, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1709, Total reward=0, Steps=112872, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1710, Total reward=0, Steps=112920, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1711, Total reward=0, Steps=112957, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1712, Total reward=0, Steps=113029, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1713, Total reward=0, Steps=113073, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1714, Total reward=0, Steps=113160, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1715, Total reward=0, Steps=113190, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1716, Total reward=0, Steps=113381, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1717, Total reward=0, Steps=113467, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1718, Total reward=0, Steps=113622, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1719, Total reward=0, Steps=113737, Training iteration=85
Training> Name=main_level/agent, Worker=0, Episode=1720, Total reward=0, Steps=113851, Training iteration=85
Policy training> Surrogate loss=0.009425629861652851, KL divergence=0.018078943714499474, Entropy=2.3131213188171387, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.11113368719816208, KL divergence=0.06568832695484161, Entropy=2.2821195125579834, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12865833938121796, KL divergence=0.0670575201511383, Entropy=2.288408041000366, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1368628889322281, KL divergence=0.0781121551990509, Entropy=2.2479612827301025, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1415640115737915, KL divergence=0.07960826903581619, Entropy=2.252992630004883, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1395229697227478, KL divergence=0.07432821393013, Entropy=2.2922861576080322, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1433517336845398, KL divergence=0.07420545071363449, Entropy=2.283074140548706, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14180806279182434, KL divergence=0.07518922537565231, Entropy=2.2894985675811768, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14611560106277466, KL divergence=0.0765547975897789, Entropy=2.2792813777923584, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.15067435801029205, KL divergence=0.07580063492059708, Entropy=2.3049163818359375, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/86_Step-113851.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/86_Step-113851.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 86
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_86.pb
Best checkpoint number: 79, Last checkpoint number: 84
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'83'}
Training> Name=main_level/agent, Worker=0, Episode=1721, Total reward=0, Steps=113924, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1722, Total reward=0, Steps=114003, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1723, Total reward=0, Steps=114041, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1724, Total reward=0, Steps=114081, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1725, Total reward=0, Steps=114342, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1726, Total reward=0, Steps=114363, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1727, Total reward=0, Steps=114463, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1728, Total reward=0, Steps=114513, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1729, Total reward=0, Steps=114580, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1730, Total reward=0, Steps=114715, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1731, Total reward=0, Steps=114751, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1732, Total reward=0, Steps=114808, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1733, Total reward=0, Steps=114911, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1734, Total reward=0, Steps=115035, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1735, Total reward=0, Steps=115082, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1736, Total reward=0, Steps=115199, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1737, Total reward=0, Steps=115263, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1738, Total reward=0, Steps=115399, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1739, Total reward=0, Steps=115511, Training iteration=86
Training> Name=main_level/agent, Worker=0, Episode=1740, Total reward=0, Steps=115547, Training iteration=86
Policy training> Surrogate loss=0.014731941744685173, KL divergence=0.021551579236984253, Entropy=2.3255653381347656, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.1077970415353775, KL divergence=0.05797451734542847, Entropy=2.2997069358825684, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.125802144408226, KL divergence=0.06480222195386887, Entropy=2.3095812797546387, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13486027717590332, KL divergence=0.06778356432914734, Entropy=2.2995784282684326, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.14530439674854279, KL divergence=0.06508660316467285, Entropy=2.3240203857421875, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14180245995521545, KL divergence=0.06584387272596359, Entropy=2.3329923152923584, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.14230549335479736, KL divergence=0.06652230024337769, Entropy=2.3418610095977783, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14627064764499664, KL divergence=0.06626670062541962, Entropy=2.3517861366271973, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1472400724887848, KL divergence=0.06752578914165497, Entropy=2.353457450866699, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14205099642276764, KL divergence=0.07007798552513123, Entropy=2.3454947471618652, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/87_Step-115547.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/87_Step-115547.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 87
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_87.pb
Best checkpoint number: 79, Last checkpoint number: 85
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'84'}
Training> Name=main_level/agent, Worker=0, Episode=1741, Total reward=0, Steps=115625, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1742, Total reward=0, Steps=115681, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1743, Total reward=0, Steps=115725, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1744, Total reward=0, Steps=115767, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1745, Total reward=0, Steps=115791, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1746, Total reward=0, Steps=115909, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1747, Total reward=0, Steps=115963, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1748, Total reward=0, Steps=116029, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1749, Total reward=0, Steps=116168, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1750, Total reward=0, Steps=116225, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1751, Total reward=0, Steps=116260, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1752, Total reward=0, Steps=116299, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1753, Total reward=0, Steps=116506, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1754, Total reward=0, Steps=116638, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1755, Total reward=0, Steps=116669, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1756, Total reward=0, Steps=116826, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1757, Total reward=0, Steps=116904, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1758, Total reward=0, Steps=116979, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1759, Total reward=0, Steps=117094, Training iteration=87
Training> Name=main_level/agent, Worker=0, Episode=1760, Total reward=0, Steps=117288, Training iteration=87
Policy training> Surrogate loss=0.020981160923838615, KL divergence=0.01874697394669056, Entropy=2.360861301422119, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.10003118216991425, KL divergence=0.07333959639072418, Entropy=2.3243942260742188, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1232653483748436, KL divergence=0.07136383652687073, Entropy=2.3671770095825195, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1293962597846985, KL divergence=0.07596295326948166, Entropy=2.3327927589416504, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1342281699180603, KL divergence=0.06897196918725967, Entropy=2.362142562866211, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13644036650657654, KL divergence=0.06882594525814056, Entropy=2.373305082321167, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13553547859191895, KL divergence=0.06611552834510803, Entropy=2.37937068939209, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13604013621807098, KL divergence=0.06601589918136597, Entropy=2.3848187923431396, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13213813304901123, KL divergence=0.06564419716596603, Entropy=2.392367362976074, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13630802929401398, KL divergence=0.06494271010160446, Entropy=2.3972060680389404, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/88_Step-117288.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/88_Step-117288.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 88
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_88.pb
Best checkpoint number: 79, Last checkpoint number: 86
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'85'}
Training> Name=main_level/agent, Worker=0, Episode=1761, Total reward=0, Steps=117339, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1762, Total reward=0, Steps=117391, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1763, Total reward=0, Steps=117411, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1764, Total reward=0, Steps=117462, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1765, Total reward=0, Steps=117496, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1766, Total reward=0, Steps=117543, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1767, Total reward=0, Steps=117584, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1768, Total reward=0, Steps=117675, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1769, Total reward=0, Steps=117725, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1770, Total reward=0, Steps=117762, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1771, Total reward=0, Steps=117839, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1772, Total reward=0, Steps=117865, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1773, Total reward=0, Steps=117946, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1774, Total reward=0, Steps=118146, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1775, Total reward=0, Steps=118207, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1776, Total reward=0, Steps=118369, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1777, Total reward=0, Steps=118431, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1778, Total reward=0, Steps=118474, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1779, Total reward=0, Steps=118526, Training iteration=88
Training> Name=main_level/agent, Worker=0, Episode=1780, Total reward=0, Steps=118589, Training iteration=88
Policy training> Surrogate loss=0.003173965262249112, KL divergence=0.020802434533834457, Entropy=2.3445591926574707, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.1093183159828186, KL divergence=0.052038393914699554, Entropy=2.3527584075927734, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1261153370141983, KL divergence=0.06431879103183746, Entropy=2.3359556198120117, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13119076192378998, KL divergence=0.061449747532606125, Entropy=2.3688597679138184, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13223335146903992, KL divergence=0.06418560445308685, Entropy=2.3462109565734863, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13734638690948486, KL divergence=0.05946343019604683, Entropy=2.3717899322509766, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13822494447231293, KL divergence=0.05886866897344589, Entropy=2.3710789680480957, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14139075577259064, KL divergence=0.057113099843263626, Entropy=2.3867006301879883, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13321293890476227, KL divergence=0.057763755321502686, Entropy=2.381564140319824, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13720956444740295, KL divergence=0.06196168065071106, Entropy=2.3780124187469482, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/89_Step-118589.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/89_Step-118589.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 89
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_89.pb
Best checkpoint number: 79, Last checkpoint number: 87
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'86'}
Training> Name=main_level/agent, Worker=0, Episode=1781, Total reward=0, Steps=118660, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1782, Total reward=0, Steps=118719, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1783, Total reward=0, Steps=118784, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1784, Total reward=0, Steps=118910, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1785, Total reward=0, Steps=118944, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1786, Total reward=0, Steps=119053, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1787, Total reward=0, Steps=119166, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1788, Total reward=0, Steps=119216, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1789, Total reward=0, Steps=119524, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1790, Total reward=0, Steps=119592, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1791, Total reward=0, Steps=119753, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1792, Total reward=0, Steps=119869, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1793, Total reward=0, Steps=119997, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1794, Total reward=0, Steps=120044, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1795, Total reward=0, Steps=120069, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1796, Total reward=0, Steps=120144, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1797, Total reward=0, Steps=120174, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1798, Total reward=0, Steps=120229, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1799, Total reward=0, Steps=120310, Training iteration=89
Training> Name=main_level/agent, Worker=0, Episode=1800, Total reward=0, Steps=120336, Training iteration=89
Policy training> Surrogate loss=0.017828036099672318, KL divergence=0.03500402346253395, Entropy=2.2589354515075684, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09497693181037903, KL divergence=0.0774458721280098, Entropy=2.2051496505737305, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11906281113624573, KL divergence=0.07227250933647156, Entropy=2.2363123893737793, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13048586249351501, KL divergence=0.07247837632894516, Entropy=2.2498021125793457, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.14020277559757233, KL divergence=0.07021686434745789, Entropy=2.260465383529663, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13798893988132477, KL divergence=0.0723954513669014, Entropy=2.2677340507507324, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.14178428053855896, KL divergence=0.07262896001338959, Entropy=2.269321918487549, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14262457191944122, KL divergence=0.07334793359041214, Entropy=2.2742342948913574, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14397978782653809, KL divergence=0.07183359563350677, Entropy=2.284241199493408, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14199718832969666, KL divergence=0.0720154345035553, Entropy=2.2961504459381104, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/90_Step-120336.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/90_Step-120336.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 90
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_90.pb
Best checkpoint number: 79, Last checkpoint number: 88
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'87'}
Training> Name=main_level/agent, Worker=0, Episode=1801, Total reward=0, Steps=120408, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1802, Total reward=0, Steps=120462, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1803, Total reward=0, Steps=120522, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1804, Total reward=0, Steps=120555, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1805, Total reward=0, Steps=120805, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1806, Total reward=0, Steps=120824, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1807, Total reward=0, Steps=120887, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1808, Total reward=0, Steps=121011, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1809, Total reward=0, Steps=121174, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1810, Total reward=0, Steps=121304, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1811, Total reward=0, Steps=121419, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1812, Total reward=0, Steps=121463, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1813, Total reward=0, Steps=121667, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1814, Total reward=0, Steps=121866, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1815, Total reward=0, Steps=121981, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1816, Total reward=0, Steps=122149, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1817, Total reward=0, Steps=122213, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1818, Total reward=0, Steps=122259, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1819, Total reward=0, Steps=122308, Training iteration=90
Training> Name=main_level/agent, Worker=0, Episode=1820, Total reward=0, Steps=122367, Training iteration=90
Policy training> Surrogate loss=0.019437622278928757, KL divergence=0.019750334322452545, Entropy=2.431276798248291, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09089840203523636, KL divergence=0.05422879010438919, Entropy=2.3799960613250732, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12434583157300949, KL divergence=0.05110364034771919, Entropy=2.389867067337036, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1331120878458023, KL divergence=0.05552968755364418, Entropy=2.376147508621216, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13817031681537628, KL divergence=0.05278021842241287, Entropy=2.4011354446411133, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13427576422691345, KL divergence=0.0553148128092289, Entropy=2.376408100128174, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.14120671153068542, KL divergence=0.05271833389997482, Entropy=2.409207582473755, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1402767151594162, KL divergence=0.05399115011096001, Entropy=2.388019323348999, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1423739194869995, KL divergence=0.05421755090355873, Entropy=2.4100468158721924, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14304903149604797, KL divergence=0.05478345602750778, Entropy=2.424739360809326, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/91_Step-122367.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/91_Step-122367.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 91
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_91.pb
Best checkpoint number: 79, Last checkpoint number: 89
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'88'}
Training> Name=main_level/agent, Worker=0, Episode=1821, Total reward=0, Steps=122409, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1822, Total reward=0, Steps=122484, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1823, Total reward=0, Steps=122550, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1824, Total reward=0, Steps=122601, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1825, Total reward=0, Steps=122638, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1826, Total reward=0, Steps=122703, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1827, Total reward=0, Steps=122816, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1828, Total reward=0, Steps=122865, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1829, Total reward=0, Steps=122968, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1830, Total reward=0, Steps=123194, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1831, Total reward=0, Steps=123278, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1832, Total reward=0, Steps=123337, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1833, Total reward=0, Steps=123408, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1834, Total reward=0, Steps=123537, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1835, Total reward=0, Steps=123581, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1836, Total reward=0, Steps=123648, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1837, Total reward=0, Steps=123763, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1838, Total reward=0, Steps=123801, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1839, Total reward=0, Steps=123824, Training iteration=91
Training> Name=main_level/agent, Worker=0, Episode=1840, Total reward=0, Steps=123943, Training iteration=91
Policy training> Surrogate loss=0.007235584314912558, KL divergence=0.018562916666269302, Entropy=2.3511736392974854, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.10279109328985214, KL divergence=0.05782904848456383, Entropy=2.3719260692596436, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12330219894647598, KL divergence=0.06744813919067383, Entropy=2.3580965995788574, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12079351395368576, KL divergence=0.06725459545850754, Entropy=2.324946880340576, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13189759850502014, KL divergence=0.06414221972227097, Entropy=2.3441083431243896, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13427676260471344, KL divergence=0.06065090373158455, Entropy=2.368337869644165, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.14037439227104187, KL divergence=0.06264404952526093, Entropy=2.3542873859405518, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13919410109519958, KL divergence=0.05946877598762512, Entropy=2.382812738418579, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1386534720659256, KL divergence=0.059620145708322525, Entropy=2.384246826171875, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.1308489441871643, KL divergence=0.057644810527563095, Entropy=2.402405023574829, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/92_Step-123943.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/92_Step-123943.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 92
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_92.pb
Best checkpoint number: 79, Last checkpoint number: 90
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'89'}
Training> Name=main_level/agent, Worker=0, Episode=1841, Total reward=0, Steps=123973, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1842, Total reward=0, Steps=124023, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1843, Total reward=0, Steps=124094, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1844, Total reward=0, Steps=124135, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1845, Total reward=0, Steps=124155, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1846, Total reward=0, Steps=124207, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1847, Total reward=0, Steps=124509, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1848, Total reward=0, Steps=124531, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1849, Total reward=0, Steps=124617, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1850, Total reward=0, Steps=124656, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1851, Total reward=0, Steps=124708, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1852, Total reward=0, Steps=124757, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1853, Total reward=0, Steps=124879, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1854, Total reward=0, Steps=124928, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1855, Total reward=0, Steps=125049, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1856, Total reward=0, Steps=125079, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1857, Total reward=0, Steps=125252, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1858, Total reward=0, Steps=125311, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1859, Total reward=0, Steps=125399, Training iteration=92
Training> Name=main_level/agent, Worker=0, Episode=1860, Total reward=0, Steps=125475, Training iteration=92
Policy training> Surrogate loss=0.001596712740138173, KL divergence=0.014070735312998295, Entropy=2.415419340133667, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.0933033674955368, KL divergence=0.04359064996242523, Entropy=2.4243783950805664, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.1349562555551529, KL divergence=0.058329012244939804, Entropy=2.371037006378174, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1405654102563858, KL divergence=0.054085623472929, Entropy=2.399916887283325, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13432694971561432, KL divergence=0.0550578273832798, Entropy=2.4032301902770996, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.14148713648319244, KL divergence=0.055055614560842514, Entropy=2.4205210208892822, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.14329184591770172, KL divergence=0.055940110236406326, Entropy=2.430250644683838, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13495135307312012, KL divergence=0.05710330232977867, Entropy=2.4417459964752197, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1387822926044464, KL divergence=0.05839728191494942, Entropy=2.4444942474365234, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14128918945789337, KL divergence=0.056570544838905334, Entropy=2.443727493286133, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/93_Step-125475.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/93_Step-125475.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 93
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_93.pb
Best checkpoint number: 79, Last checkpoint number: 91
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'90'}
Training> Name=main_level/agent, Worker=0, Episode=1861, Total reward=0, Steps=125545, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1862, Total reward=0, Steps=125782, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1863, Total reward=0, Steps=125820, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1864, Total reward=0, Steps=125870, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1865, Total reward=0, Steps=125989, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1866, Total reward=0, Steps=126015, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1867, Total reward=0, Steps=126077, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1868, Total reward=0, Steps=126145, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1869, Total reward=0, Steps=126195, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1870, Total reward=0, Steps=126362, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1871, Total reward=0, Steps=126408, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1872, Total reward=0, Steps=126523, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1873, Total reward=0, Steps=126548, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1874, Total reward=0, Steps=126625, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1875, Total reward=0, Steps=126677, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1876, Total reward=0, Steps=126746, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1877, Total reward=0, Steps=126795, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1878, Total reward=0, Steps=126818, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1879, Total reward=0, Steps=126845, Training iteration=93
Training> Name=main_level/agent, Worker=0, Episode=1880, Total reward=0, Steps=126907, Training iteration=93
Policy training> Surrogate loss=0.006384184584021568, KL divergence=0.02095937356352806, Entropy=2.350360155105591, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.09916578978300095, KL divergence=0.06414729356765747, Entropy=2.3319778442382812, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.11922075599431992, KL divergence=0.06086171790957451, Entropy=2.3608429431915283, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.14246083796024323, KL divergence=0.06751463562250137, Entropy=2.327986001968384, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1411380022764206, KL divergence=0.06312989443540573, Entropy=2.374776840209961, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1410388946533203, KL divergence=0.06491950899362564, Entropy=2.35665225982666, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1435575783252716, KL divergence=0.06018807739019394, Entropy=2.4015920162200928, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.14102481305599213, KL divergence=0.05902452394366264, Entropy=2.4015140533447266, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14195862412452698, KL divergence=0.05778135359287262, Entropy=2.4099855422973633, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14250488579273224, KL divergence=0.057173147797584534, Entropy=2.4218363761901855, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/94_Step-126907.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/94_Step-126907.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 94
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_94.pb
Best checkpoint number: 79, Last checkpoint number: 92
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'91'}
Training> Name=main_level/agent, Worker=0, Episode=1881, Total reward=0, Steps=126933, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1882, Total reward=0, Steps=126985, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1883, Total reward=0, Steps=127045, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1884, Total reward=0, Steps=127153, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1885, Total reward=0, Steps=127187, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1886, Total reward=0, Steps=127230, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1887, Total reward=0, Steps=127284, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1888, Total reward=0, Steps=127378, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1889, Total reward=0, Steps=127456, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1890, Total reward=0, Steps=127514, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1891, Total reward=0, Steps=127563, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1892, Total reward=0, Steps=127607, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1893, Total reward=0, Steps=127727, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1894, Total reward=0, Steps=127805, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1895, Total reward=0, Steps=127834, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1896, Total reward=0, Steps=127873, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1897, Total reward=0, Steps=128031, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1898, Total reward=0, Steps=128093, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1899, Total reward=0, Steps=128170, Training iteration=94
Training> Name=main_level/agent, Worker=0, Episode=1900, Total reward=0, Steps=128203, Training iteration=94
Policy training> Surrogate loss=0.001409928547218442, KL divergence=0.013060550205409527, Entropy=2.4325575828552246, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.10847922414541245, KL divergence=0.039989445358514786, Entropy=2.4441046714782715, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12890471518039703, KL divergence=0.06036991626024246, Entropy=2.387924909591675, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13346359133720398, KL divergence=0.062452442944049835, Entropy=2.374823570251465, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13786861300468445, KL divergence=0.05422859638929367, Entropy=2.407313823699951, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.13806486129760742, KL divergence=0.05790739133954048, Entropy=2.4000182151794434, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13757632672786713, KL divergence=0.052236221730709076, Entropy=2.4357008934020996, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13369473814964294, KL divergence=0.05091729760169983, Entropy=2.4340829849243164, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13860857486724854, KL divergence=0.05140243098139763, Entropy=2.4399704933166504, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13673916459083557, KL divergence=0.05053498595952988, Entropy=2.449078321456909, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/95_Step-128203.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/95_Step-128203.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 95
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_95.pb
Best checkpoint number: 79, Last checkpoint number: 93
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'92'}
Training> Name=main_level/agent, Worker=0, Episode=1901, Total reward=0, Steps=128231, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1902, Total reward=0, Steps=128284, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1903, Total reward=0, Steps=128303, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1904, Total reward=0, Steps=128332, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1905, Total reward=0, Steps=128359, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1906, Total reward=0, Steps=128474, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1907, Total reward=0, Steps=128577, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1908, Total reward=0, Steps=128723, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1909, Total reward=0, Steps=128772, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1910, Total reward=0, Steps=128925, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1911, Total reward=0, Steps=128976, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1912, Total reward=0, Steps=129108, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1913, Total reward=0, Steps=129147, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1914, Total reward=0, Steps=129202, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1915, Total reward=0, Steps=129289, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1916, Total reward=0, Steps=129324, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1917, Total reward=0, Steps=129447, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1918, Total reward=0, Steps=129585, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1919, Total reward=0, Steps=129628, Training iteration=95
Training> Name=main_level/agent, Worker=0, Episode=1920, Total reward=0, Steps=129658, Training iteration=95
Policy training> Surrogate loss=0.014837879687547684, KL divergence=0.010852960869669914, Entropy=2.433145046234131, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.11311519145965576, KL divergence=0.046676818281412125, Entropy=2.4081029891967773, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12567667663097382, KL divergence=0.04913243278861046, Entropy=2.394496440887451, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13464504480361938, KL divergence=0.04871704429388046, Entropy=2.397732734680176, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1351475566625595, KL divergence=0.04713476076722145, Entropy=2.4128623008728027, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1368817836046219, KL divergence=0.04738153517246246, Entropy=2.4329402446746826, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1406869739294052, KL divergence=0.047906544059515, Entropy=2.4336776733398438, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1504291296005249, KL divergence=0.04810675233602524, Entropy=2.4390604496002197, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.14361800253391266, KL divergence=0.04763653501868248, Entropy=2.4623191356658936, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14720141887664795, KL divergence=0.047844048589468, Entropy=2.447925090789795, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/96_Step-129658.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/96_Step-129658.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 96
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_96.pb
Best checkpoint number: 79, Last checkpoint number: 94
Copying the frozen checkpoint from ./frozen_models/agent/model_79.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'93'}
Training> Name=main_level/agent, Worker=0, Episode=1921, Total reward=0, Steps=129719, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1922, Total reward=0, Steps=129775, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1923, Total reward=0, Steps=129936, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1924, Total reward=0, Steps=129976, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1925, Total reward=0, Steps=130012, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1926, Total reward=0, Steps=130069, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1927, Total reward=0, Steps=130147, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1928, Total reward=0, Steps=130233, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1929, Total reward=0, Steps=130267, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1930, Total reward=0, Steps=130353, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1931, Total reward=0, Steps=130463, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1932, Total reward=0, Steps=130483, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1933, Total reward=0, Steps=130640, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1934, Total reward=0, Steps=130674, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1935, Total reward=0, Steps=130755, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1936, Total reward=0, Steps=130844, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1937, Total reward=0, Steps=130912, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1938, Total reward=0, Steps=131032, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1939, Total reward=0, Steps=131135, Training iteration=96
Training> Name=main_level/agent, Worker=0, Episode=1940, Total reward=0, Steps=131180, Training iteration=96
Policy training> Surrogate loss=0.012097666040062904, KL divergence=0.0122189000248909, Entropy=2.452758550643921, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.10049790889024734, KL divergence=0.04277445003390312, Entropy=2.442826747894287, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12309569865465164, KL divergence=0.04802277311682701, Entropy=2.417118549346924, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.13277548551559448, KL divergence=0.05311432108283043, Entropy=2.409902811050415, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13767747581005096, KL divergence=0.05193781480193138, Entropy=2.4233100414276123, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1400761902332306, KL divergence=0.05308778956532478, Entropy=2.4411416053771973, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.13680057227611542, KL divergence=0.05147181823849678, Entropy=2.4625277519226074, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13451597094535828, KL divergence=0.05250955745577812, Entropy=2.4563002586364746, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.1435103416442871, KL divergence=0.05343011021614075, Entropy=2.468557834625244, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14128683507442474, KL divergence=0.05469587445259094, Entropy=2.472006320953369, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/97_Step-131180.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/97_Step-131180.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 97
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_97.pb
Best checkpoint number: 95, Last checkpoint number: 95
Copying the frozen checkpoint from ./frozen_models/agent/model_95.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'94'}
Training> Name=main_level/agent, Worker=0, Episode=1941, Total reward=0, Steps=131211, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1942, Total reward=0, Steps=131241, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1943, Total reward=0, Steps=131278, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1944, Total reward=0, Steps=131329, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1945, Total reward=0, Steps=131423, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1946, Total reward=0, Steps=131452, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1947, Total reward=0, Steps=131548, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1948, Total reward=0, Steps=131658, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1949, Total reward=0, Steps=131680, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1950, Total reward=0, Steps=131744, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1951, Total reward=0, Steps=131805, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1952, Total reward=0, Steps=131886, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1953, Total reward=0, Steps=131965, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1954, Total reward=0, Steps=132060, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1955, Total reward=0, Steps=132185, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1956, Total reward=0, Steps=132266, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1957, Total reward=0, Steps=132303, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1958, Total reward=0, Steps=132389, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1959, Total reward=0, Steps=132424, Training iteration=97
Training> Name=main_level/agent, Worker=0, Episode=1960, Total reward=0, Steps=132544, Training iteration=97
Policy training> Surrogate loss=0.007344132289290428, KL divergence=0.015190470963716507, Entropy=2.4457619190216064, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.0999113917350769, KL divergence=0.04436923936009407, Entropy=2.4508652687072754, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12372615188360214, KL divergence=0.04942386597394943, Entropy=2.413026809692383, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.12954527139663696, KL divergence=0.04710448160767555, Entropy=2.431988000869751, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.1316484659910202, KL divergence=0.05034354329109192, Entropy=2.4184577465057373, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1364511400461197, KL divergence=0.045846883207559586, Entropy=2.4579029083251953, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.145241841673851, KL divergence=0.048700276762247086, Entropy=2.433389663696289, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.1382260024547577, KL divergence=0.0470212884247303, Entropy=2.454439163208008, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13237108290195465, KL divergence=0.04686729982495308, Entropy=2.4647295475006104, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.14033927023410797, KL divergence=0.0476192869246006, Entropy=2.4600017070770264, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/98_Step-132544.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/98_Step-132544.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 98
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_98.pb
Best checkpoint number: 96, Last checkpoint number: 96
Copying the frozen checkpoint from ./frozen_models/agent/model_96.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'79'}
Training> Name=main_level/agent, Worker=0, Episode=1961, Total reward=0, Steps=132567, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1962, Total reward=0, Steps=132592, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1963, Total reward=0, Steps=132663, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1964, Total reward=0, Steps=132720, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1965, Total reward=0, Steps=132748, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1966, Total reward=0, Steps=132797, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1967, Total reward=0, Steps=132945, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1968, Total reward=0, Steps=133194, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1969, Total reward=0, Steps=133266, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1970, Total reward=0, Steps=133330, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1971, Total reward=0, Steps=133374, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1972, Total reward=0, Steps=133409, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1973, Total reward=0, Steps=133463, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1974, Total reward=0, Steps=133494, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1975, Total reward=0, Steps=133617, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1976, Total reward=0, Steps=133639, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1977, Total reward=0, Steps=133679, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1978, Total reward=0, Steps=133804, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1979, Total reward=0, Steps=133825, Training iteration=98
Training> Name=main_level/agent, Worker=0, Episode=1980, Total reward=0, Steps=133928, Training iteration=98
Policy training> Surrogate loss=0.013525215908885002, KL divergence=0.01464023720473051, Entropy=2.398780345916748, training epoch=0, learning_rate=0.0003
Policy training> Surrogate loss=-0.1070995107293129, KL divergence=0.053618211299180984, Entropy=2.3744149208068848, training epoch=1, learning_rate=0.0003
Policy training> Surrogate loss=-0.12825237214565277, KL divergence=0.05679669231176376, Entropy=2.370795488357544, training epoch=2, learning_rate=0.0003
Policy training> Surrogate loss=-0.1276801973581314, KL divergence=0.06180668994784355, Entropy=2.3313148021698, training epoch=3, learning_rate=0.0003
Policy training> Surrogate loss=-0.13938625156879425, KL divergence=0.058100201189517975, Entropy=2.3820559978485107, training epoch=4, learning_rate=0.0003
Policy training> Surrogate loss=-0.1337774097919464, KL divergence=0.05853315070271492, Entropy=2.3705668449401855, training epoch=5, learning_rate=0.0003
Policy training> Surrogate loss=-0.1416429728269577, KL divergence=0.05895904079079628, Entropy=2.387052536010742, training epoch=6, learning_rate=0.0003
Policy training> Surrogate loss=-0.13856588304042816, KL divergence=0.057984840124845505, Entropy=2.396364212036133, training epoch=7, learning_rate=0.0003
Policy training> Surrogate loss=-0.13751190900802612, KL divergence=0.058009617030620575, Entropy=2.4034640789031982, training epoch=8, learning_rate=0.0003
Policy training> Surrogate loss=-0.13741979002952576, KL divergence=0.05705616995692253, Entropy=2.4169633388519287, training epoch=9, learning_rate=0.0003
INFO:tensorflow:./checkpoint_sagemaker/agent/99_Step-133928.ckpt is not in all_model_checkpoint_paths. Manually adding it.
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/99_Step-133928.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 99
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
INFO:tensorflow:Froze 11 variables.
INFO:tensorflow:Converted 11 variables to const ops.
saved intermediate frozen graph: data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/model_99.pb
Best checkpoint number: 96, Last checkpoint number: 97
Copying the frozen checkpoint from ./frozen_models/agent/model_96.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-e7cbafab-267a-4be7-bc83-4324f23e1f72/models/044eac5b-477b-40f2-b6d5-b6a7c6567bda/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'95'}
Training> Name=main_level/agent, Worker=0, Episode=1981, Total reward=0, Steps=134019, Training iteration=99
Training> Name=main_level/agent, Worker=0, Episode=1982, Total reward=0, Steps=134074, Training iteration=99
Training> Name=main_level/agent, Worker=0, Episode=1983, Total reward=0, Steps=134109, Training iteration=99
Training> Name=main_level/agent, Worker=0, Episode=1984, Total reward=0, Steps=134159, Training iteration=99
Training> Name=main_level/agent, Worker=0, Episode=1985, Total reward=0, Steps=134190, Training iteration=99
Training> Name=main_level/agent, Worker=0, Episode=1986, Total reward=0, Steps=134232, Training iteration=99
Training> Name=main_level/agent, Worker=0, Episode=1987, Total reward=0, Steps=134300, Training iteration=99
Training> Name=main_level/agent, Worker=0, Episode=1988, Total reward=0, Steps=134409, Training iteration=99
Training> Name=main_level/agent, Worker=0, Episode=1989, Total reward=0, Steps=134664, Training iteration=99
